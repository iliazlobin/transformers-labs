{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%pip install \"sagemaker>=2.163.0\"\n",
    "!huggingface-cli login --token $HUGGING_FACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-east-1')\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "region = \"us-east-1\"\n",
    "\n",
    "sagemaker_role = \"arn:aws:iam::643713846674:role/sagemaker-executor\"\n",
    "session_name = \"sagemaker-executor-session\"\n",
    "\n",
    "response = sts_client.assume_role(RoleArn=sagemaker_role, RoleSessionName=session_name)\n",
    "\n",
    "credentials = response[\"Credentials\"]\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=credentials[\"AccessKeyId\"],\n",
    "    aws_secret_access_key=credentials[\"SecretAccessKey\"],\n",
    "    aws_session_token=credentials[\"SessionToken\"],\n",
    ")\n",
    "pprint(session)\n",
    "\n",
    "sagemaker_client = session.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'get_execution_role'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# sagemaker_session = sagemaker.Session()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# region = sagemaker_session.boto_region_name\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m role \u001b[38;5;241m=\u001b[39m sagemaker_session\u001b[38;5;241m.\u001b[39mget_execution_role()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'get_execution_role'"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# region = sagemaker_session.boto_region_name\n",
    "role = sagemaker_session.get_execution_role()\n",
    "print(f\"{role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.4.2-gpu-py310-cu121-ubuntu22.04'\n"
     ]
    }
   ],
   "source": [
    "huggingface_image_uri = get_huggingface_llm_image_uri(\n",
    "  backend=\"huggingface\", # or lmi\n",
    "  region=region\n",
    ")\n",
    "pprint(huggingface_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.huggingface.model.HuggingFaceModel object at 0x7f50f9cc3e30>\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"grammarly/coedit-large\"\n",
    "model_name = \"grammarly-coedit-large-2-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "hub = {\n",
    "    # \"HF_MODEL_ID\": \"EleutherAI/gpt-neox-20b\",\n",
    "    \"HF_MODEL_ID\": \"grammarly/coedit-large\",\n",
    "    \"HF_TASK\": \"text-generation\",\n",
    "    \"SM_NUM_GPUS\": \"1\",\n",
    "    \"HF_MODEL_QUANTIZE\": \"bitsandbytes\",\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel(name=model_name, env=hub, role=sagemaker_role, image_uri=huggingface_image_uri)\n",
    "pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.1-gpu-py310\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "pytorch_inference_image = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.1\",\n",
    "    # py_version=\"py3\",\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "\n",
    "print(pytorch_inference_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./model/  already exists\n",
      "s3://sagemaker-us-east-1-643713846674/sagemaker/huggingface-pytorch-inference-recommender/inference/hf_payload.tar.gz\n",
      "s3://sagemaker-us-east-1-643713846674/sagemaker/huggingface-pytorch-inference-recommender/grammarly-coedit-large/model/hf-model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer, pipeline\n",
    "\n",
    "export_dir = \"./model/\"\n",
    "\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "    print(\"Directory \", export_dir, \" Created \")\n",
    "else:\n",
    "    print(\"Directory \", export_dir, \" already exists\")\n",
    "\n",
    "# coedit_large_tokenizer = AutoTokenizer.from_pretrained(\"grammarly/coedit-large\")\n",
    "# coedit_large_model = T5ForConditionalGeneration.from_pretrained(\"grammarly/coedit-large\")\n",
    "coedit_large_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "coedit_large_pipeline.save_pretrained(\"./model\")\n",
    "\n",
    "model_archive_name = \"hf-model.tar.gz\"\n",
    "payload_archive_name = \"hf_payload.tar.gz\"\n",
    "\n",
    "# !cd model && tar -cvpzf ../{model_archive_name} *\n",
    "# !cd model/sample-payload && tar czvf ../../{payload_archive_name} *\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "prefix = \"sagemaker/huggingface-pytorch-inference-recommender\"\n",
    "\n",
    "sample_payload_url = sagemaker.Session().upload_data(\n",
    "    payload_archive_name, bucket=bucket, key_prefix=prefix + \"/inference\"\n",
    ")\n",
    "model_url = sagemaker.Session().upload_data(\n",
    "    model_archive_name, bucket=bucket, key_prefix=prefix + \"/grammarly-coedit-large/model\"\n",
    ")\n",
    "\n",
    "\n",
    "print(sample_payload_url)\n",
    "print(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pytorch-2024-04-08-00-40-32\n",
      "{'ModelPackageGroupArn': 'arn:aws:sagemaker:us-east-1:643713846674:model-package-group/huggingface-pytorch-2024-04-08-00-40-32', 'ResponseMetadata': {'RequestId': '6cb9c8b4-ed73-4f06-8cb0-343bb45a73dd', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6cb9c8b4-ed73-4f06-8cb0-343bb45a73dd', 'content-type': 'application/x-amz-json-1.1', 'content-length': '127', 'date': 'Mon, 08 Apr 2024 00:40:32 GMT'}, 'RetryAttempts': 0}}\n",
      "{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:643713846674:model-package/huggingface-pytorch-2024-04-08-00-40-32/1',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '118',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Mon, 08 Apr 2024 00:40:32 GMT',\n",
      "                                      'x-amzn-requestid': 'd7f39b37-9edc-4592-b53e-9c444df30032'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'd7f39b37-9edc-4592-b53e-9c444df30032',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region)\n",
    "\n",
    "model_package_group_name = \"huggingface-pytorch-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(model_package_group_name)\n",
    "\n",
    "model_pacakge_group_response = client.create_model_package_group(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageGroupDescription=\"My sample HuggingFace PyTorch model package group\",\n",
    ")\n",
    "\n",
    "print(model_pacakge_group_response)\n",
    "\n",
    "ml_domain = \"NATURAL_LANGUAGE_PROCESSING\"\n",
    "ml_task = \"FILL_MASK\"\n",
    "ml_framework = \"PYTORCH\"\n",
    "framework_version = \"1.6.0\"\n",
    "model = \"grammarly-coedit-large\"\n",
    "\n",
    "model_package_version_response = client.create_model_package(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageDescription=\"HuggingFace PyTorch Inference Recommender Demo\",\n",
    "    Domain=ml_domain,\n",
    "    Task=ml_task,\n",
    "    SamplePayloadUrl=sample_payload_url,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"ContainerHostname\": \"huggingface-pytorch\",\n",
    "                \"Image\": huggingface_image_uri,\n",
    "                \"ModelDataUrl\": model_url,\n",
    "                \"Framework\": ml_framework,\n",
    "                \"NearestModelName\": model,\n",
    "                \"Environment\": {\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "                    \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "                    \"SAGEMAKER_REGION\": region,\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": model_url,\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
    "            \"ml.g5.xlarge\",\n",
    "            \"ml.g4dn.xlarge\",\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"text/csv\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"text/csv\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "pprint(model_package_version_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JobArn': 'arn:aws:sagemaker:us-east-1:643713846674:inference-recommendations-job/huggingface-pytorch-basic-recommender-job-2024-04-07-20-44-22', 'ResponseMetadata': {'RequestId': 'a8a0d26a-4761-4676-922a-ba6bc0636751', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'a8a0d26a-4761-4676-922a-ba6bc0636751', 'content-type': 'application/x-amz-json-1.1', 'content-length': '145', 'date': 'Mon, 08 Apr 2024 00:44:23 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "\n",
    "default_job = \"huggingface-pytorch-basic-recommender-job-\" + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "default_response = sagemaker_client.create_inference_recommendations_job(\n",
    "    JobName=str(default_job),\n",
    "    JobDescription=\"HuggingFace PyTorch Inference Basic Recommender Job\",\n",
    "    JobType=\"Default\",\n",
    "    RoleArn=sagemaker_role,\n",
    "    InputConfig={\"ModelPackageVersionArn\": model_package_version_response[\"ModelPackageArn\"]},\n",
    ")\n",
    "\n",
    "print(default_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job in progress\n",
      "Inference recommender job failed \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'inference_recommender_job'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:18\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'inference_recommender_job'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region)\n",
    "\n",
    "ended = False\n",
    "while not ended:\n",
    "    inference_recommender_job = client.describe_inference_recommendations_job(JobName=str(default_job))\n",
    "    if inference_recommender_job[\"Status\"] in [\"COMPLETED\", \"STOPPED\", \"FAILED\"]:\n",
    "        ended = True\n",
    "    else:\n",
    "        print(\"Inference recommender job in progress\")\n",
    "        time.sleep(60)\n",
    "\n",
    "if inference_recommender_job[\"Status\"] == \"FAILED\":\n",
    "    print(\"Inference recommender job failed \")\n",
    "    print(\"Failed Reason: {}\".inference_recommender_job[\"FailedReason\"])\n",
    "else:\n",
    "    print(\"Inference recommender job completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!<sagemaker.huggingface.model.HuggingFacePredictor object at 0x7f50fa0c3f80>\n"
     ]
    }
   ],
   "source": [
    "# https://aws.amazon.com/ec2/instance-types/\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    # instance_type=\"ml.g4dn.xlarge\",\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    "    endpoint_name=model_name\n",
    ")\n",
    "pprint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I will go to the store.'}]\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "  \"inputs\": \"fix grammar: I goes to the store\",\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 1,\n",
    "    # \"watermark\": True\n",
    "  }\n",
    "}\n",
    "\n",
    "response = predictor.predict(input_data)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Framework</th>\n",
       "      <th>FrameworkVersion</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>MXNET</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>densenet201-gluon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>MXNET</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>resnet18v2-gluon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>resnet152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>efficientnetb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>nasnetlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>inception-v3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>xception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>densenet201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>xceptionV1-keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_CLASSIFICATION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_SEGMENTATION</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>unet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>IMAGE_SEGMENTATION</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>mask-rcnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>OBJECT_DETECTION</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>yolov4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>OBJECT_DETECTION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>faster-rcnn-resnet101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COMPUTER_VISION</td>\n",
       "      <td>OBJECT_DETECTION</td>\n",
       "      <td>TENSORFLOW</td>\n",
       "      <td>1.15.5</td>\n",
       "      <td>retinanet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACHINE_LEARNING</td>\n",
       "      <td>CLASSIFICATION</td>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>1.0-1</td>\n",
       "      <td>xgboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MACHINE_LEARNING</td>\n",
       "      <td>REGRESSION</td>\n",
       "      <td>SAGEMAKER-SCIKIT-LEARN</td>\n",
       "      <td>0.23-1</td>\n",
       "      <td>sagemaker-scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MACHINE_LEARNING</td>\n",
       "      <td>REGRESSION</td>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>1.3-1</td>\n",
       "      <td>xgboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NATURAL_LANGUAGE_PROCESSING</td>\n",
       "      <td>FILL_MASK</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>bert-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NATURAL_LANGUAGE_PROCESSING</td>\n",
       "      <td>FILL_MASK</td>\n",
       "      <td>PYTORCH</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Domain                     Task                Framework        FrameworkVersion          Model         \n",
       "9               COMPUTER_VISION  IMAGE_CLASSIFICATION                   MXNET       1.8.0            densenet201-gluon\n",
       "10              COMPUTER_VISION  IMAGE_CLASSIFICATION                   MXNET       1.8.0             resnet18v2-gluon\n",
       "14              COMPUTER_VISION  IMAGE_CLASSIFICATION                 PYTORCH       1.6.0                    resnet152\n",
       "0               COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5               efficientnetb7\n",
       "4               COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                  nasnetlarge\n",
       "5               COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                        vgg16\n",
       "6               COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                 inception-v3\n",
       "11              COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                     xception\n",
       "12              COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                  densenet201\n",
       "17              COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5             xceptionV1-keras\n",
       "18              COMPUTER_VISION  IMAGE_CLASSIFICATION              TENSORFLOW      1.15.5                     resnet50\n",
       "1               COMPUTER_VISION    IMAGE_SEGMENTATION                 PYTORCH       1.6.0                         unet\n",
       "7               COMPUTER_VISION    IMAGE_SEGMENTATION                 PYTORCH       1.6.0                    mask-rcnn\n",
       "13              COMPUTER_VISION      OBJECT_DETECTION                 PYTORCH       1.6.0                       yolov4\n",
       "3               COMPUTER_VISION      OBJECT_DETECTION              TENSORFLOW      1.15.5        faster-rcnn-resnet101\n",
       "19              COMPUTER_VISION      OBJECT_DETECTION              TENSORFLOW      1.15.5                    retinanet\n",
       "2              MACHINE_LEARNING        CLASSIFICATION                 XGBOOST       1.0-1                      xgboost\n",
       "8              MACHINE_LEARNING            REGRESSION  SAGEMAKER-SCIKIT-LEARN      0.23-1       sagemaker-scikit-learn\n",
       "15             MACHINE_LEARNING            REGRESSION                 XGBOOST       1.3-1                      xgboost\n",
       "16  NATURAL_LANGUAGE_PROCESSING             FILL_MASK                 PYTORCH       1.6.0              bert-base-cased\n",
       "20  NATURAL_LANGUAGE_PROCESSING             FILL_MASK                 PYTORCH       1.6.0            bert-base-uncased"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region)\n",
    "\n",
    "list_model_metadata_response = client.list_model_metadata(MaxResults=50)\n",
    "\n",
    "domains = []\n",
    "frameworks = []\n",
    "framework_versions = []\n",
    "tasks = []\n",
    "models = []\n",
    "\n",
    "for model_summary in list_model_metadata_response[\"ModelMetadataSummaries\"]:\n",
    "    domains.append(model_summary[\"Domain\"])\n",
    "    tasks.append(model_summary[\"Task\"])\n",
    "    models.append(model_summary[\"Model\"])\n",
    "    frameworks.append(model_summary[\"Framework\"])\n",
    "    framework_versions.append(model_summary[\"FrameworkVersion\"])\n",
    "\n",
    "data = {\n",
    "    \"Domain\": domains,\n",
    "    \"Task\": tasks,\n",
    "    \"Framework\": frameworks,\n",
    "    \"FrameworkVersion\": framework_versions,\n",
    "    \"Model\": models,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.colheader_justify\", \"center\")\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "\n",
    "display(df.sort_values(by=[\"Domain\", \"Task\", \"Framework\", \"FrameworkVersion\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
