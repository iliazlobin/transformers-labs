{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "Requirement already satisfied: transformers in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (4.39.2)\n",
      "Requirement already satisfied: filelock in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/izlobin/miniconda3/envs/pytorch/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/izlobin/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%pip install transformers\n",
    "!huggingface-cli login --token $HUGGING_FACE_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007eb76713bb4ae7851428ca9b119c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type phi to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef064d64d9344e38857809a2f4811911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.layer_norm.weight', 'encoder.block.10.layer.1.DenseReluDense.wi.weight', 'encoder.block.10.layer.1.DenseReluDense.wo.weight', 'encoder.block.10.layer.1.layer_norm.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.layer_norm.weight', 'encoder.block.11.layer.1.DenseReluDense.wi.weight', 'encoder.block.11.layer.1.DenseReluDense.wo.weight', 'encoder.block.11.layer.1.layer_norm.weight', 'encoder.block.12.layer.0.SelfAttention.k.weight', 'encoder.block.12.layer.0.SelfAttention.o.weight', 'encoder.block.12.layer.0.SelfAttention.q.weight', 'encoder.block.12.layer.0.SelfAttention.v.weight', 'encoder.block.12.layer.0.layer_norm.weight', 'encoder.block.12.layer.1.DenseReluDense.wi.weight', 'encoder.block.12.layer.1.DenseReluDense.wo.weight', 'encoder.block.12.layer.1.layer_norm.weight', 'encoder.block.13.layer.0.SelfAttention.k.weight', 'encoder.block.13.layer.0.SelfAttention.o.weight', 'encoder.block.13.layer.0.SelfAttention.q.weight', 'encoder.block.13.layer.0.SelfAttention.v.weight', 'encoder.block.13.layer.0.layer_norm.weight', 'encoder.block.13.layer.1.DenseReluDense.wi.weight', 'encoder.block.13.layer.1.DenseReluDense.wo.weight', 'encoder.block.13.layer.1.layer_norm.weight', 'encoder.block.14.layer.0.SelfAttention.k.weight', 'encoder.block.14.layer.0.SelfAttention.o.weight', 'encoder.block.14.layer.0.SelfAttention.q.weight', 'encoder.block.14.layer.0.SelfAttention.v.weight', 'encoder.block.14.layer.0.layer_norm.weight', 'encoder.block.14.layer.1.DenseReluDense.wi.weight', 'encoder.block.14.layer.1.DenseReluDense.wo.weight', 'encoder.block.14.layer.1.layer_norm.weight', 'encoder.block.15.layer.0.SelfAttention.k.weight', 'encoder.block.15.layer.0.SelfAttention.o.weight', 'encoder.block.15.layer.0.SelfAttention.q.weight', 'encoder.block.15.layer.0.SelfAttention.v.weight', 'encoder.block.15.layer.0.layer_norm.weight', 'encoder.block.15.layer.1.DenseReluDense.wi.weight', 'encoder.block.15.layer.1.DenseReluDense.wo.weight', 'encoder.block.15.layer.1.layer_norm.weight', 'encoder.block.16.layer.0.SelfAttention.k.weight', 'encoder.block.16.layer.0.SelfAttention.o.weight', 'encoder.block.16.layer.0.SelfAttention.q.weight', 'encoder.block.16.layer.0.SelfAttention.v.weight', 'encoder.block.16.layer.0.layer_norm.weight', 'encoder.block.16.layer.1.DenseReluDense.wi.weight', 'encoder.block.16.layer.1.DenseReluDense.wo.weight', 'encoder.block.16.layer.1.layer_norm.weight', 'encoder.block.17.layer.0.SelfAttention.k.weight', 'encoder.block.17.layer.0.SelfAttention.o.weight', 'encoder.block.17.layer.0.SelfAttention.q.weight', 'encoder.block.17.layer.0.SelfAttention.v.weight', 'encoder.block.17.layer.0.layer_norm.weight', 'encoder.block.17.layer.1.DenseReluDense.wi.weight', 'encoder.block.17.layer.1.DenseReluDense.wo.weight', 'encoder.block.17.layer.1.layer_norm.weight', 'encoder.block.18.layer.0.SelfAttention.k.weight', 'encoder.block.18.layer.0.SelfAttention.o.weight', 'encoder.block.18.layer.0.SelfAttention.q.weight', 'encoder.block.18.layer.0.SelfAttention.v.weight', 'encoder.block.18.layer.0.layer_norm.weight', 'encoder.block.18.layer.1.DenseReluDense.wi.weight', 'encoder.block.18.layer.1.DenseReluDense.wo.weight', 'encoder.block.18.layer.1.layer_norm.weight', 'encoder.block.19.layer.0.SelfAttention.k.weight', 'encoder.block.19.layer.0.SelfAttention.o.weight', 'encoder.block.19.layer.0.SelfAttention.q.weight', 'encoder.block.19.layer.0.SelfAttention.v.weight', 'encoder.block.19.layer.0.layer_norm.weight', 'encoder.block.19.layer.1.DenseReluDense.wi.weight', 'encoder.block.19.layer.1.DenseReluDense.wo.weight', 'encoder.block.19.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.20.layer.0.SelfAttention.k.weight', 'encoder.block.20.layer.0.SelfAttention.o.weight', 'encoder.block.20.layer.0.SelfAttention.q.weight', 'encoder.block.20.layer.0.SelfAttention.v.weight', 'encoder.block.20.layer.0.layer_norm.weight', 'encoder.block.20.layer.1.DenseReluDense.wi.weight', 'encoder.block.20.layer.1.DenseReluDense.wo.weight', 'encoder.block.20.layer.1.layer_norm.weight', 'encoder.block.21.layer.0.SelfAttention.k.weight', 'encoder.block.21.layer.0.SelfAttention.o.weight', 'encoder.block.21.layer.0.SelfAttention.q.weight', 'encoder.block.21.layer.0.SelfAttention.v.weight', 'encoder.block.21.layer.0.layer_norm.weight', 'encoder.block.21.layer.1.DenseReluDense.wi.weight', 'encoder.block.21.layer.1.DenseReluDense.wo.weight', 'encoder.block.21.layer.1.layer_norm.weight', 'encoder.block.22.layer.0.SelfAttention.k.weight', 'encoder.block.22.layer.0.SelfAttention.o.weight', 'encoder.block.22.layer.0.SelfAttention.q.weight', 'encoder.block.22.layer.0.SelfAttention.v.weight', 'encoder.block.22.layer.0.layer_norm.weight', 'encoder.block.22.layer.1.DenseReluDense.wi.weight', 'encoder.block.22.layer.1.DenseReluDense.wo.weight', 'encoder.block.22.layer.1.layer_norm.weight', 'encoder.block.23.layer.0.SelfAttention.k.weight', 'encoder.block.23.layer.0.SelfAttention.o.weight', 'encoder.block.23.layer.0.SelfAttention.q.weight', 'encoder.block.23.layer.0.SelfAttention.v.weight', 'encoder.block.23.layer.0.layer_norm.weight', 'encoder.block.23.layer.1.DenseReluDense.wi.weight', 'encoder.block.23.layer.1.DenseReluDense.wo.weight', 'encoder.block.23.layer.1.layer_norm.weight', 'encoder.block.24.layer.0.SelfAttention.k.weight', 'encoder.block.24.layer.0.SelfAttention.o.weight', 'encoder.block.24.layer.0.SelfAttention.q.weight', 'encoder.block.24.layer.0.SelfAttention.v.weight', 'encoder.block.24.layer.0.layer_norm.weight', 'encoder.block.24.layer.1.DenseReluDense.wi.weight', 'encoder.block.24.layer.1.DenseReluDense.wo.weight', 'encoder.block.24.layer.1.layer_norm.weight', 'encoder.block.25.layer.0.SelfAttention.k.weight', 'encoder.block.25.layer.0.SelfAttention.o.weight', 'encoder.block.25.layer.0.SelfAttention.q.weight', 'encoder.block.25.layer.0.SelfAttention.v.weight', 'encoder.block.25.layer.0.layer_norm.weight', 'encoder.block.25.layer.1.DenseReluDense.wi.weight', 'encoder.block.25.layer.1.DenseReluDense.wo.weight', 'encoder.block.25.layer.1.layer_norm.weight', 'encoder.block.26.layer.0.SelfAttention.k.weight', 'encoder.block.26.layer.0.SelfAttention.o.weight', 'encoder.block.26.layer.0.SelfAttention.q.weight', 'encoder.block.26.layer.0.SelfAttention.v.weight', 'encoder.block.26.layer.0.layer_norm.weight', 'encoder.block.26.layer.1.DenseReluDense.wi.weight', 'encoder.block.26.layer.1.DenseReluDense.wo.weight', 'encoder.block.26.layer.1.layer_norm.weight', 'encoder.block.27.layer.0.SelfAttention.k.weight', 'encoder.block.27.layer.0.SelfAttention.o.weight', 'encoder.block.27.layer.0.SelfAttention.q.weight', 'encoder.block.27.layer.0.SelfAttention.v.weight', 'encoder.block.27.layer.0.layer_norm.weight', 'encoder.block.27.layer.1.DenseReluDense.wi.weight', 'encoder.block.27.layer.1.DenseReluDense.wo.weight', 'encoder.block.27.layer.1.layer_norm.weight', 'encoder.block.28.layer.0.SelfAttention.k.weight', 'encoder.block.28.layer.0.SelfAttention.o.weight', 'encoder.block.28.layer.0.SelfAttention.q.weight', 'encoder.block.28.layer.0.SelfAttention.v.weight', 'encoder.block.28.layer.0.layer_norm.weight', 'encoder.block.28.layer.1.DenseReluDense.wi.weight', 'encoder.block.28.layer.1.DenseReluDense.wo.weight', 'encoder.block.28.layer.1.layer_norm.weight', 'encoder.block.29.layer.0.SelfAttention.k.weight', 'encoder.block.29.layer.0.SelfAttention.o.weight', 'encoder.block.29.layer.0.SelfAttention.q.weight', 'encoder.block.29.layer.0.SelfAttention.v.weight', 'encoder.block.29.layer.0.layer_norm.weight', 'encoder.block.29.layer.1.DenseReluDense.wi.weight', 'encoder.block.29.layer.1.DenseReluDense.wo.weight', 'encoder.block.29.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.30.layer.0.SelfAttention.k.weight', 'encoder.block.30.layer.0.SelfAttention.o.weight', 'encoder.block.30.layer.0.SelfAttention.q.weight', 'encoder.block.30.layer.0.SelfAttention.v.weight', 'encoder.block.30.layer.0.layer_norm.weight', 'encoder.block.30.layer.1.DenseReluDense.wi.weight', 'encoder.block.30.layer.1.DenseReluDense.wo.weight', 'encoder.block.30.layer.1.layer_norm.weight', 'encoder.block.31.layer.0.SelfAttention.k.weight', 'encoder.block.31.layer.0.SelfAttention.o.weight', 'encoder.block.31.layer.0.SelfAttention.q.weight', 'encoder.block.31.layer.0.SelfAttention.v.weight', 'encoder.block.31.layer.0.layer_norm.weight', 'encoder.block.31.layer.1.DenseReluDense.wi.weight', 'encoder.block.31.layer.1.DenseReluDense.wo.weight', 'encoder.block.31.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.layer_norm.weight', 'encoder.block.6.layer.1.DenseReluDense.wi.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'encoder.block.6.layer.1.layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.DenseReluDense.wi.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'encoder.block.7.layer.1.layer_norm.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.layer_norm.weight', 'encoder.block.8.layer.1.DenseReluDense.wi.weight', 'encoder.block.8.layer.1.DenseReluDense.wo.weight', 'encoder.block.8.layer.1.layer_norm.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.layer_norm.weight', 'encoder.block.9.layer.1.DenseReluDense.wi.weight', 'encoder.block.9.layer.1.DenseReluDense.wo.weight', 'encoder.block.9.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1583566848\n",
      "Trainable Parameters: 1583566848\n",
      "Estimated model memory: 5.90 GB\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Parameters: {total_trainable_params}\")\n",
    "\n",
    "total_memory_GB = total_params * 4 / (1024**3)\n",
    "print(f\"Estimated model memory: {total_memory_GB:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def print_prime(n):\n",
      "   \"\"\"\n",
      "   Print all primes between 1 and n\n",
      "   \"\"\"\n",
      "   for i in range(2, n+1):\n",
      "       for j in range(2, i):\n",
      "           if i % j == 0:\n",
      "               break\n",
      "       else:\n",
      "           print(i)\n",
      "\n",
      "print_prime(20)\n",
      "```\n",
      "\n",
      "## Exercises\n",
      "\n",
      "1. Write a Python function that takes a list of numbers and returns the sum of all even numbers in the list.\n",
      "\n",
      "```python\n",
      "def sum_even(numbers):\n",
      "    \"\"\"\n",
      "    Returns the sum of all even numbers in the list\n",
      "    \"\"\"\n",
      "    return sum(filter(lambda x: x % 2 == 0, numbers))\n",
      "\n",
      "print(sum_even([1, 2, 3, 4, 5, 6])) # Output: 12\n",
      "```\n",
      "\n",
      "2. Write a Python function that takes\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    '''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''',\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=False,\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>pacDuration gagontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoontoonto\n"
     ]
    }
   ],
   "source": [
    "# pipe = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device_map=\"auto\", max_length=128)\n",
    "# result = pipe(\"Fix grammatical errors in this sentence: When I grow up, I start to understand what he said is quite right\")\n",
    "# print(f\"Result: {result}\")\n",
    "\n",
    "prompt = \"translate English to German: How old are you?\"\n",
    "# prompt = \"Fix grammatical errors in this sentence: When I grow up, I start to understand what he said is quite right\"\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
