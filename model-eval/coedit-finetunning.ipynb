{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/izlobin/.local/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: evaluate in /home/izlobin/.local/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: filelock in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: dill in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/izlobin/.local/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/izlobin/.local/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/izlobin/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/izlobin/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/izlobin/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/izlobin/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/izlobin/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /home/izlobin/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: absl-py in /home/izlobin/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: rouge_score in /home/izlobin/.local/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: click in /home/izlobin/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/izlobin/.local/lib/python3.10/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/izlobin/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/izlobin/.local/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: numpy in /home/izlobin/.local/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/izlobin/.local/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bleu in /home/izlobin/.local/lib/python3.10/site-packages (0.3)\n",
      "Requirement already satisfied: sacrebleu in /home/izlobin/.local/lib/python3.10/site-packages (2.4.2)\n",
      "Requirement already satisfied: efficiency in /home/izlobin/.local/lib/python3.10/site-packages (from bleu) (2.0)\n",
      "Requirement already satisfied: portalocker in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: regex in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/izlobin/.local/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\n",
      "Requirement already satisfied: pandas in /home/izlobin/.local/lib/python3.10/site-packages (from efficiency->bleu) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->efficiency->bleu) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->efficiency->bleu) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->efficiency->bleu) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/izlobin/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->efficiency->bleu) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sacremoses in /home/izlobin/.local/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /home/izlobin/.local/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\n",
      "Requirement already satisfied: click in /home/izlobin/.local/lib/python3.10/site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/izlobin/.local/lib/python3.10/site-packages (from sacremoses) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /home/izlobin/.local/lib/python3.10/site-packages (from sacremoses) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /home/izlobin/.local/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /home/izlobin/.local/lib/python3.10/site-packages (from scipy) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece in /home/izlobin/.local/lib/python3.10/site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optimum in /home/izlobin/.local/lib/python3.10/site-packages (1.18.1)\n",
      "Requirement already satisfied: auto-gptq in /home/izlobin/.local/lib/python3.10/site-packages (0.7.1)\n",
      "Requirement already satisfied: coloredlogs in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: transformers<4.40.0,>=4.26.0 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers[sentencepiece]<4.40.0,>=4.26.0->optimum) (4.39.3)\n",
      "Requirement already satisfied: torch>=1.11 in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (2.2.2)\n",
      "Requirement already satisfied: packaging in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (24.0)\n",
      "Requirement already satisfied: numpy in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (0.22.2)\n",
      "Requirement already satisfied: datasets in /home/izlobin/.local/lib/python3.10/site-packages (from optimum) (2.18.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (0.28.0)\n",
      "Requirement already satisfied: sentencepiece in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\n",
      "Requirement already satisfied: rouge in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: gekko in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (1.1.1)\n",
      "Requirement already satisfied: safetensors in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (0.4.2)\n",
      "Requirement already satisfied: peft>=0.5.0 in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (0.10.0)\n",
      "Requirement already satisfied: tqdm in /home/izlobin/.local/lib/python3.10/site-packages (from auto-gptq) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/izlobin/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/izlobin/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/izlobin/.local/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/izlobin/.local/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/izlobin/.local/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/izlobin/.local/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/izlobin/.local/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/izlobin/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/izlobin/.local/lib/python3.10/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum) (0.15.2)\n",
      "Requirement already satisfied: protobuf in /home/izlobin/.local/lib/python3.10/site-packages (from transformers[sentencepiece]<4.40.0,>=4.26.0->optimum) (5.26.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/izlobin/.local/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/izlobin/.local/lib/python3.10/site-packages (from datasets->optimum) (3.9.4)\n",
      "Requirement already satisfied: six in /home/izlobin/.local/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/izlobin/.local/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/izlobin/.local/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/izlobin/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/izlobin/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/izlobin/.local/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/izlobin/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/izlobin/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/izlobin/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/izlobin/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/izlobin/.local/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/izlobin/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# %%script echo skipping\n",
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%pip install transformers evaluate\n",
    "%pip install nltk absl-py rouge_score\n",
    "%pip install bleu sacrebleu\n",
    "%pip install sacremoses\n",
    "%pip install scipy\n",
    "%pip install sentencepiece\n",
    "%pip install optimum auto-gptq\n",
    "%pip install scikit-learn\n",
    "!huggingface-cli login --token $HUGGING_FACE_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izlobin/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Device: cuda'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")\n",
    "from utils.metric import calculate_scores\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pprint(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading coedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Device: cuda'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# model = T5ForConditionalGeneration.from_pretrained(model_name)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(model_name)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     device_map=\"auto\",\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model_name = \"grammarly/coedit-large\"\n",
    "model_name = \"google/flan-t5-large\"\n",
    "\n",
    "# model_name = \"google/gemma-2b-it\"\n",
    "# model_name = \"google/gemma-7b-it\"\n",
    "# model_name = \"google/gemma-7b\"\n",
    "\n",
    "model_alias = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     # torch_dtype=torch.float16,\n",
    "#     # revision=\"float16\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading llama-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Loading llama-2\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_name = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "# model_name = \"TheBloke/Nous-Hermes-Llama-2-7B-GPTQ\"\n",
    "\n",
    "model_alias = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "model = LlamaForCausalLM.from_pretrained(model_name, device_map=0)\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix grammatical errors in this sentence: I goes to work every noning. nobody\n",
      "I goes to work every day.\n"
     ]
    }
   ],
   "source": [
    "# reference = \" Some even provided gateways, such as UFGATE, by which members could send / receive e-mail to and from the Internet via UUCP, and many FidoNet discussion groups were shared via gateway to Usenet.\"\n",
    "input_text = \"Fix grammatical errors in this sentence: I goes to work every noning.\"\n",
    "# input_ids = tokenizer(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **input_ids,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=256,\n",
    ")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring memory (VRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total/trainable params: 262410240/262410240\n",
      "{'total_memory': 10736893952, 'memory_used': 5499146240, 'cuda_allocated': 4112738304, 'cuda_reserved': 4427087872, 'ram_usage': 8382889984}\n",
      "{'total_memory': '10.00', 'memory_used': '5.12', 'cuda_allocated': '3.83', 'cuda_reserved': '4.12', 'ram_usage': '7.81'}\n",
      "total/used/cuda/res/ram(Gb): 10.00/5.12/3.83/4.12/7.81\n",
      "Total/used/available memory (Gb): 10.00/{utilization['memory_used']/1024**3:.2f}/{available_memory/1024**3:.2f}\n",
      "Recommended/actual fraction: 0.49/0.95\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "from utils.monitoring import calculate_utilization, format_utilization_narrow, print_utilization\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total/trainable params: {total_params}/{total_trainable_params}')\n",
    "\n",
    "utilization = calculate_utilization()\n",
    "print(utilization)\n",
    "utilization_str = format_utilization_narrow(utilization)\n",
    "print(utilization_str)\n",
    "print(\n",
    "    f\"total/used/cuda/res/ram(Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "    f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']}\"\n",
    ")\n",
    "\n",
    "actual_fraction = 0.95\n",
    "available_memory = utilization['total_memory'] - utilization['memory_used']\n",
    "recommended_fraction = available_memory / utilization['total_memory']\n",
    "torch.cuda.set_per_process_memory_fraction(actual_fraction, 0)\n",
    "\n",
    "print(\n",
    "    f\"Total/used/available memory (Gb): {utilization['total_memory']/1024**3:.2f}/\"\n",
    "    \"{utilization['memory_used']/1024**3:.2f}/{available_memory/1024**3:.2f}\"\n",
    ")\n",
    "print(f'Recommended/actual fraction: {recommended_fraction:.2f}/{actual_fraction:.2f}')\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.empty(utilization['total_memory'] // 2, dtype=torch.int8, device='cuda')\n",
    "# print_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I does work.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# reference = \" Some even provided gateways, such as UFGATE, by which members could send / receive e-mail to and from the Internet via UUCP, and many FidoNet discussion groups were shared via gateway to Usenet.\"\n",
    "input_text = \"Fix grammatical errors in this sentence: I does work.\"\n",
    "# input_ids = tokenizer(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'task', 'src', 'tgt'],\n",
      "        num_rows: 69071\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['_id', 'task', 'src', 'tgt'],\n",
      "        num_rows: 1712\n",
      "    })\n",
      "})\n",
      "{'train', 'validation'}\n",
      "{'simplification', 'coherence', 'gec', 'clarity', 'neutralize', 'paraphrase'}\n"
     ]
    }
   ],
   "source": [
    "# api = HfApi()\n",
    "# coedit_info = api.dataset_info(\"grammarly/coedit\")\n",
    "# pprint(coedit_info)\n",
    "\n",
    "grammarly_dataset = load_dataset(\"grammarly/coedit\")\n",
    "pprint(grammarly_dataset)\n",
    "\n",
    "unique_categories = set(grammarly_dataset)\n",
    "pprint(unique_categories)\n",
    "\n",
    "unique_tasks = set(grammarly_dataset[\"train\"][\"task\"])\n",
    "pprint(unique_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gec] Fix grammar in this sentence\n",
      "src: Be careful man!\n",
      "tgt: Be careful, man!\n",
      "[gec] Fix grammaticality in this sentence\n",
      "src: Dear friends, I hope you should correctly but I can gives you some opinion, I guess that is a good idea if you go to a small schools, under you can met a lot on people and there are more closed friend of course you cannot like that opcion if you like the biggest once, so in that ways you can go from the other school.\n",
      "tgt: Dear friend, I hope you choose correctly but I can give you my opinion. I guess that it's a good idea if you go to a small school, because you can meet a lot of people and make more close friends of course you won't like that option if you like the bigger one, so in that case you should go to the other school.\n"
     ]
    }
   ],
   "source": [
    "def get_samples(dataset, category=\"validation\", task=\"gec\", num_samples=1, seed=42):\n",
    "    return dataset[category].shuffle(seed=seed).filter(lambda item: item[\"task\"] == task).select(range(num_samples))\n",
    "\n",
    "def print_samples(samples) -> None:\n",
    "    for item in samples:\n",
    "        pfx, src = item[\"src\"].split(\": \", 1)\n",
    "        print(f\"[{item['task']}] {pfx}\")\n",
    "        print(f\"src: {src}\")\n",
    "        print(f\"tgt: {item['tgt']}\")\n",
    "\n",
    "\n",
    "print_samples(get_samples(grammarly_dataset, num_samples=2))\n",
    "\n",
    "# input_ids = tokenizer(item[\"task\"], return_tensors=\"pt\").input_ids.to(device)\n",
    "# outputs = model.generate(input_ids, max_length=256)\n",
    "# corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# return {\"processed\": corrected}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
