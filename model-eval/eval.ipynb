{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/izlobin/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "!huggingface-cli login --token $HUGGING_FACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install nltk absl-py rouge_score\n",
    "# %pip install bleu sacrebleu\n",
    "# %pip install sacremoses\n",
    "# %pip install scipy\n",
    "# %pip install sentencepiece\n",
    "# %pip install optimum auto-gptq\n",
    "# %pip install scikit-learn\n",
    "# %pip install einops\n",
    "# %pip install bitsandbytes\n",
    "# %pip install huggingface_hub\n",
    "# %pip install transformers evaluate gradio datasets chardet cchardet librosa ipython sentencepiece plotly phonemizer\n",
    "# %pip install accelerate\n",
    "# %pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "'Device: cuda'\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BartForCausalLM,\n",
    "    BartModel,\n",
    "    BartTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    T5TokenizerFast,\n",
    ")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.dataset import get_iterater_samples_simplified, get_iterater_samples_with_instruction\n",
    "from utils.metric import calculate_scores\n",
    "from utils.monitoring import calculate_utilization, format_utilization_narrow, print_utilization\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading custom gpt2 / gpt2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: gpt2-large,model_id: openai-community/gpt2-large,model_path: openai-community_gpt2-large\n",
      "<class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n",
      "50256\n",
      "50256\n",
      "left\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"padding_side\": \"left\"\n",
      "}\n",
      "\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1280)\n",
      "    (wpe): Embedding(1024, 1280)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-35): 36 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"gpt2-large\"\n",
    "model_repo = f\"openai-community\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    ")\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"\n",
    "print(type(tokenizer))\n",
    "# print(tokenizer.add_eos_token)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)\n",
    "\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", max_memory={0: \"80GiB\"})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "\n",
    "model.generation_config.max_new_tokens = 0\n",
    "# model.generation_config.new_tokens = 350\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "model.generation_config.padding_side = \"left\"\n",
    "\n",
    "print(model.generation_config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: gpt2-large-coedit,model_id: iliazlobin/gpt2-large-coedit,model_path: iliazlobin_gpt2-large-coedit\n",
      "<class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n",
      "50256\n",
      "50256\n",
      "left\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "GPT2Config {\n",
      "  \"_name_or_path\": \"iliazlobin/gpt2-large-coedit\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1280,\n",
      "  \"n_head\": 20,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 36,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"max_new_tokens\": 350,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"padding_side\": \"left\"\n",
      "}\n",
      "\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1280)\n",
      "    (wpe): Embedding(1024, 1280)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-35): 36 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"gpt2-large-coedit\"\n",
    "model_repo = f\"iliazlobin\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    ")\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"\n",
    "print(type(tokenizer))\n",
    "# print(tokenizer.add_eos_token)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)\n",
    "\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", max_memory={0: \"80GiB\"})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "print(model.config)\n",
    "\n",
    "# model.generation_config.max_new_tokens = 350\n",
    "# model.generation_config.new_tokens = 350\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "model.generation_config.padding_side = \"left\"\n",
    "\n",
    "print(model.generation_config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"gpt2-large\"\n",
    "model_repo = f\"openai-community\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    ")\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "print(type(tokenizer))\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=0)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "# print(model.config)\n",
    "# print(model)\n",
    "\n",
    "trained_model_name = \"gpt2-large-bnb8-coedit\"\n",
    "trained_model_repo = f\"iliazlobin\"\n",
    "trained_model_id = f\"{trained_model_repo}/{trained_model_name}\"\n",
    "trained_model_checkpoint = f\"{trained_model_repo}/{trained_model_name}\"\n",
    "trained_model_path = f\"{trained_model_repo}_{trained_model_name}\"\n",
    "print(\n",
    "    f\"trained_model_name: {trained_model_name},\"\n",
    "    f\"trained_model_id: {trained_model_id},\"\n",
    "    f\"trained_model_path: {trained_model_path}\"\n",
    ")\n",
    "\n",
    "\n",
    "adapters_path = f\"../model-train/model-{trained_model_repo}_{trained_model_name}\"\n",
    "peft_model = PeftModel.from_pretrained(model, adapters_path)\n",
    "\n",
    "print(type(peft_model))\n",
    "print(peft_model.config)\n",
    "print(peft_model)\n",
    "\n",
    "origin_model = model\n",
    "model = peft_model\n",
    "model_name = trained_model_name\n",
    "model_repo = trained_model_repo\n",
    "model_id = trained_model_id\n",
    "model_checkpoint = trained_model_checkpoint\n",
    "model_path = trained_model_path\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading BART\n",
    "* https://huggingface.co/facebook/bart-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: bart-large,model_id: facebook/bart-large,model_path: facebook_bart-large\n",
      "<class 'transformers.models.bart.tokenization_bart.BartTokenizer'>\n",
      "<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BartForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"bart-large\"\n",
    "model_repo = f\"facebook\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_eos_token = True\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(type(tokenizer))\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: bart-large-coedit,model_id: iliazlobin/bart-large-coedit,model_path: iliazlobin_bart-large-coedit\n",
      "<class 'transformers.models.bart.tokenization_bart.BartTokenizer'>\n",
      "<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BartForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"bart-large-coedit\"\n",
    "model_repo = f\"iliazlobin\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_eos_token = True\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(type(tokenizer))\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=0, max_memory={0: \"20GIB\"})\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=0)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bart.tokenization_bart.BartTokenizer'>\n",
      "<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>\n",
      "BartConfig {\n",
      "  \"_name_or_path\": \"iliazlobin/bart-grammarly\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"iliazlobin/bart-grammarly\"\n",
    "model_alias = model_name.replace(\"/\", \"_\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "# model = BartModel.from_pretrained(model_name)\n",
    "# model = BartForCausalLM.from_pretrained(model_name, device_map=0)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, device_map=0)\n",
    "\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading google/t5-large\n",
    "* https://huggingface.co/google-t5/t5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: t5-large,model_id: google-t5/t5-large,model_path: google-t5_t5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izlobin/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n",
      "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n",
      "T5Config {\n",
      "  \"_name_or_path\": \"google-t5/t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-large\"\n",
    "model_repo = f\"google-t5\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_id)\n",
    "# tokenizer.add_eos_token = True\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"right\"\n",
    "print(type(tokenizer))\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=0, max_memory={0: \"20GIB\"})\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id, device_map=0)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "print(type(model))\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading grammarly/coedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: coedit-large,model_id: grammarly/coedit-large,model_path: grammarly_coedit-large\n",
      "<class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n",
      "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n",
      "T5Config {\n",
      "  \"_name_or_path\": \"grammarly/coedit-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"coedit-large\"\n",
    "model_repo = f\"grammarly\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(type(tokenizer))\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: gemma-2b-it,model_id: google/gemma-2b-it,model_path: google_gemma-2b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>\n",
      "1\n",
      "0\n",
      "left\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55ada2ac96a473491c429537fe86097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gemma.modeling_gemma.GemmaForCausalLM'>\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "GemmaForCausalLM(\n",
      "  (model): GemmaModel(\n",
      "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): GemmaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
      "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): GemmaRMSNorm()\n",
      "        (post_attention_layernorm): GemmaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): GemmaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"gemma-2b-it\"\n",
    "# model_name = \"gemma-7b-it\"\n",
    "# model_name = \"gemma-7b\"\n",
    "model_repo = f\"google\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    ")\n",
    "# tokenizer.add_eos_token = True\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"left\"\n",
    "print(type(tokenizer))\n",
    "# print(tokenizer.add_eos_token)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", max_memory={0: \"80GiB\"})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "\n",
    "# model.generation_config.max_new_tokens = 350\n",
    "# # model.generation_config.new_tokens = 350\n",
    "# model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "# model.generation_config.padding_side = \"left\"\n",
    "\n",
    "print(model.generation_config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Phi-2\n",
    "* https://huggingface.co/microsoft/phi-2\n",
    "* https://huggingface.co/TheBloke/phi-2-GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izlobin/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.eos_token: <|endoftext|>\n",
      "PhiConfig {\n",
      "  \"_name_or_path\": \"TheBloke/phi-2-GPTQ\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"PhiForCausalLM\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"TheBloke/phi-2-GPTQ--configuration_phi.PhiConfig\",\n",
      "    \"AutoModelForCausalLM\": \"TheBloke/phi-2-GPTQ--modeling_phi.PhiForCausalLM\"\n",
      "  },\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"flash_attn\": false,\n",
      "  \"flash_rotary\": false,\n",
      "  \"fused_dense\": false,\n",
      "  \"img_processor\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"phi-msft\",\n",
      "  \"n_embd\": 2560,\n",
      "  \"n_head\": 32,\n",
      "  \"n_head_kv\": null,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 32,\n",
      "  \"n_positions\": 2048,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"batch_size\": 1,\n",
      "    \"bits\": 4,\n",
      "    \"block_name_to_quantize\": null,\n",
      "    \"cache_block_outputs\": true,\n",
      "    \"damp_percent\": 0.1,\n",
      "    \"dataset\": null,\n",
      "    \"desc_act\": true,\n",
      "    \"exllama_config\": {\n",
      "      \"version\": 1\n",
      "    },\n",
      "    \"group_size\": 128,\n",
      "    \"max_input_length\": null,\n",
      "    \"model_seqlen\": null,\n",
      "    \"module_name_preceding_first_block\": null,\n",
      "    \"modules_in_block_to_quantize\": null,\n",
      "    \"pad_token_id\": null,\n",
      "    \"quant_method\": \"gptq\",\n",
      "    \"sym\": true,\n",
      "    \"tokenizer\": null,\n",
      "    \"true_sequential\": true,\n",
      "    \"use_cuda_fp16\": false,\n",
      "    \"use_exllama\": true\n",
      "  },\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"rotary_dim\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"phi-2\"\n",
    "model_repo = f\"microsoft\"\n",
    "model_id = f\"{model_repo}/{model_name}\"\n",
    "model_checkpoint = f\"{model_repo}/{model_name}\"\n",
    "model_path = f\"{model_repo}_{model_name}\"\n",
    "print(f\"model_name: {model_name},\" f\"model_id: {model_id},\" f\"model_path: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_fast=True,\n",
    ")\n",
    "# tokenizer.add_eos_token = True\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"left\"\n",
    "print(type(tokenizer))\n",
    "# print(tokenizer.add_eos_token)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", max_memory={0: \"80GiB\"})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0)\n",
    "print(type(model))\n",
    "\n",
    "# model.generation_config.max_new_tokens = 350\n",
    "# # model.generation_config.new_tokens = 350\n",
    "# model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "# model.generation_config.padding_side = \"left\"\n",
    "\n",
    "print(model.generation_config)\n",
    "print(model.config)\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total/trainable params: {total_params}/{total_trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading mixtral-8x7B\n",
    "* https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\n",
    "* https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ\n",
    "\n",
    "Quantization\n",
    "* https://medium.com/@rakeshrajpurohit/model-quantization-with-hugging-face-transformers-and-bitsandbytes-integration-b4c9983e8996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# from transformers import BitsAndBytesConfig\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# quantization_config = BitsAndBytesConfig(load_in_4bit=4)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(f\"model.config.eos_token_id: {model.config.eos_token_id}\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# eos_token_id = 50256 # https://huggingface.co/microsoft/phi-2/blob/main/config.json\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     29\u001b[0m     model_name,\n\u001b[1;32m     30\u001b[0m     use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(f\"tokenizer.eos_token: {tokenizer.eos_token}\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# tokenizer.pad_token = tokenizer.eos_token\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3039\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_quantized \u001b[38;5;129;01mor\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_quantized:\n\u001b[0;32m-> 3039\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoHfQuantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_quantization_configs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3043\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m quantization_config\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/quantizers/auto.py:153\u001b[0m, in \u001b[0;36mAutoHfQuantizer.merge_quantization_configs\u001b[0;34m(cls, quantization_config, quantization_config_from_args)\u001b[0m\n\u001b[1;32m    149\u001b[0m     quantization_config \u001b[38;5;241m=\u001b[39m AutoQuantizationConfig\u001b[38;5;241m.\u001b[39mfrom_dict(quantization_config)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quantization_config, (GPTQConfig, AwqConfig)) \u001b[38;5;129;01mand\u001b[39;00m quantization_config_from_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# special case for GPTQ / AWQ config collision\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     loading_attr_dict \u001b[38;5;241m=\u001b[39m \u001b[43mquantization_config_from_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loading_attributes\u001b[49m()\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr, val \u001b[38;5;129;01min\u001b[39;00m loading_attr_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(quantization_config, attr, val)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'"
     ]
    }
   ],
   "source": [
    "# model_name = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "model_name = 'TheBloke/Mixtral-8x7B-v0.1-GPTQ'\n",
    "model_alias = model_name.replace('/', '_')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "# quantization_config = BitsAndBytesConfig(load_in_4bit=4)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=0,\n",
    "#     # torch_dtype=torch.float16,\n",
    "#     # load_in_4bit=True,\n",
    "#     # quantization_config=quantization_config,\n",
    "# )\n",
    "\n",
    "# print(f\"model.config.eos_token_id: {model.config.eos_token_id}\")\n",
    "# eos_token_id = 50256 # https://huggingface.co/microsoft/phi-2/blob/main/config.json\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=0,\n",
    "    load_in_4bit=True,\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "# print(f\"tokenizer.eos_token: {tokenizer.eos_token}\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "print(model.config)\n",
    "\n",
    "# text = 'Hello my name is'\n",
    "# inputs = tokenizer(text, return_tensors='pt')\n",
    "# outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading llama-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/izlobin/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "The cos_cached attribute will be removed in 4.39. Bear in mind that its contents changed in v4.38. Use the forward method of RoPE from now on instead. It is not used in the `LlamaAttention` class\n",
      "The sin_cached attribute will be removed in 4.39. Bear in mind that its contents changed in v4.38. Use the forward method of RoPE from now on instead. It is not used in the `LlamaAttention` class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>\n",
      "<class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
      "LlamaConfig {\n",
      "  \"_name_or_path\": \"TheBloke/Llama-2-7B-GPTQ\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_length\": 4096,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"batch_size\": 1,\n",
      "    \"bits\": 4,\n",
      "    \"block_name_to_quantize\": null,\n",
      "    \"cache_block_outputs\": true,\n",
      "    \"damp_percent\": 0.01,\n",
      "    \"dataset\": null,\n",
      "    \"desc_act\": false,\n",
      "    \"exllama_config\": {\n",
      "      \"version\": 1\n",
      "    },\n",
      "    \"group_size\": 128,\n",
      "    \"max_input_length\": null,\n",
      "    \"model_seqlen\": null,\n",
      "    \"module_name_preceding_first_block\": null,\n",
      "    \"modules_in_block_to_quantize\": null,\n",
      "    \"pad_token_id\": null,\n",
      "    \"quant_method\": \"gptq\",\n",
      "    \"sym\": true,\n",
      "    \"tokenizer\": null,\n",
      "    \"true_sequential\": true,\n",
      "    \"use_cuda_fp16\": false,\n",
      "    \"use_exllama\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_name = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "# model_name = \"TheBloke/Nous-Hermes-Llama-2-7B-GPTQ\"\n",
    "model_alias = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "model = LlamaForCausalLM.from_pretrained(model_name, device_map=0)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n",
    "print(model.config)\n",
    "\n",
    "# from auto_gptq import exllama_set_max_input_length\n",
    "# model = exllama_set_max_input_length(model, max_input_length=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammarly/coedit dataset\n",
    "* https://huggingface.co/datasets/grammarly/coedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set {'gec', 'clarity', 'neutralize', 'coherence', 'simplification', 'paraphrase'}\n",
      "Dataset({\n",
      "    features: ['task', 'input', 'reference', 'references'],\n",
      "    num_rows: 63703\n",
      "})\n",
      "test set {'gec', 'clarity', 'neutralize', 'coherence', 'simplification', 'paraphrase'}\n",
      "Dataset({\n",
      "    features: ['task', 'input', 'reference', 'references'],\n",
      "    num_rows: 7080\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['task', 'input', 'reference', 'references', 'request', 'prompt'],\n",
      "        num_rows: 63703\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['task', 'input', 'reference', 'references', 'request', 'prompt'],\n",
      "        num_rows: 7080\n",
      "    })\n",
      "})\n",
      "{'task': 'gec', 'input': 'Remove all grammatical errors from this text: For example, countries with a lot of deserts can terraform their desert to increase their habitable land and using irrigation to provide clean water to the desert.', 'reference': 'For example, countries with a lot of deserts can transform their desert to increase their habitable land and use irrigation to provide clean water to the desert.', 'references': ['For example, countries with a lot of deserts can transform their desert to increase their habitable land and use irrigation to provide clean water to the desert.'], 'request': 'Remove all grammatical errors from this text: For example, countries with a lot of deserts can terraform their desert to increase their habitable land and using irrigation to provide clean water to the desert.\\nResponse:', 'prompt': 'Remove all grammatical errors from this text: For example, countries with a lot of deserts can terraform their desert to increase their habitable land and using irrigation to provide clean water to the desert.\\nResponse:For example, countries with a lot of deserts can transform their desert to increase their habitable land and use irrigation to provide clean water to the desert.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, load_dataset\n",
    "\n",
    "# full_dataset = load_dataset(\"grammarly/coedit\")\n",
    "# print(full_dataset)\n",
    "\n",
    "# train_dataset = load_dataset(\"grammarly/coedit\", split=\"train[:50000]\")\n",
    "# test_dataset = load_dataset(\"grammarly/coedit\", split=\"train[10000:]\")\n",
    "# # test_dataset = load_dataset(\"grammarly/coedit\", split=\"validation\")\n",
    "\n",
    "all_dataset = load_dataset(\"grammarly/coedit\", split=\"train+validation\")\n",
    "# print(all_dataset)\n",
    "\n",
    "# print()\n",
    "# print(f\"train set {set(all_dataset['task'])}\")\n",
    "# print(f\"total len: {len(all_dataset)}\")\n",
    "# print(f\"gec len: {len(all_dataset.filter(lambda x: x['task'] == 'gec'))}\")\n",
    "# print(f\"simplification len: {len(all_dataset.filter(lambda x: x['task'] == 'simplification'))}\")\n",
    "# print(f\"clarity len: {len(all_dataset.filter(lambda x: x['task'] == 'clarity'))}\")\n",
    "# print(f\"coherence len: {len(all_dataset.filter(lambda x: x['task'] == 'coherence'))}\")\n",
    "# print(f\"paraphrase len: {len(all_dataset.filter(lambda x: x['task'] == 'paraphrase'))}\")\n",
    "# print(f\"neutralize len: {len(all_dataset.filter(lambda x: x['task'] == 'neutralize'))}\")\n",
    "# print()\n",
    "\n",
    "# train_ratio = 0.01\n",
    "# test_ratio = 0.001\n",
    "# train_ratio = 0.1\n",
    "# test_ratio = 0.01\n",
    "train_ratio = 0.9\n",
    "test_ratio = 0.1\n",
    "\n",
    "gec_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"gec\")\n",
    "train_gec_dataset = gec_dataset.select(range(0, int(train_ratio * len(gec_dataset))))\n",
    "test_gec_dataset = gec_dataset.select(range(int((1 - test_ratio) * len(gec_dataset)), len(gec_dataset)))\n",
    "\n",
    "simplification_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"simplification\")\n",
    "train_simplification_dataset = simplification_dataset.select(range(0, int(train_ratio * len(simplification_dataset))))\n",
    "test_simplification_dataset = simplification_dataset.select(\n",
    "    range(int((1 - test_ratio) * len(simplification_dataset)), len(simplification_dataset))\n",
    ")\n",
    "\n",
    "clarity_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"clarity\")\n",
    "train_clarity_dataset = clarity_dataset.select(range(0, int(train_ratio * len(clarity_dataset))))\n",
    "test_clarity_dataset = clarity_dataset.select(range(int((1 - test_ratio) * len(clarity_dataset)), len(clarity_dataset)))\n",
    "\n",
    "coherence_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"coherence\")\n",
    "train_coherence_dataset = coherence_dataset.select(range(0, int(train_ratio * len(coherence_dataset))))\n",
    "test_coherence_dataset = coherence_dataset.select(\n",
    "    range(int((1 - test_ratio) * len(coherence_dataset)), len(coherence_dataset))\n",
    ")\n",
    "\n",
    "paraphrase_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"paraphrase\")\n",
    "train_paraphrase_dataset = paraphrase_dataset.select(range(0, int(train_ratio * len(paraphrase_dataset))))\n",
    "test_paraphrase_dataset = paraphrase_dataset.select(\n",
    "    range(int((1 - test_ratio) * len(paraphrase_dataset)), len(paraphrase_dataset))\n",
    ")\n",
    "\n",
    "neutralize_dataset = all_dataset.filter(lambda x: x[\"task\"] == \"neutralize\")\n",
    "neutralize_dataset_split = int(train_ratio * len(neutralize_dataset))\n",
    "train_neutralize_dataset = neutralize_dataset.select(range(0, int(train_ratio * len(neutralize_dataset))))\n",
    "test_neutralize_dataset = neutralize_dataset.select(\n",
    "    range(int((1 - test_ratio) * len(neutralize_dataset)), len(neutralize_dataset))\n",
    ")\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "train_dataset = concatenate_datasets(\n",
    "    [\n",
    "        train_gec_dataset,\n",
    "        train_simplification_dataset,\n",
    "        train_clarity_dataset,\n",
    "        train_coherence_dataset,\n",
    "        train_paraphrase_dataset,\n",
    "        train_neutralize_dataset,\n",
    "    ]\n",
    ")\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda item: {\n",
    "        \"input\": item[\"src\"],\n",
    "        \"reference\": item[\"tgt\"],\n",
    "        \"references\": [item[\"tgt\"]],\n",
    "    },\n",
    "    remove_columns=[\"src\", \"tgt\", \"_id\"],\n",
    ")\n",
    "print(f\"train set {set(train_dataset['task'])}\")\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = concatenate_datasets(\n",
    "    [\n",
    "        test_gec_dataset,\n",
    "        test_simplification_dataset,\n",
    "        test_clarity_dataset,\n",
    "        test_coherence_dataset,\n",
    "        test_paraphrase_dataset,\n",
    "        test_neutralize_dataset,\n",
    "    ]\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda item: {\n",
    "        \"input\": item[\"src\"],\n",
    "        \"reference\": item[\"tgt\"],\n",
    "        \"references\": [item[\"tgt\"]],\n",
    "    },\n",
    "    remove_columns=[\"src\", \"tgt\", \"_id\"],\n",
    ")\n",
    "print(f\"test set {set(test_dataset['task'])}\")\n",
    "print(test_dataset)\n",
    "\n",
    "\n",
    "def add_prompt(item):\n",
    "    return {\n",
    "        \"request\": f\"{item['input']}\\nResponse:\",\n",
    "        \"prompt\": f\"{item['input']}\\nResponse:{item['reference']}\",\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "# dataset = dataset.rename_column(\"task\", \"label\")\n",
    "dataset = dataset.map(add_prompt)\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_input_length train: 171\n",
      "max_input_length test: 239\n"
     ]
    }
   ],
   "source": [
    "# find the longest sequence in the dataset\n",
    "max_input_length = max(len(tokenizer.encode(item[\"input\"])) for item in dataset[\"train\"])\n",
    "print(f\"max_input_length train: {max_input_length}\")\n",
    "max_input_length = max(len(tokenizer.encode(item[\"input\"])) for item in dataset[\"test\"])\n",
    "print(f\"max_input_length test: {max_input_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/gec: 18277\n",
      "train/clarity: 1126\n",
      "train/neutralize: 10143\n",
      "train/coherence: 9554\n",
      "train/simplification: 10296\n",
      "train/paraphrase: 14307\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_lists_map = {}\n",
    "\n",
    "for task in set(train_dataset['task']):\n",
    "    train_lists_map[task] = []\n",
    "\n",
    "for item in dataset[\"train\"]:\n",
    "    train_lists_map[item[\"task\"]].append(item)\n",
    "\n",
    "train_dataset_map = {}\n",
    "for task, l in train_lists_map.items():\n",
    "    train_dataset_map[task] = Dataset.from_list(l)\n",
    "# print(train_dataset_map)\n",
    "\n",
    "train_dataset_dict = DatasetDict(train_dataset_map)\n",
    "# print(train_dataset_dict)\n",
    "\n",
    "# for task, ds in train_dataset_dict.items():\n",
    "#     print(f\"{task}: {ds}\")\n",
    "\n",
    "for task in set(train_dataset['task']):\n",
    "    print(f\"train/{task}: {len(train_lists_map[task])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/gec: 2031\n",
      "test/clarity: 126\n",
      "test/neutralize: 1127\n",
      "test/coherence: 1062\n",
      "test/simplification: 1144\n",
      "test/paraphrase: 1590\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_lists_map = {}\n",
    "\n",
    "for task in set(train_dataset['task']):\n",
    "    test_lists_map[task] = []\n",
    "\n",
    "for item in dataset[\"test\"]:\n",
    "    test_lists_map[item[\"task\"]].append(item)\n",
    "\n",
    "test_dataset_map = {}\n",
    "for task, l in test_lists_map.items():\n",
    "    test_dataset_map[task] = Dataset.from_list(l)\n",
    "# print(test_dataset_map)\n",
    "\n",
    "test_dataset_dict = DatasetDict(test_dataset_map)\n",
    "# print(test_dataset_dict)\n",
    "\n",
    "# for task, ds in test_dataset_dict.items():\n",
    "#     print(f\"{task}: {ds}\")\n",
    "\n",
    "for task in set(train_dataset['task']):\n",
    "    print(f\"test/{task}: {len(test_lists_map[task])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gec\n",
      "Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.\n",
      "Despite the strict Japanese society, I feel happy when I have dinner with my family.\n",
      "Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.\n",
      "Response:Despite the strict Japanese society, I feel happy when I have dinner with my family.\n",
      "Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.\n",
      "Response:\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"test\"][0][\"task\"])\n",
    "print(dataset[\"test\"][0][\"input\"])\n",
    "print(dataset[\"test\"][0][\"reference\"])\n",
    "print(dataset[\"test\"][0][\"prompt\"])\n",
    "print(dataset[\"test\"][0][\"request\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=350) and `max_length`(=350) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> gec\n",
      "input: ['Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.', 'Fix grammaticality in this sentence: They are increasing rapidly in Japan for a couple of years.']\n",
      "result: ['Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.', 'Fix grammaticality in this sentence: They are increasing rapidly in Japan for a couple of years.']\n"
     ]
    }
   ],
   "source": [
    "max_batch = 2\n",
    "max_length = 350\n",
    "\n",
    "for task, batch in test_dataset_dict.items():\n",
    "    print()\n",
    "    print(f\">> {task}\")\n",
    "    batch_size = len(batch) if len(batch) < max_batch else max_batch\n",
    "    input_batch = batch.select(range(batch_size))\n",
    "    print(f\"input: {input_batch['input']}\")\n",
    "\n",
    "    input = tokenizer(input_batch[\"input\"], padding=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(input.input_ids, max_length=max_length)\n",
    "    result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(f\"result: {result}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> gec\n",
      "request: ['Fix grammaticality in this sentence: Despite strict japanese society, I feel happy when I had dinner with my family.\\nResponse:', 'Fix grammaticality in this sentence: They are increasing rapidly in Japan for a couple of years.\\nResponse:']\n",
      "reference: ['Despite the strict Japanese society, I feel happy when I have dinner with my family.', 'They have been increasing rapidly in Japan for over a couple of years.']\n",
      "result: ['Despite strict Japanese society, I feel happy when I had dinner with my family.', 'They are increasing rapidly in Japan for a couple of years.']\n",
      "\n",
      ">> clarity\n",
      "request: ['Use clearer wording: Canals are waterways channels, or artificial waterways, for water conveyance, or to service water transport vehicles.\\nResponse:', 'Clarify this text: Canals are waterways channels, or artificial waterways, for water conveyance, or to service water transport vehicles.\\nResponse:']\n",
      "reference: ['Canals are waterway channels, or artificial waterways, for water conveyance, or to service water transport vehicles.', 'Canals are waterways channels, or artificial waterways, for water conveyance, or for servicing water transport vehicles.']\n",
      "result: ['Canals are waterways channels, or artificial waterways, for water conveyance, or to service water transport vehicles.', 'Canals are waterways channels, or artificial waterways, for water conveyance, or to service water transport vehicles.']\n",
      "\n",
      ">> neutralize\n",
      "request: ['Remove non-neutral POV: new moon received poor reviews from critics.\\nResponse:', 'Remove POVs in this text: rhonda shear (born 1954), american television personality, comedienne, and actress\\nResponse:']\n",
      "reference: ['new moon received negative reviews from critics.', 'rhonda shear (born 1954), american television personality, comedian, and actress']\n",
      "result: ['new moon received poor reviews from critics.', 'rhonda shear (born 1954), american television personality, comedian, and actress']\n",
      "\n",
      ">> coherence\n",
      "request: ['Fix coherence: Outside the town, 6 tourists were reported killed. Official documents indicate that at least 255 local residents were killed, with a further 29 never found.\\nResponse:', 'Make the text more cohesive: Whereas at some times (and in some places) a Corps of two divisions was sufficient, at other times 5 or 6 divisions were necessary. Under the Hindenburg regime (from summer 1916), new Corps headquarters were created without organic divisions.\\nResponse:']\n",
      "reference: ['Outside the town, 6 tourists were reported killed. However, official documents indicate that at least 255 local residents were killed, with a further 29 never found.', 'Whereas at some times (and in some places) a Corps of two divisions was sufficient, at other times 5 or 6 divisions were necessary. Therefore, under the Hindenburg regime (from summer 1916), new Corps headquarters were created without organic divisions.']\n",
      "result: ['Outside the town, 6 tourists were reported killed. However, official documents indicate that at least 255 local residents were killed, with a further 29 never found.', 'Whereas at some times (and in some places) a Corps of two divisions was sufficient, at other times 5 or 6 divisions were necessary. However, under the Hindenburg regime (from summer 1916), new Corps headquarters were created without organic divisions.']\n",
      "\n",
      ">> simplification\n",
      "request: ['Change to simpler wording: \" Torchwood \" launched with 2.4 million viewers in October 2006.\\nResponse:', 'Simplify this sentence: Felony disenfranchisement in Florida began with the 1838 ratification of the state constitution.\\nResponse:']\n",
      "reference: ['When the first episode of Torchwood was launched in October 2006 on BBC Three, 2.4 million people watched it.', 'Florida  s constitution was ratified in 1838 and with that felony disenfranchisement was established in Florida.']\n",
      "result: ['It was launched in October 2006 with 2.4 million viewers.', 'Felony disenfranchisement in Florida began with the 1838 ratification of the state constitution.']\n",
      "\n",
      ">> paraphrase\n",
      "request: ['Write a paraphrased version of the sentence: Still, the thought of Speedy Parker danced at the edge of his mind as Jack ambled across the boardwalk and down to the depressingly empty beach.\\nResponse:', 'Rewrite the sentence with different wording: \"The proposal, if your Majesty will forgive my saying so, is most generous,\" Valgon observed, concluding his reading of the latest treaty offered by Ran Borune.\\nResponse:']\n",
      "reference: ['Yet, as Jack walked slowly over the wooden gangway to the depressed, deserted beach, the thought of Speedy Parker was dancing on the boundary of his awareness.', '\"This suggestion is, indeed, very noble, \" said Valgon after completing his readings about the recent treaty proposed by Ran Borune, \"if your Majesty allows me to call it that.']\n",
      "result: ['As Jack walked across the boardwalk and down to the beach, the thought of Speedy Parker danced in his mind.', 'The proposal, if your Majesty will forgive my saying so, is most generous, Valgon concluded.']\n"
     ]
    }
   ],
   "source": [
    "max_batch = 2\n",
    "max_length = 350\n",
    "\n",
    "for task, batch in test_dataset_dict.items():\n",
    "    print()\n",
    "    print(f\">> {task}\")\n",
    "    batch_size = len(batch) if len(batch) < max_batch else max_batch\n",
    "    input_batch = batch.select(range(batch_size))\n",
    "    print(f\"request: {input_batch['request']}\")\n",
    "    print(f\"reference: {input_batch['reference']}\")\n",
    "\n",
    "    inputs = tokenizer(input_batch['request'], return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    # outputs = model.generate(**inputs, max_new_tokens=128, num_return_sequences=1)\n",
    "    outputs = model.generate(**inputs, num_return_sequences=1)\n",
    "    # outputs = model.generate(\n",
    "    #     **inputs,\n",
    "    #     do_sample=True,\n",
    "    #     top_k=10,\n",
    "    #     num_return_sequences=1,\n",
    "    #     pad_token_id=tokenizer.eos_token_id,\n",
    "    #     # return_attention_mask=True,\n",
    "    #     max_length=256,\n",
    "    # )\n",
    "\n",
    "    trimmed_output = outputs[:, inputs.input_ids.shape[1] :]\n",
    "    result = tokenizer.batch_decode(trimmed_output, skip_special_tokens=True)\n",
    "    print(f\"result: {result}\")\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total/trainable params: 774030080/774030080\n",
      "{'total_memory': 10736893952, 'memory_used': 4979257344, 'cuda_allocated': 3218543104, 'cuda_reserved': 3552575488, 'ram_usage': 18353610752}\n",
      "{'total_memory': '10.00', 'memory_used': '4.64', 'cuda_allocated': '3.00', 'cuda_reserved': '3.31', 'ram_usage': '17.09'}\n",
      "total/used/cuda/res/ram(Gb): 10.00/4.64/3.00/3.31/17.09\n",
      "Total/used/available memory (Gb): 10.00/{utilization['memory_used']/1024**3:.2f}/{available_memory/1024**3:.2f}\n",
      "Recommended/actual fraction: 0.54/0.95\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "from utils.monitoring import calculate_utilization, format_utilization_narrow, print_utilization\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total/trainable params: {total_params}/{total_trainable_params}')\n",
    "\n",
    "utilization = calculate_utilization()\n",
    "print(utilization)\n",
    "utilization_str = format_utilization_narrow(utilization)\n",
    "print(utilization_str)\n",
    "print(\n",
    "    f\"total/used/cuda/res/ram(Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "    f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']}\"\n",
    ")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "actual_fraction = 0.95\n",
    "available_memory = utilization['total_memory'] - utilization['memory_used']\n",
    "recommended_fraction = available_memory / utilization['total_memory']\n",
    "torch.cuda.set_per_process_memory_fraction(actual_fraction, 0)\n",
    "\n",
    "print(\n",
    "    f\"Total/used/available memory (Gb): {utilization['total_memory']/1024**3:.2f}/\"\n",
    "    \"{utilization['memory_used']/1024**3:.2f}/{available_memory/1024**3:.2f}\"\n",
    ")\n",
    "print(f'Recommended/actual fraction: {recommended_fraction:.2f}/{actual_fraction:.2f}')\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.empty(utilization['total_memory'] // 2, dtype=torch.int8, device='cuda')\n",
    "# print_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval encoder-decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "\n",
    "batch_size = 20 # home: t5, grammarly/coedit\n",
    "# batch_size = 100\n",
    "max_length = 350\n",
    "\n",
    "\n",
    "def model_process(batch, idx, **kwargs):\n",
    "    num_samples = len(batch[\"input\"])\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = kwargs.get(\"model\")\n",
    "    tokenizer = kwargs.get(\"tokenizer\")\n",
    "    total_samples = kwargs.get(\"total_samples\")\n",
    "\n",
    "    inputs = tokenizer(batch[\"input\"], max_length=max_length, padding=True, return_tensors=\"pt\").to(device)\n",
    "    # input_ids = tokenizer(batch['task'], return_tensors=\"pt\").input_ids.to(device)\n",
    "    # input_ids = tokenizer(item['task'], return_tensors=\"pt\").input_ids\n",
    "    # outputs = model.generate(input_ids, max_length=512)\n",
    "    outputs = model.generate(inputs.input_ids, max_length=max_length)\n",
    "    # print(f\"outputs: {outputs}\")\n",
    "    processed = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    sps = num_samples / elapsed_time\n",
    "    sps_str = f\"{sps:.2f}\"\n",
    "\n",
    "    utilization = calculate_utilization()\n",
    "    utilization_str = format_utilization_narrow(utilization)\n",
    "    print(\n",
    "        f\"{idx[0]}-{idx[-1]}/{total_samples} | total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "        f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']} | \"\n",
    "        f\"batch/sps: {num_samples}/{sps_str}\"\n",
    "    )\n",
    "\n",
    "    return {\"processed\": processed}\n",
    "\n",
    "\n",
    "utilization = calculate_utilization()\n",
    "utilization_str = format_utilization_narrow(utilization)\n",
    "print(\n",
    "    f\"total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "    f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']}\"\n",
    ")\n",
    "\n",
    "processed_samples_map = {}\n",
    "\n",
    "for task, samples in test_dataset_dict.items():\n",
    "    total_samples = len(samples)\n",
    "\n",
    "    print(f\"Processing {total_samples} samples for {task}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    processed_samples = samples.map(\n",
    "        model_process,\n",
    "        fn_kwargs={\n",
    "            \"model\": model,\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"total_samples\": total_samples,\n",
    "        },\n",
    "        num_proc=1,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        with_indices=True,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    sps = total_samples / elapsed_time\n",
    "    sps_str = f\"{sps:.2f}\"\n",
    "\n",
    "    print(f\"Finished processing {total_samples} samples for {task}.\")\n",
    "\n",
    "    utilization = calculate_utilization()\n",
    "    utilization_str = format_utilization_narrow(utilization)\n",
    "    print(\n",
    "        f\"{total_samples} | total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "        f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']} | \"\n",
    "        f\"sps: {sps_str}\"\n",
    "    )\n",
    "\n",
    "    processed_samples_map[task] = {\n",
    "        # \"task\": task,\n",
    "        # \"samples\": samples,\n",
    "        \"samples\": processed_samples,\n",
    "        \"total_samples\": total_samples,\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"sps\": sps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_length\": max_length,\n",
    "        \"utilization\": utilization,\n",
    "    }\n",
    "\n",
    "# processed_samples = samples.map(model_process, num_proc=torch.cuda.device_count())\n",
    "# processed_samples = samples.map(\n",
    "#     model_process,\n",
    "#     fn_kwargs={\n",
    "#         \"model\": model,\n",
    "#         \"tokenizer\": tokenizer,\n",
    "#         \"total_samples\": total_samples,\n",
    "#     },\n",
    "#     num_proc=1,\n",
    "#     batched=True,\n",
    "#     batch_size=batch_size,\n",
    "#     with_indices=True,\n",
    "# )\n",
    "\n",
    "processed_gec_samples = processed_samples_map[\"gec\"][\"samples\"]\n",
    "\n",
    "pprint(processed_gec_samples)\n",
    "pprint(processed_gec_samples[\"processed\"][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval decoder-only models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "total/used/cuda/res/ram (Gb): 10.00/4.45/3.00/3.07/17.09\n",
      "Processing 2031 samples for gec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11819eabb36444f4ad9f815f11110d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Despite strict Japanese society, I feel happy when I had dinner with my family.', 'They are increasing rapidly in Japan for a couple of years.', \"As I go to my friends' house, I play 'Wii' together every time.\", 'I have to come home as soon as possible, because my wife had a cough yesterday.', \"Of course, my wife and I went to my father's house to eat dinner together.\", 'I have much time to do many things because today is free.', 'Therefore, I come to go their company to discuss once a few months.', 'Tonight, I ate yellow noodle soup with red pork and wonton at a roadside vendor cart.']\n",
      "0-7/2031 | total/used/cuda/res/ram (Gb): 10.00/4.87/3.00/3.37/22.70 | batch/sps: 8/12.51\n",
      "['As it to me, the place which is important to me is Hangzhou city located in Zhejiang province.', 'Of course, I like Hangzhou city also because there are many great Chinese traditional restaurants.', \"So I'm a little bit different from people who want to get English ability as a tool of business or something.\", \"I'm now really embarrassed because I can't decide my future.\", 'People around me all do job hunting, which makes me even more hasty.', \"I've been pretty happy all my life, so far.\", 'First of all, if students learn in serious and strict learning environments, they can become more polite people in the future.', 'Taking all of these things into account, there is no doubt in my mind that a serious and strict teaching method is more effective than an amusing and easygoing that.']\n",
      "8-15/2031 | total/used/cuda/res/ram (Gb): 10.00/5.02/3.00/3.55/22.70 | batch/sps: 8/11.70\n",
      "[\"I'm little bit excited about this and hope to make many friends here.\", 'The characters are almost junior high-school boys or girls, so they are admirable for the younger children.', \"Momiji manju is a waffle shaped like a maple leaf filled with sweet bean paste, and it's the most popular sweet in Hiroshima.\", 'The biggest point is to add a lot of bief tendons.', \"Oden is a wonderful dish because it's easy to make while it takes much time, and we can eat vegetables and meat at the same time.\", 'I sometimes felt irritated to see children playing innocently, but I thought again that I had to do anything to keep them smiling.', 'I was watching her wondering what she would do next.', 'I felt happy to see that my daughter could do nice things naturally and that her kindness was warmly accepted.']\n",
      "16-23/2031 | total/used/cuda/res/ram (Gb): 10.00/5.05/3.00/3.55/22.64 | batch/sps: 8/12.95\n",
      "[\"According to today's newspaper, groups of Keio university and others developed a new method to diagnose nine lever diseases such as hepatitis B, C, and liver cancer from only one drop of the blood.\", 'The earth would remain as it was even if human beings would become extinct.', 'He will come back next Saturday, so I have to spend my days only with my two children till then.', \"My husband will come back too, but I came back with my two children little earlier than him because he can't take so much holidays.\", \"I bought heart-shaped mugs with elephant's design that I loved at first sight, though they were not discounted.\", 'Mucin is a polysaccharide and has effect of enhancing protein absorption and lowering cholesterol absorption.', 'It looked pretty when it was placed on the hanger printed with characters, but the cloth itself was not so pretty and seemed to be uncomfortable.', 'They are not what she exactly wanted, but I hope she will like it.']\n",
      "24-31/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.63 | batch/sps: 8/8.95\n",
      "['When I was a junior high school student, there was a dagashi store near my school, and I used to go there with my friends after school.', 'Tomato is used for the base of taste in many countries.', 'It is promising for anti-aging effect, such as hypoglycemic effect and preventive arterial sclerosis effect.', 'In Hina-nagashi, dolls made of paper or straw are thrown in rivers, supposedly taking troubles or bad spirits away with them.', 'However, it looked a little strange for me when I got home, so I cut her hair again by myself.', 'Children in elementary schools seem not to be addicted to the particular cartoons as much as when they were little.', 'I uploaded the photos of a comic books section in a bookstore.', 'The pictures are detailed, and we can find many surprises in it.']\n",
      "32-39/2031 | total/used/cuda/res/ram (Gb): 10.00/5.16/3.00/3.62/22.63 | batch/sps: 8/12.85\n",
      "['The recipe is simple, and it says to make a dough by mixing flour, butter, sugar, milk, and dry yeast and let it rise for 10 minutes in a microwave.', 'But yukata is a little difficult to move for children, so I made a colorful one-piece for my daughter and she put on that.', 'We had a very good time.', 'The photo I loaded is the one she drew when she was just three years old, and this was not taken transversely but from the front.', \"The weather forecast says it will be cloudy in the morning, and it's going to rain later.\", \"Isothiocyanate is volatile, so the grated radish will be less pungent when it's allowed to stand for a while.\", \"That's why we could see only two or three times a year.\", 'A cup of coffee and something sweet makes me so happy!']\n",
      "40-47/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.65 | batch/sps: 8/10.86\n",
      "['Even though we can get babies to sleep by rocking, they will wake up when we try to put them on the bed.', 'Recently, I found a very good way to get him to sleep!', 'Next, I bounce on the balance boll, holding my son in my arms.', \"He doesn't wake up!\", 'I feel like there is no place to live in this world.', 'The exhibition was very crowded and took over 2 hours to look at the mos of them.', 'I went to Egypt on my honeymoon last year, so the exhibition brought me some memories.', 'The interest of investors in enterprises producing iron and steel, finished metal ware, food products, drinks, and tobacco products is also steady.']\n",
      "48-55/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.64 | batch/sps: 8/14.97\n",
      "['Difficulty of choice in such uneasy matters as, for example, membership in NATO and European Union causes rather unstable and often even unpredictable political situation.', 'With regard to the importance of investment climate improvement the primary task of the Government is developing legal and organizational framework.', 'Also in 2008 the Cabinet of Ministers of Ukraine has adopted new decree which establishes common mechanism of pre-trial settlement of disputes arising between investors and government bodies.', 'But anyway, I would appreciate your help and corrections.', 'To write a diary in English is one of the most effective study methods.', 'I will do a short presentation tomorrow.', 'My Hero is not far from me.', 'I swear I will recover from cold first before next run.']\n",
      "56-63/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.64 | batch/sps: 8/12.41\n",
      "[\"I'll have sushi for lunch and udon for dinner today, and tomorrow I will have sushi for lunch and udon for dinner.\", 'American never talk to me, so I have to talk to them first.', 'So they are good teachers.', 'I had met him first, and I thought he was a good guy.', 'The ComicMarket is one of the biggest comic festivals in Japan.', 'The book is for Kids, so I can understand the outline.', 'Or must I read these unfamiliar words before I check these unfamiliar words?', 'This year, I had been very busy and worked even on every weekend in April and May.']\n",
      "64-71/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.65 | batch/sps: 8/14.71\n",
      "['I told my mom about this, and she said that she had a business partner was interested, too.', 'Could you please answer for me?', 'My friend, Kumiko suggested that I could share her umbrella.', 'I got a T-shirt at half price, and trousers cheaper than usual!', 'It is anything but a notebook computer!', 'It means saving for a rainy day.', 'So maybe I will go on a normal day.', 'I was very nervous at first because I thought my English was very bad.']\n",
      "72-79/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.65 | batch/sps: 8/17.11\n",
      "['I was very nervous at first because I thought my English was very bad.', 'After a phone call, I cleaned my messy room.', 'It had been really hard and time-consuming, but the hospital would continue to work.', \"But first of all, I'd like to thank everybody for the help you're giving me with my English understanding!\", 'Firstly, I would like to know where the school is and how to reach it from the nearest underground station.', 'I was very embarrassed today because I put my essay in lang-8.', 'At first, I thought that was a very good idea.', \"That's another accident in my life, which is filled with coincidences and big surprises.\"]\n",
      "80-87/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/16.69\n",
      "['I just do it.', 'If this happens to you, slow down the walking or stop it completely and put your arm up.', 'Making a list of the things to carry on with you could save you of being in trouble.', 'I want to sell strawberries', 'One day, I decide to invite her to a restaurant or club.', 'I like active sports, and I try to do as often as I can.', 'Tsunami will come here soon.', \"It's rainy season in Korea.\"]\n",
      "88-95/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/17.15\n",
      "['After my part-time job, my family and I went to have dinner.', 'I had muscle pain a little today.', 'I am a lucky, because I could get my bonus if it was less than last year.', 'I hurried to go there, at last I arrived there at 8 pm.', 'I know, Studying language to prepare for an examination is very tedious and difficult.', 'If I can have time, I will study how to write a correct report.', 'When I face this case, that reminds me of a man suddenly.', 'He creates a very interesting and rich story.']\n",
      "96-103/2031 | total/used/cuda/res/ram (Gb): 10.00/5.15/3.00/3.62/22.64 | batch/sps: 8/20.39\n",
      "['Today was windy and nasty weather.', 'I want to be good English speaker.', 'I want to know good translation for this sentence.', 'The other day, I sat on the bench near Shibuya Station, and was eating bread and drinking fruit juice.', 'Just after eating bread, a homeless man came up and sat next to me.', 'Just after eating bread, a homeless man came up and sat next to me.', 'I thought maybe he wanted to have this drink, but I was very hungry and thirsty.', 'I think they are very diligent, no less than any other people.']\n",
      "104-111/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.65 | batch/sps: 8/16.10\n",
      "['I think they are very diligent, no less than any other people.', 'They are much better than people who ask for public assistance but have no intention to work.', 'I go to Australia after an interval of three years.', 'I insisted you do something because you are a man.', 'The artist draws with strong and beautiful taste.', \"If I would live with Kimura-san's family or my family, my role in the family might have changed.\", 'Her name is Endo-Miki and 24 years old, and she is getting married.', 'To speak more frankly, everything was high-level compared to the other common accomodations.']\n",
      "112-119/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/16.90\n",
      "['They looked at the other guests who were paying the expenses next to them.', 'They can pay the amount as much as they want to pay.', 'Because I spend so much time on the computer.', 'I know, Pooh is the most important book in this book.', 'You know how comfortable it is in?', 'I am looking forward to next story.', 'When I took an order of a coffee, I brought the coffee with sugar and cream.', \"And as I've written for the first part, from my experience, we can also know that the guest can choose whether they have dinner or not.\"]\n",
      "120-127/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/13.59\n",
      "['It was very hard for me because they never said like NHK announcers and had no captions.', 'And every day, we talk to each other via skype after his work.', 'Those who are jumping, called Haneto.', 'Do you know what day is February second?', 'When you return to your room and find this memo, please call the front desk.', 'The second dinner of two nights was abalone dish which is cooked by another style.', 'Turning to the original story, although LiLICO-san has the parents who speak different languages, she could speak only Swedish until 18.', 'This is the story about the proofreader who wants to correct one history book to what he thinks of.']\n",
      "128-135/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/14.25\n",
      "[\"I just wanted to tell you, I've made it every day.\", \"She copied a Rakugo-ka's way of talking on TV show.\", 'Because I could hear what exactly Rakugo-ka said, and so far as I understand it.', \"When I go to a 100 Yen shop or home center, I also say 'roon-roon'!\", 'In this duration, almost of the guests usually stayed for two or three days.', \"Lately, I've been so busy that I couldn't write anything here.\", 'Additionally, I want to escape from the responsibilities when something bad happens.', 'Because there were many drifted things which I never saw from all over the world.']\n",
      "136-143/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/16.59\n",
      "['I thought I would bring it and put it in a trash can.', 'Besides, it was a little difficult for the guests to find an elevator.', 'I also turn off the Gotatsu and put on the clothes more and even socks when I am at home.', \"There is no need to 100 percent agree with someone's philosophy and also force someone to make the same opinions as oneself.\", 'I am a clod-blooded person, by nature.', 'It made me very tired very much.', 'If I want to read it right now, I can ask people in the supermarket.', 'I think that the clerk is better than other customers because it can be the part of their job to answer the customer.']\n",
      "144-151/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/16.15\n",
      "['A few days ago, I had my job started as a waitress at a restaurant of the hotel where my husband worked in.', 'If you grow the seed in a bright place, it has green leaves.', 'It was so warm.', 'This picture is me.', 'The next day, we went to the Takasaki mountain and the aquarium.', 'I was given a shot, and I was pulled a tooth after all.', 'The university authorities did not approve the regulation, neither explained why.', 'Jane is tired of dealing with customer complaints and wishes that she could be allocated to do another work.']\n",
      "152-159/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/14.86\n",
      "[\"The only thing that I'm worrying is that I might have forgotten how to use English during the long break time.\", \"I'm afraid of the weight scale now.\", 'It was the first time we used the expressway bus for our business trip.', 'Is this the song of the second full moon in a month?', \"I went to my home, which located Saitama prefecture, and made a New Year's greeting with my mother and brother.\", 'But I forgot to take pictures of the party because of too much fun.', 'But I forgot to take pictures of the party because of too much fun.', 'As you may know, sukiyaki is one of the traditional Japanese meat dishes.']\n",
      "160-167/2031 | total/used/cuda/res/ram (Gb): 10.00/5.14/3.00/3.62/22.64 | batch/sps: 8/14.39\n",
      "['In Japan, the owners of the lost pets often put up some notices of the lost pet in their town.', 'How can we catch the owl frying around the sky at night?', \"I guess it's difficult for the owner to get the owl back, even though I can't tell the owner that you should give up the owl.\", \"I'd like to write a New Year's resolution for this year.\", \"I don't know whether this resolution has been completed or not.\", \"On the other hand, if I made big resolutions, I could not carry them out because I'm a weak-willed man.\", \"I'm sorry for writing about dirty topic on this diary entry.\", \"So today, I'd like to finish this diary.\"]\n",
      "168-175/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.66 | batch/sps: 8/12.36\n",
      "['In this month, the height of the tower began to become taller again.', \"It will continue to grow taller and taller, and I'd like to report it on my diary entries sometimes hereafter, too.\", 'The above picture is the scene of then which I saw at my house.', 'I thought this rank was the best for the beginning of the new year.', \"The picture above is one which I took on the way to my company on today's morning.\", 'It is a very fine day and we can see the whole tower.', 'I have been practicing of the marathon in every weekend at the club, for the Tokyo Marathon which will be held in the end of this month.', 'This is my diary entry for the first time in about 10 days.']\n",
      "176-183/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.64 | batch/sps: 8/13.89\n",
      "['Therefore, a few days around Christmas day are the hardest days in a year for me, almost every year.', 'I and my colleague talked that we should care about his mental trauma from now.', \"And I don't think rapid trains and express trains are abnormal, of course.\", \"I think the shark's fin of my case may be similar with the case of caviar.\", 'Actually, I hardly spoke what I wanted to say at that time.', 'I can see the Tokyo Sky Tree which is under construction now from my house.', 'The summer had gone, but it had been still hot in Tokyo.', 'I went to Akihabara to buy new computer memories for my computer yesterday.']\n",
      "184-191/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.64 | batch/sps: 8/17.24\n",
      "['As far as I was concerned, Akihabara is such a unique town, currently.', \"I'd like to write my diary entry after an interval of nearly two months.\", 'Today is a very hot day in Tokyo.', \"I'm not a believer of Japanese shinto shrine, but I often go to Hatsumode as one of the events of new year holidays, like most of the Japanese.\", \"I'm not a believer of Japanese shinto shrine, but I often go to Hatsumode as one of the events of new year holidays, like most of the Japanese.\", 'So I lined up at the end of the row, and waited to visit to the main shrine, with watching stands near the main pilgrim.', 'Though both John and Ringo were the former members of the Beatles, furthermore, Ringo is still alive, why does such a difference occur?', 'At first, the reason why I started writing English diary entries on this site was because I was not good at English writing.']\n",
      "192-199/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.65 | batch/sps: 8/11.16\n",
      "['This is a part of the restaurant which I went to today.', \"However, many stores are still open, and it doesn't mean that there are no products in stores.\", 'I think we, the Japanese, are still dealing with our situation calmly now.', 'She was very faithful for everything, of course, of course, for her job.', 'She was very faithful for everything, of course, of course, for her job.', 'And she retired the job when she was in the eighth month of pregnancy.', 'We little worried but we thought that she might be forgotten about her report.', 'Fortunately, when I arrived at Yokohama, the rain stopped and the sun shone in the clear sky.']\n",
      "200-207/2031 | total/used/cuda/res/ram (Gb): 10.00/5.13/3.00/3.62/22.64 | batch/sps: 8/16.79\n",
      "['I went to pick up my bicycle which parked near my company office.', 'In addition, there were many musicians and dancers performing near the marathon course.', \"There are many variations of hamburgers, and unique side dishes on Wendy's recipe.\", 'Recently, the Japanese government has released that the price of cigarettes will rise on October.', 'However, when I took the above picture, a young Caucasian woman came close to the displayed kimonos.', 'However, I like Natto very much no matter how many people dislike it.', 'I might stay up all night because I have a job which has a deadline to send up the report until next morning, now.', 'I went to the place where my bicycle has been stolen this morning.']\n",
      "208-215/2031 | total/used/cuda/res/ram (Gb): 10.00/5.11/3.00/3.62/22.64 | batch/sps: 8/13.76\n",
      "['Anyway, most of bicycle thieves either continue to ride on the stolen bicycle by themselves or set them down after riding.', \"Today I'm going to my diary entry shortly.\", \"But I'll do my best on the examination which I'll take on tomorrow.\", 'He dropped out of secondary school because of poverty of his family.', \"Though we often forget it, I think it's happy for us to have equally opportunity to study.\", 'Anyway, the Imperial Palace is one of the most internationally famous tourist spots in Tokyo, as well as a jogging course.', 'There were many foreign tourists too, yesterday.', 'Joking aside, I began to realize the day of the Tokyo Marathon is coming up, when I saw the guidebook.']\n",
      "216-223/2031 | total/used/cuda/res/ram (Gb): 10.00/5.11/3.00/3.62/22.64 | batch/sps: 8/12.61\n",
      "['This is the front door of an Chinese restaurant near my company office building.', 'Power company said Kanto area divided into five groups and my area was group1.', \"We went to hometown for 13th anniversary for wife's grandmother's death last weekend.\", 'Police was so nice that they could identify him and find him before the day.', 'I had planned to go skiing with my family this weekend.', 'The third picture is our dinner that my wife has made.', 'Today was a very busy day.', 'I went to the computer academy after meeting.']\n",
      "224-231/2031 | total/used/cuda/res/ram (Gb): 10.00/5.16/3.00/3.62/22.64 | batch/sps: 8/19.00\n",
      "['Today was the worst day.', 'I picked it up, but there is nothing on its screen.', 'Maybe my English contains too many mistakes to be understood by native speakers.', 'If you have time, I would be happy for you to correct my sentence.', 'Light novel has no other features.', 'Of course, human needs not only a stick but also a candy.', 'Just she went back to her home in a few weeks.', 'It is they are satisfied with enough family loves.']\n",
      "232-239/2031 | total/used/cuda/res/ram (Gb): 10.00/5.16/3.00/3.62/22.65 | batch/sps: 8/24.47\n",
      "[\"How's your foreign language study?\", 'I packed up my luggage and got out of the function center.', \"Although you would want to meet your family, anybody won't tolerate your action, because your office is always labor shortage from to reduce personnel expenses.\", 'This tragedy would be identified with a moving story in Japan.', 'Arranged marriage, just like marriage in ancient China.', 'I have a dream of going abroad to study English and the latest education conducted by foreign countries.', 'My friend Ryu, who was a baseball team-mate from high school got married the day before yesterday.', 'Anyway, what I want to tell you is that I could not have good sleep last night because of my failures in the game.']\n",
      "240-247/2031 | total/used/cuda/res/ram (Gb): 10.00/5.17/3.00/3.62/22.64 | batch/sps: 8/10.50\n",
      "[\"It's fantastic when you can get up later than usual because you don't have to hurry up on your bus.\", \"You can't buy love and friendship.\", 'I mean the held was postponed two times and finally held on the day before yesterday.', 'However, the postpaid envelope has disappeared.', 'I went to a large park today early morning with my daughter.', 'We bought glasses for my daughter.', 'The check needed strong effect eye medicine.', 'But we enjoyed the match.']\n",
      "248-255/2031 | total/used/cuda/res/ram (Gb): 10.00/5.17/3.00/3.62/22.64 | batch/sps: 8/13.67\n",
      "['The book said me.', 'I keep chickens in a henhouse, and goldfish in a pond.', 'After that, I and my baby take a walk to shop.', 'When I borrowed the books, the librarian said to me that thank you.', 'According to the book I read, this is very useful for Japanese studying English.', 'And to earch for an exact phrase, enclose the phrase in double quotation marks.', 'I drank a lot of hot water to keep me warm.', \"However, some families don't need to go out, like mine.\"]\n",
      "256-263/2031 | total/used/cuda/res/ram (Gb): 10.00/5.17/3.00/3.62/22.64 | batch/sps: 8/17.39\n",
      "['When I am away from him, he usually calls my name directly.', 'I must not sleep today, and I must sleep early tomorrow.', 'Then, does anyone know how to first effectively contact in English??', 'We are supposed to do a trial lesson, group discussion, and two interviews in Japanese.', 'I need to prepare for them now!', 'Today we first met for about four weeks.', \"By the way, she's been in Japan for two and a half years and taught English at three schools in Kumamoto.\", 'I want to teach students the pleasure of learning and want them to experience it.']\n",
      "264-271/2031 | total/used/cuda/res/ram (Gb): 10.00/5.18/3.00/3.62/22.64 | batch/sps: 8/12.96\n",
      "['I stopped by Dunkin Donuts on the way to give her donuts.', \"If I have a important plan of studying English this month, I'll learn a lot of verbs.\", 'But it takes me a long time to read only one page.', 'She was always running on the treadmill, which was in the corner of the gym.', \"I'm going to the institute to prepare for the qualification exam in the next month.\", 'I am a person who works well with people in my company.', 'I love myself as much as I love you.', 'I love myself as much as I love you.']\n",
      "272-279/2031 | total/used/cuda/res/ram (Gb): 10.00/5.18/3.00/3.62/22.65 | batch/sps: 8/14.31\n",
      "['I just want to catch up on sleep and take a rest.', 'I like music as much as I enjoy listening to music even during work hours.', 'I respect him because he is learning Japanese very hard to go to Japan and study here.', 'I also joined the Chinese speech contest and I won first prize!!', 'I sometimes join volunteer work.', 'Both physical and mental balance are the most important for any professionals, so either one is not able to defect at all.', 'I went to automobile shops with my father until my club started.', 'Every country and every culture has its own traditional celebrations and festivities.']\n",
      "280-287/2031 | total/used/cuda/res/ram (Gb): 10.00/5.18/3.00/3.62/22.65 | batch/sps: 8/12.37\n",
      "['It is located near the Taipei 101 and with a well-designed interior.', 'The diary is written for the first time.', \"I hope I can get enough money to buy a Wii for my parents, then they could do some exercises even I'm not at home.\", 'Her son is the same age as mine, and he goes to a kindergarten that is very focused on sports.', \"Even though it's been one year since he joined the school, it seems like he cries every morning.\", 'It happens all the time that kids cry when they start the new school for the first couple of months.', 'However, most Japanese know the fact that we have a civil war behind the scenes.', 'I always thank you for your labor.']\n",
      "288-295/2031 | total/used/cuda/res/ram (Gb): 10.00/5.21/3.00/3.62/22.65 | batch/sps: 8/12.65\n",
      "['Actually, it is very hard work for everyone.', \"But my level isn't enough to correct other people.\", \"I'm looking forward to the festival.\", 'My sons will go to school, they are looking forward to meeting their friends.', \"I received a call from afterschool's teacher after 5 o'clock.\", 'It is easy to put off what you have to do tomorrow.', 'But someday you will have to do it.', 'I was scared too much, could not say the answer.']\n",
      "296-303/2031 | total/used/cuda/res/ram (Gb): 10.00/5.21/3.00/3.62/22.65 | batch/sps: 8/19.94\n",
      "['I think today was a lucky day, but I learned a lot.', \"If I can't pass the test again, what should I do?\", \"I'm looking forward to going to field trip with my youngest son.\", 'If that day rained, we would go to the Aquarium.', 'Cut sushi roll, you will find a face.', \"Then we went to friend's apartment, ate together Japanese hotpot.\", 'I wish I could have a chance to meet them soon.', \"Now I still stay up, I know it isn't good for the exam.\"]\n",
      "304-311/2031 | total/used/cuda/res/ram (Gb): 10.00/5.27/3.00/3.69/22.65 | batch/sps: 8/21.12\n",
      "['So lesson level is not high, but it is enough high for me.', \"My youngest son couldn't ride a bicycle without my husband's support.\", 'By that time, I should work hard for me and my family, and I should be working hard for my family.', 'Today I was very tired, because we went fishing for an afternoon.', 'It was harder for me to arrive there than I expected due to heavy snow.', 'I have a question about English climate.', 'Well, I sing an English song today, so please check my English pronunciation.', 'The soul which develops the truth self-worth and can able to live the creative life is absolutely happy soul.']\n",
      "312-319/2031 | total/used/cuda/res/ram (Gb): 10.00/5.26/3.00/3.69/22.65 | batch/sps: 8/13.81\n",
      "[\"So I went to my grandparents and my father's tomb on last sunday with my cousin and did it.\", \"By cutting the grass, we appreciate the ancestor's favor and meet the relatives and have a good time there.\", 'I am here to develop my confidence in English.', 'I think it is not true.', 'So, write to me if you also want to be friends with me.', 'The weather report said that it would be a rainy day for last 2 to 3 days.', 'In 1794, British recognised the independence of the 13 colonies, but kept Canada.', 'I got an e-mail about power saving from my univ in the afternoon.']\n",
      "320-327/2031 | total/used/cuda/res/ram (Gb): 10.00/5.25/3.00/3.69/22.67 | batch/sps: 8/14.67\n",
      "[\"Actually, I didn't have any pink nail polish.\", \"However, I wasn't hardly able to catch most of words spoken in the video.\", \"I am embarrassed it, but if you don't mind, please correct the following sentences I wrote down.\", 'By the way, the reason that I had such a dream may be because fall has come?', 'Now I am growing tomatos in my room since my friend gave me the seeds on my birthday in July.', 'However, after I heard this song, it was hard to fall asleep because my heartbeat was so fast.', 'I want to do a difficult pose that I could not do yesterday.', 'Neither I enjoyed it nor understood why some people were so inflexible with this.']\n",
      "328-335/2031 | total/used/cuda/res/ram (Gb): 10.00/5.25/3.00/3.69/22.65 | batch/sps: 8/14.78\n",
      "['Yet I have a sense that my wooden bed will tremble and make a loud noise.', 'We would appreciate it if you could answer by December 1.', \"I haven't had a diary for a long time because I was busy.\", 'It is a warm spring day.', 'Bikan historical quarter is very fantastic!', 'How should we use the time in our lives.', 'Despite such an act, I love my cat.', 'It has been 6 years that I have been going around places in Japan.']\n",
      "336-343/2031 | total/used/cuda/res/ram (Gb): 10.00/5.25/3.00/3.69/22.65 | batch/sps: 8/18.50\n",
      "['Movies I like are true stories, but they are sad stories sometimes.', 'But it was the hard year for her, some bad things happened again and again.', \"It is a pessimistic thinking, isn't it?\", \"I heard that the TOEIC exam in Canada is much easier than Korean one, and I noticed that it's really easy!\", \"She didn't answer me, I wrote to her a few e-mails so I could convince her to try to contact me at least once to make me understand what just happened to her and me.\", \"I do know I'll be able to find myself in the right place with the right person who willingly cares for me, loves me, gives me such an affection.\", \"What he advised me was that I have to enjoy every time of Vancouver life because it's not a normal chance.\", 'How can she marry someone in such a short time?']\n",
      "344-351/2031 | total/used/cuda/res/ram (Gb): 10.00/5.32/3.00/3.76/22.65 | batch/sps: 8/8.63\n",
      "['Today, I worked so hard, had a conversation with Canadian, talking with my friend for few hours.', 'It is the reason why I love them and want to be an animal protector.', 'Physiotherapist inspected my knee and showed me what exercises I have to do.', 'The guests always seemed to enjoy the dish we made and the conversation.', 'She is housekeeper and all her life she has been hard working.', 'Then she asked me if I had any questions or not.', \"Today's topic in my English school is job hunting by a university student in Japan.\", 'It is waste of money.']\n",
      "352-359/2031 | total/used/cuda/res/ram (Gb): 10.00/5.32/3.00/3.76/22.65 | batch/sps: 8/15.23\n",
      "['I told him I wanted to learn guitar, and he promised to teach me online.', 'And I wanted to write many proses, poems, or other things about art.', 'I saw a bear that was trying to kill himself on the road.', \"For example, New York City is located in a cold climate area, isn't it?\", 'But why do the TV broadcasting company broadcast it so easily?', 'Suddenly, it started to collapse with sounds like an earthquake.', 'Nowadays, we can do anything on the internet.', 'My sister so sad.']\n",
      "360-367/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.65 | batch/sps: 8/19.91\n",
      "['My sister so sad.', 'My sister failed to pass the exam of university again.', \"We are conscious that we don't invade other people's territories.\", 'But we lost all games, so we go to eat dinner.', 'He is a mischievous angel.', 'The sparkling foreshore everywhere in the morning sunlight is so beautiful.', \"If she didn't hold her toy, if she didn't walk beside me, I couldn't release from her leash.\", 'It was difficult to find the foreign classic picture book in my local city.']\n",
      "368-375/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.65 | batch/sps: 8/13.94\n",
      "['It was a hot day.', 'But she will feel so hot even if I parked my car in the shade of a tree.', 'Instead of them, she found her favorite toy.', \"I'm not used to writing English diary.\", 'I think that I want to become a day like today.', \"In the snow, it's so cold, but it's so beautiful.\", 'The purpose of the tea party today was to talk with members and have fun.', 'However, there is not written my address.']\n",
      "376-383/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.65 | batch/sps: 8/18.08\n",
      "[\"That's a good point for her and her family, and also me.\", 'OKONOMIYAKI is a Japanese food which is like pizza or pancake containing lots of ingredients such as cabbage, egg, seafood, and noodles.', 'Then, I happen to find this site and would like to try this diary.', 'However, during my stay in Tokyo, I could forget my morning sickness and could have a great time.', 'Do you want to have this machine?', 'Nice to meet you again!', 'Because it is difficult to create a quaint atmosphere.', 'The game was one of the team competitions.']\n",
      "384-391/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.66 | batch/sps: 8/10.15\n",
      "['Second, I will use English at my business near future.', 'I hope the second half will be the fruitful period for my team and me.', 'The book is about a man who was fired his senior management position at a big ad company and after a series of bad things, he finally found a job at a Starbucks branch.', 'The book is about a man who was fired his senior management position at a big ad company and after a series of bad things, he finally found a job at a Starbucks branch.', 'Starting cleaning the store toilet and bagan to learn valuable things through his job and finally found his true happiness in his new job and unfamillier environment.', 'Japanese summer is usually very muggy, but today is hot and dry day.', 'I boiled it and an egg, then I cut an egg with a knife.', 'I want to do many things!']\n",
      "392-399/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.66 | batch/sps: 8/9.72\n",
      "['Oh, I need to buy a bottle of milk!', 'Sometimes she runs into her neighbor and they have a chat.', 'I lean the coaching now, and I went to the class yesterday.', 'I need to go to the dental clinic.', 'She went to City Hall and got a record book for pregnant mothers.', 'She wanted to buy a book because she wanted to learn English.', 'She went to the cafeteria after buying it, and she met her friend.', 'An apple is a fruit that is used to grouse on an apple tree.']\n",
      "400-407/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.66 | batch/sps: 8/20.50\n",
      "['For example, in 2004, Maria Sharapova, who is a tennis player, becomes the number one in tennis.', 'For instance, air pollution from smoke and various chemicals kills 3 million people a year.', 'Moreover, there are many factories that throw their toxic chemicals to the environment.', 'According to the Intergovernmental Panel on Climate Change, tropical deforestation is responsible for approximately 20% of world greenhouse gas emissions.', 'And I will be there 14 days later at last.', \"I don't want to be shackled by anything.\", 'I like to take photos in my free time, and I belong to a photo club.', 'If you like to take pictures, please send me your best shot.']\n",
      "408-415/2031 | total/used/cuda/res/ram (Gb): 10.00/5.33/3.00/3.76/22.66 | batch/sps: 8/14.97\n",
      "['The descriptions should be on the top and middle of photographs and illustrations.', 'Women tend to share their feelings just to get some empathy, not advice, while men would think they are asked for a solution.', 'I have sent many messages to strangers who speak English.', \"I should wear more clothes, but I wanted to wear my new clothes so I didn't wear more clothes.\", 'I have been suffering on my rough and dry hands.', 'I feel really cold on my hands when I wash some dishes.', 'My friends are always laughed at me because my English is not good.', \"And I'm grateful to people around the world who reach out!\"]\n",
      "416-423/2031 | total/used/cuda/res/ram (Gb): 10.00/5.32/3.00/3.76/22.65 | batch/sps: 8/12.27\n",
      "['I will stay here until the 10th of September.', 'Just one thing for my motivation was going to Tokyo and seeing my boyfriend!!', 'Last 3 weeks were so much fun.', 'I will difinetly come and visit people I met in Vancouver.', 'Friday is going to be the last day!', 'Or you can use stereotype phrases, cheat with homework, and graduate school at least haphazardly.', 'It rained for two days.', \"Studying English is really hard, I often wander off when I'm studying English, I try to focus on it, but I often make the mistake again.\"]\n",
      "424-431/2031 | total/used/cuda/res/ram (Gb): 10.00/5.32/3.00/3.76/22.65 | batch/sps: 8/11.49\n",
      "[\"I can't figure out.\", 'My colleague was promoted again, he was a Lieutenant now.', \"I should have gone back, but it's really far away from my home.\", 'When I went off of work tonight and breathed the fresh cold air, I recalled my hometown in winter, the air is cold like it.', \"There is only once I can take off, that's my time to die.\", 'I watched many films these two days.', 'My uncle and aunt dote their daughters and grandchildren too much, I think.', 'They are too weak to do housework, but the two daughters never helped them with cooking or washing, even a meal.']\n",
      "432-439/2031 | total/used/cuda/res/ram (Gb): 10.00/5.31/3.00/3.76/22.66 | batch/sps: 8/12.80\n",
      "['I should be hard to go through all of this.', 'His new apartment was very big, and had a huge balcony.', 'Bunny was very smart, when I watched him, he just stood in here and never moved.', 'Before I got the train, I had a feeling that I would meet someone who came from another country, when a man came to me and asked me to exchange my site, I found that a westerner sat opposite to me.', 'As I posted my warm clothing and the weather became colder and colder, I plan to buy warm clothes and shoes tomorrow.', \"It's interesting, right?\", \"I'd like to go to take a shower and go to bed later.\", 'What I want to say is maybe I find an answer about girls and boys.']\n",
      "440-447/2031 | total/used/cuda/res/ram (Gb): 10.00/5.39/3.00/3.84/22.65 | batch/sps: 8/7.47\n",
      "['I seldom watch scary movies except when I was with my friend.', 'Friend said I was such a completist, so it made me feel bad.', 'Then I learned driving, I was fitted two artificial teeth by the dentist.', 'I found that my last entry got the highest clicks than others of mine, whyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'I think it is because of the name!', 'I watched three movies today again.', 'I like linkin park, but I never listen to them for too long, cause it makes me feel like dizzy.', 'I love film music more, it makes me feel like peace.']\n",
      "448-455/2031 | total/used/cuda/res/ram (Gb): 10.00/8.82/3.00/7.32/22.65 | batch/sps: 8/1.11\n",
      "['After that, I just talked with some friends, wasted of time again, oops!', 'It was about what I had done in last year, the important things to me in last year.', \"I think it's useful to me if I did it, but I don't want to write it this time.\", \"It's little warm in the morning, and I thought it was going to rain in the afternoon.\", \"I hope I can write funny dairies as him, but I don't hope I'm old as him.\", 'Maybe I can make them up tomorrow if I have a break!', \"I don't know if it is good for me or not.\", \"That's what friends are for\"]\n",
      "456-463/2031 | total/used/cuda/res/ram (Gb): 10.00/8.83/3.00/7.32/22.65 | batch/sps: 8/17.00\n",
      "['I think that the soul dwelled in the rod after catching a fish.', 'In this situation, I cannot return to my home.', 'Mission complete this time!', 'If I had put it on my desk, dormitory teacher gave me black marks.', \"But I know, I can't stop or give up, so I have to get up and do what I must do.\", 'When rainbow always painted in three different colors, even it has seven colors in it.', 'So I had to stay with my friends one day longer than my plan.', 'If I had a chance, I would go there again.']\n",
      "464-471/2031 | total/used/cuda/res/ram (Gb): 10.00/8.83/3.00/7.32/22.65 | batch/sps: 8/14.11\n",
      "[\"The most impressive thing I've known through my investigation was that they didn't plan to move to Germany from the first.\", 'Most of my memories in Germany are related to alcohol because many German festivals is connected to alcohol.', 'One of the purposes of my study in Germany is to write my graduation thesis.', \"I went to London from 30th of December to 3rd of January to spend the new year's day with british friends of mine.\", 'My letter will be introduced by one of the graduate students at the last party.', 'But two reviewers checked my paper, pointing out many corrections, including English writing.', 'But, I forget lots of English, my own English skill is worse and worse.', 'I was very tired, as soon as I came back to my home, I got to bed.']\n",
      "472-479/2031 | total/used/cuda/res/ram (Gb): 10.00/8.84/3.00/7.32/22.65 | batch/sps: 8/12.39\n",
      "['I thought about an effective way for me to learn English.', 'Read some articles or books written in English, or try some vocabulary builder.', 'The site gave me a way of calorie counting of daily meals.', \"I'd like to talk about my experience of hands-free devices for cell phones.\", 'The part of the microphone was so small that it looked like a simple earphone, so it was very handy and stylish.', 'Previously, it showed me ads for Chinese conversation, which I had nothing to do with.', \"I'm into Jane Austen's novels these days, so I read 6 of her novels.\", 'Today is really tough day.']\n",
      "480-487/2031 | total/used/cuda/res/ram (Gb): 10.00/8.74/3.00/7.32/22.66 | batch/sps: 8/14.40\n",
      "['Today is really busy day.', 'My mother does not like him to do this.', 'I am practicing golf once a week.', 'When I learned at university, I understood that I had lots of fears and mental problems.', 'It was a very hard job.', 'You should eat the snow cone in a hot day, right?', 'I want a new one!', \"I'm happy not to go to work, but I have no plan.\"]\n",
      "488-495/2031 | total/used/cuda/res/ram (Gb): 10.00/8.77/3.00/7.32/22.76 | batch/sps: 8/18.85\n",
      "['In this weekend, I will study English as well as last weekend.', 'I have almost a month left for TOEIC test.', 'Especially it was a scene that a bus flew over 50 feet gap.', 'I guess that a person who decided these has a high position.', 'He decides to go to a bridge in Canada and study math on the brige.', 'I want to sleep, I want to sleep, I want to count sheep.', 'I left for a station quickly so I could get in the train in time.', 'Why did someone break into the rail on this rush hour?']\n",
      "496-503/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.71 | batch/sps: 8/19.39\n",
      "['I have to work beginning today.', 'This morning, I left my room with my new music player.', 'It had no sounds suddenly.', 'So, I had to buy a new one, and I did it.', 'I had to search the web for how to use Windows 7.', 'If it was early time, we would study in a library.', \"We can't cut apart between one vowel and one consonant and join some consonants.\", 'I have loved it.']\n",
      "504-511/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.66 | batch/sps: 8/20.51\n",
      "[\"However, I can't speak at all.\", \"Today's journal is a bit long.\", 'I have to say that Lang-8 has a very innovative idea.', 'Our son found a fruit at a Thai food stall and asked.', 'I always cook rice for our breakfast, but this morning I forgot that.', 'If the day when I can live in Canada comes, it is good.', 'I insist that happiness not only result from wealth, but love lays a solid foundation for it.', 'But, He was never given even a young goat by his father.']\n",
      "512-519/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.66 | batch/sps: 8/19.41\n",
      "['Besides, the older son must celebrate for such a younger brother.', 'If I have mistakes, please tell me.', 'I fix up temporary expedient on each occasion.', 'There are many women in Japanese department, this week.', 'At that time, I practiced yoga or massage.', \"I'm supposed to be on bed with a freshly new cold and a decisive resistance to insomnia caused by a bunch of homework to come tomorrow and next week.\", 'They are for the locals, cheap and most accessible.', 'My university is in the most busy and crowded town in Japan, Shibuya.']\n",
      "520-527/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.66 | batch/sps: 8/11.28\n",
      "['They can send to the address without a zip code.', 'I wander why there is this difference between snow and rain.', 'When spring comes along, it will get warm and people will be infused with energy.', 'If I write a diary in English, I will make mistakes, so I want native English speakers to see my dairies.', 'From now, I will have to read and write English papers and additionally, make presentations in English!', 'I hope to progress in my English more and more, so I will write diaries on this site everyday.', 'I got my learners license yesterday and I can drive legally on the public road with an experienced driver.', 'I often got rattled at intersections and when I found a parking car, I was often rattled.']\n",
      "528-535/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.66 | batch/sps: 8/14.70\n",
      "['It may be no exaggeration to say that studying is my hobby.', 'Five days ago, I went to see the professor who will teach me, and I asked his advice.', 'Also touring artists such as famous musicians and orchestras usually visit only the main cities in a region.', 'And I will be going to the school of nurse in April.', 'But I need money to play with my friends, to pay taxes on my car, and so on.', 'Please teach me, whether to use it or not.', 'I watched soccer yesterday.', \"I know English like that, because I watch many, many movies, and I accustom one's ear to English, like baby, I learn like a baby.\"]\n",
      "536-543/2031 | total/used/cuda/res/ram (Gb): 10.00/8.79/3.00/7.32/22.66 | batch/sps: 8/10.89\n",
      "['Hope somebody will find it and correct it!', \"I didn't study English for five days.\", 'I took my daughter to the hospital today because she had a skin problem.', 'But one act by one of them has gripped my attention so much that I like him in particular.', 'Can you derive any other interesting thing from this quote?', 'Posing him getting out of bed at the end of each hour to change his bed makes me smile.', \"You often use emoticons that stand sideways like the Sleeping Buddha, and I can't read them while maintaining the upright position.\", 'I am aware that it is just another faith, and I also have to confess that my conception of my god is not very clear or well-defined even to myself.']\n",
      "544-551/2031 | total/used/cuda/res/ram (Gb): 10.00/8.79/3.00/7.32/22.67 | batch/sps: 8/10.86\n",
      "['There are still other complexities, which I find too hard even just to explain.', 'I feel that Japanese men are especially in unfavorable conditions regarding the emoticons, because Japanese emoticons are very graphic and expressive, thus having additional girlishness compared to English counterparts.', 'It is not in the traditional Japanese punctuation, and actually just a recent introduction to the Japanese writing system.', 'If I want to hide it, what can I do?', 'Third, I want to know what he will do in his carrier.', \"He told me that it's common for Korean people to eat frogs and don't dislike them.\", 'Is it because of differences between national cultures?', \"I'm going to Halloween party tomorrow night.\"]\n",
      "552-559/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.67 | batch/sps: 8/10.36\n",
      "[\"I'm going to go to the party with my young sister and my friend.\", 'I have felt my normal body temperature is decreasing in these days.', 'My professor said my fluency is average, but accuracy is low.', 'I sometimes go to a sports ground for a jog after work.', 'I sometimes go to a bookstore in my hometown after work.', 'I went to AEONCAINEMA, a movie theater in Ota city, with my family in the morning today.', 'The adventure course, Kusatsu Forest Stage, has high wire adventure courses and you can enjoy rope bridges, tree swings and zip slides.', 'If you go to a shopping center in Japan, you enjoy snack shopping.']\n",
      "560-567/2031 | total/used/cuda/res/ram (Gb): 10.00/8.78/3.00/7.32/22.70 | batch/sps: 8/13.61\n",
      "['If you go to a shopping center in Japan, you enjoy snack shopping.', 'I want to improve my English and talk with many friends for in the street.', 'In the book, there are lots of words, idioms, or slang that I never knew or never used.', 'Reading books I am not interested in and writing an essay about those books are so annoying, probably for everyone.', 'I am studying abroad from Japan and have a homestay in America.', \"However, I'm too small person to eliminate it.\", 'She said she would use that money to get cosmetic surgery!!!', 'I heard a big sound.']\n",
      "568-575/2031 | total/used/cuda/res/ram (Gb): 10.00/8.79/3.00/7.32/22.68 | batch/sps: 8/15.32\n",
      "['I took part in a social gathering today.', 'Golf is one of my hobbies.', 'I have no money because I bought an iPad last day.', 'My husband took a summer vacation at the first week of August.', 'Do you know each ingredient of Osechi has a meaning?', 'You might be wondering why we eat shurimp to live longer.', 'The rule is very simple, and the strategy is very profound, and the experience of over ten years is necessary to become a master.', 'I decided college that I want to go in this summer.']\n",
      "576-583/2031 | total/used/cuda/res/ram (Gb): 10.00/8.81/3.00/7.32/22.67 | batch/sps: 8/12.81\n",
      "['Nice to meet you.', 'I think this is India because I heard that cow would wander on the road in India.', 'From now on, I will go to my new student to teach studies.', 'I have to go south campus from now on.', 'Then, I cooked for lunch and ate, and went to school.', \"I just couldn't read.\", 'I finally decided to take the IELTS 2 month later so I have to improve my English in haste!', 'And it is the 12th most populous city in the Kanto region.']\n",
      "584-591/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.68 | batch/sps: 8/13.55\n",
      "[\"Tokyo has many places to go and see, and I think there's something enjoyable for everyone there.\", 'I wrote this entry preparing for the writnig part of the IELTS.', \"So, If there's any word that is not used in the British English country, let me know please.\", \"Her birthday, which I didn't know when, turned out to be June 1st, and yes, it's today!!\", 'If you want to know more about Japanese, call me now.', \"Don't you think?\", 'I started to learn English 3 months ago and very interested in English.', 'I hope that helps me to accept a new job and find new friends.']\n",
      "592-599/2031 | total/used/cuda/res/ram (Gb): 10.00/8.95/3.00/7.32/22.68 | batch/sps: 8/15.11\n",
      "['I also want to watch films in the original, but I have problems with speech.', 'The other side, Freddy respects and values Eliza deeply as independent woman as he is so weak.', 'I like traveling, surfing the internet, chatting with my friends.', 'Although CMA functions like a bank account, it does not guarantee the principal.', 'Further studies on optimal dosage, side effects, and therapeutic mechanisms of axitinib are warranted for its therapeutic application to CNV.', 'However, in pathologic condition, a switch to the angiogenic phenotype may occur in which proangiogenic mechanisms overwhelm or circumvent negative regulators of angiogenesis.', 'On the other hand, activation of VEGF receptor 1 has been reported to both promote or suppress angiogenesis, depending on the tissue and context.', 'In this study, therefore, we investigated whether orally administered axitinib could exert its antiangiogenic function in laser-induced CNV animal model to evaluate its potential for the treatment of neovascular AMD.']\n",
      "600-607/2031 | total/used/cuda/res/ram (Gb): 10.00/8.95/3.00/7.32/22.67 | batch/sps: 8/8.20\n",
      "['My cultural hobby is reading books.', 'The rainy season, known as Tsuyu in Japan, has gone.', 'It is good that the laundry dries very much, but when I walk outside, I seem to be roasted by the heat.', 'Even though, Japanese is a difficult language.', \"It's very easy English, because it's for children.\", 'Thus, I ought to go back to face my dilemma as soon as possible, I can.', 'It looked so ridiculous.', 'Besides, I can space out and do other things, but just do some reading or thinking.']\n",
      "608-615/2031 | total/used/cuda/res/ram (Gb): 10.00/8.96/3.00/7.32/22.67 | batch/sps: 8/13.65\n",
      "[\"I seldom get contact with my longtime friends of many years because I don't know how to associate with someone who I'm familiar with.\", 'Most of all, we used electronic dictionaries and spoke awful English.', 'Above all, I should improve my English and do more practice constantly.', 'Above all, I should improve my English and do more practice constantly.', 'It is a Chinese historical event that a famous and important war during the end of the Han Dynasty.', 'It was a so much interesting thing at the start.', 'I think a good movie is not necessarily performed by a superstar or invested by much money.', 'The young man must learn how to be responsible for his job and life.']\n",
      "616-623/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.32/22.69 | batch/sps: 8/12.27\n",
      "[\"If I open the fridge and I find no giraffe, I don't have any evidence that a giraffe didn't enter the fridge.\", \"Or maybe this is just a lie that I'm keeping saying to myself.\", \"I have to do homework for that class, but I didn't yet.\", 'Eventually, HDD came back, and I could restore all photos.', 'I am writing about a PC game today.', \"But it's been ages since the last time I had an English class\", \"On the other hand, I'm looking forward to this experience.\", 'The voice of anyone speaking was very quick for me.']\n",
      "624-631/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/12.66\n",
      "['Because they could speak each other by their English.', 'Every time I taught him some Japanese words, he used them.', 'He said he got a new job and was preparing a new business.', 'Yesterday I played tennis with my friend for 2 hours.', \"If tomorrow is a good day, I'd like to go to my tennis lesson.\", 'And one Korean guy talked to me and exchanged our phone numbers.', 'My University has changed these subjects until now.', \"But I think it's good homeworks to improve my English for me.\"]\n",
      "632-639/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.32/22.67 | batch/sps: 8/22.90\n",
      "['When you get on the train in Tokyo in the morning, you will be crushed by many people.', 'Give it my all!!', 'I think that watching a movie is helpful for learning English.', 'Price and convenience are my first priority, and both Eva airways and Delta airline are convenience and good services.', 'It can be impressive if you learn about Thai customs and traditions such as greeting.', 'Meteor shower has romantic meaning in China because a song of a soap opera.', 'Actually, it was my daughter who came up with the idea.', 'As the days go by, I feel more embarrassed because I cannot speak English fluently.']\n",
      "640-647/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.32/22.67 | batch/sps: 8/17.44\n",
      "['They seem to find immediately we are mother and daughter.', 'Some customers come to our restaurant thanks to these cards, so this is a very important task.', 'In the afternoon, the pain became so bad that I could not walk.', 'He did not order and drink even any water I served.', 'The shop already went bankrupt in October, so I can no longer blame him.', 'We think we cannot expect that we have more customers than last year.', 'Today, my good friend told me that there is a good website to learn English called Lang-8.', 'They are still famous']\n",
      "648-655/2031 | total/used/cuda/res/ram (Gb): 10.00/8.98/3.00/7.32/22.67 | batch/sps: 8/16.86\n",
      "['I really love them', \"The companies fill in their employees' tax documents, and the employees check and sign, actually write their name and stamp their signets, on their tax documents to consent the documents are correct.\", 'But, I did not tell him because he did not want to listen to me.', 'But I did not see any necessity to go there, because the Agency which created by our company is not ready yet.', 'This is because I had a good new friends in parallel with my business.', 'Denmark was a very beautiful country.', 'I will practice more and want to go for perfect score!', 'It was a volcanic eruption.']\n",
      "656-663/2031 | total/used/cuda/res/ram (Gb): 10.00/8.97/3.00/7.32/22.67 | batch/sps: 8/9.48\n",
      "['When I remember that time, the memory is very fun.', 'When I was 7 years old, I learned to play the piano.', 'So if everyone will make a C sound in orchestra, then I will pipe a D sound.', 'These days, many mothers let their children to learn to play the clarinet.', 'My daughter and I went to a high school to listen to orientation session.', \"It's a terrible name, isn't it?\", 'I had seen in Fantastic Four, and now I am better than ever!', 'We, the rest of the world, made them or, with our negligence, let them turn into evil.']\n",
      "664-671/2031 | total/used/cuda/res/ram (Gb): 10.00/8.98/3.00/7.32/22.67 | batch/sps: 8/17.34\n",
      "['If they get too angry or drunk, they might hurt somebody that is not as tough as a dozen bricks.', 'I understand women practicing martial arts to compensate for their lack of strength but for men there are safer ways to stay healthy, unless they got their asses handed to them by women practicing too much martial arts!', \"I'm confused, so we don't have to worry about hell?\", 'If this is free-will, then slaves of man have more freedom than slaves of God because when slaves of man disobey they are only threatened with pain that will end with death, God threatens us with endless pain.', 'If inability to do wrong is good, then there was no need to create hell and eternal suffering.', 'I am now a university student.', 'Anyway, it was a good holiday!', \"I don't have internet in my dorm, so see you my skype friends!!\"]\n",
      "672-679/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.32/22.69 | batch/sps: 8/8.92\n",
      "['I was planning to study whole day, but around 12, my cell phone died.', 'If you are keen, please write down your Skype ID.', 'At the entrance of the gallery, there was a big christmas tree illuminated beautifully, and the sky turned to the night with grey sky.', 'I am very worried because I know that the application was not released for a long time after the status of many other developers.', \"To be honest, I'm slightly still confused how to use Tumblr, but hopefully I will be good at photograghy and upload fantastic ones!\", 'To be honest, I decided to put this part because I usually cannot finish my essay in time.', 'For example, in Tokyo, there are lots of foreigners and some of them come there to study Japanese.', 'They may insist that living in a small town makes people more comfortable and relaxing.']\n",
      "680-687/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/12.46\n",
      "['However, once I started cooking, I was not able to follow books because something that was not on them happened.', 'The other day, I tried the same recipe again and, I made a better one.', 'These suggestions were so beneficial because he explained logically.', 'In recent years, the sense of values has become diversified and people have a variety of opinions about benefits and disadvantages of building a huge factory.', 'To give an example, if a company constructs a new factory in a community, probably the factory will have to hire lots of workers and they start to live there.', 'Compared to what I was when I came here, my English has improved a lot.', \"I hope I won't feel sore for a long time.\", \"And what's more, we lost the game because 2 members of our team were kicked out.\"]\n",
      "688-695/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/11.85\n",
      "[\"Since I'm super lazy and my computer didn't work, I couldn't post my dialy, although I decided to write down everyday.\", \"It was kind of weard for me because I usually wear it as my team's official uniform.\", 'Anyways, I enjoyed it so much and it was so interesting.', \"Personally, I don't like that we have to pay tips every time.\", \"If waiters serve me very well, I'm willing to pay tips for them without any complaints.\", 'She is a very naughty dog.', 'Nice, I think, guys try their best to achieve their common dream.', 'Yes, I do want to finish myself.']\n",
      "696-703/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/13.14\n",
      "['Why it changed so violently and so urgently that what I cannot bear anymore?', 'The majority of the students come from language minority homes, and the program is more concerned with the perseverance of the minority language.', 'Students need to learn that words have definitions and that those definitions can be found in a dictionary.', 'I wish they just put the real price.', 'Therefore, the Thresholds Theory suggests that programs that allow children to learn using their first and second language are more effective and lead to superior results than those noted on other programs.', 'This theory is represented by the illustration of a house with three floors.', 'Do you think I should do that?', 'It feels good and makes me feel good.']\n",
      "704-711/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.32/22.67 | batch/sps: 8/10.49\n",
      "[\"I haven't taken TOEIC test for a long time.\", \"But, I didn't start that.\", 'Too bad, Japan would lose, and could not go to even round 16.', 'Takoyaki is made of flour, small pieces of boiled octopus, green onions, cabbage, small pieces of fried batter, pickled gingers.', \"I think it's not good for my health to keep up after midnight every day.\", 'Ah, I can hardly wait for the weekend to get enough sleep.', \"However, I don't like them because they have a heavy battery in them and I sometimes have to change the battery.\", 'All classes of his grade played a short drama in English.']\n",
      "712-719/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.32/22.67 | batch/sps: 8/12.18\n",
      "['My grandmother named her, and she apparently really liked her name.', \"And I'm afraid of ruining everything with my many thoughts and feelings.\", 'I will try to do my best too', 'Have you ever seen garden eels?', 'We enjoyed the cake during coffee break.', 'Basically, I work at home but sometimes at the office if necessary.', 'These friends celebrate my birthday every year.', \"Please check following lines and correct them if it doesn't sound natural.\"]\n",
      "720-727/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.32/22.67 | batch/sps: 8/22.51\n",
      "['Fortunately, I have no job tomorrow, so I can sleep after I finish this work.', 'Fortunately, I have no job tomorrow, so I can sleep after I finish this work.', 'All in all, media help develop society and increase our standard of living.', 'Therefore, my father decided to drive a car to pick her up.', 'The reason why I wrote this series is because I would like you to know Japan more.', 'I admitted that Japanese people got high scores in the world ranking.', 'Her pride prevented her from being honest.', 'I had to wait for a long time.']\n",
      "728-735/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/21.17\n",
      "[\"Phone's dictionary shows me that such word exists, so probably this child in fact is a godchild, but I'll ask anyway.\", 'Since I love dolphins so much, I was excited to go to the dolphin attraction.', 'I think one of the reasons is that kind of the same rules are written in most child-rearing books in Japan.', 'I am always impressed with high quality American drama.', 'In my software development industry, anyone can begin the company by $ 10,000.', 'I rented a books in the library today after a long time.', 'It was unusually hot day for this season today.', \"However, I can't secure a time for that.\"]\n",
      "736-743/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/13.40\n",
      "['Up to that time, my best score was 830, although it is max score is 990.', \"I really don't like this rainy day because of my clothes.\", 'I was in the middle of the chaos.', \"Now it's time to choose.\", 'And what about most of your people in your country?', 'So her grandparents, aunts and an uncle came home to celebrate her yesterday.', 'So, I can be willing to talk about any story with them.', 'They are willing to advise me which they already know many things about me.']\n",
      "744-751/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/17.22\n",
      "[\"Because new friends don't know enough about me, they may be hesitant advice for me.\", 'I am writing a project proposal as an assignment for my writing class.', 'In addition, I am sure that I can contribute my extensive knowledge of computers and Japanese skills to your company.', 'We will send new packages promptly.', 'There were many food shops which some of my friends managed.', 'At the end of the service, we all together to have a big meal, enjoying the delicious food including the Moon cake.', 'So I write it as soon as possible.', 'My old school lost the semifinals, but they played a good game.']\n",
      "752-759/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/15.11\n",
      "['By the way, traveling is the good possibility to improve foreign language.', 'That is to say, it would be enough safe to live.', \"I'll take three days off work.\", 'Why water can get hot and after a while get cool.', 'In the dictionary, I could not find a suitable translation.', 'In the dictionary, I could not find a suitable translation.', 'We should have always appeared in good spirits, especially at work.', 'Today I had a driving lesson with my boss and my subordinate.']\n",
      "760-767/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/26.46\n",
      "['Please come to play of', \"But we couldn't join because there were many students who made more softwares.\", 'So I just try it, Hopefully it can help me to improve my English.', \"I and my family are safe, so don't worry about me.\", 'We rode a bus and a train to there, and the train was crowded by the people who went to the Koshien stadium.', 'But from this season rice and other plants grow toward to autumn harvest time.', \"The exercise 'Tramporobics' is walking or jumping on small and personal trampolin.\", 'So I can join the circle while she takes care of them.']\n",
      "768-775/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/13.00\n",
      "[\"I went to my son's school and watched the English class.\", 'And my wife was hospitalized for depression.', \"I, of course, liked this program very much and couldn't wait next week to see the next portion of the story.\", \"Though I had heard about the story for a long time, I didn't know why this story had been so popular.\", 'But in this story, Jonathan does reincarnate to live higher life.', 'Like other Asian people, I take reincarnation as an ordinary thing.', \"It's an e-book reader and even though you can see the ad on Amazon in Japan, you have to go to Amazon in the U.S.\", 'And even many of them seemed to be crazy about their own Kindle.']\n",
      "776-783/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/12.26\n",
      "['Looking many websites, I found an interesting review about the reading speed.', \"Reading on Kindle, I don't have to care about the matter of printing at all.\", 'It was in the middle of the act one that a stout man named Figaro started singing cheerfully the very song!', 'The court was in an uproar, but spectators subsided when the judge asked to be quiet.', 'After meeting, I encouraged myself to speak to anyone about anything.', 'It is an outdated thought to discriminate against and be reluctant to be biracial in the age of globalization.', 'What do you need most if you want to recharge yourself with new skills and knowledge in order not to become a loser in the fierce competition in your work or your study?', 'They created 3 more albums, but in 2009 they decided to make a collapse in 2010.']\n",
      "784-791/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/10.51\n",
      "['Secondly, read the article again with fresh eyes and read it loudly.', 'Everybody has the ability to dream in one way or another.', 'The first important point is opportunity to find a lot of work.', 'For example, if you graduate from a good university and you want to find a famous company, you can find many companies there.', 'In my own country, I had very good life, whereas my life in Canada is very boring.', 'The song is very emotional and maybe you saw that from your personal experiences.', 'Tell the story and how you felt?', 'I was thinking, who is the most intelligent animal in the world?']\n",
      "792-799/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.32/22.67 | batch/sps: 8/15.30\n",
      "['A lot of families in Canada go outdoor picnics in the park and invite their friends to spend a good time.', 'We had booked a room in Hillton Hotel before we traveled to Hillton.', \"No one can see her because it's bad luck if anyone sees her.\", \"No one can see her because it's bad luck if anyone sees her.\", \"Actually, it's old rituals but now many brides like to do it as a fun day.\", 'On the right of her room, she is lying upon her bed.', 'The party consists of all men, and it is usually at a bar.', 'Once the bride gets to the alter, once she is in the room.']\n",
      "800-807/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.32/22.67 | batch/sps: 8/16.52\n",
      "['We were happy, though we had become tired very much, but we were happy.', 'In that lecture, the professor taught us about the supply and demand of energy on a global scale.', 'When you visit Japan, please enjoy different kinds of miso soup.', 'I hope to make friends with you here and help you study each other.', \"He was thinking of moving out of Israel because he didn't want his kids to join the army to harm Palestinians or harm their arabic neighbours.\", 'If you know, tell me that!', \"I don't want to join a company, but I do my own business.\", \"A mother's association for soldiers helped us to Kimjang.\"]\n",
      "808-815/2031 | total/used/cuda/res/ram (Gb): 10.00/8.98/3.00/7.32/22.67 | batch/sps: 8/12.79\n",
      "['I hope that Christmas is coming soon, and that everyone has a Merry Christmas this year!!!', \"I'm going to go to a cafe to read a book.\", 'I had a good time with my friends tonight.', 'The price of the restaurant dishes was down because of the 10th anniversary.', 'Previous image was too funny haha.', \"The story of the drama is a girl's success story at fashion magazine company.\", 'A man bumped into me and walked away without saying anything.', 'I have studied English for many years.']\n",
      "816-823/2031 | total/used/cuda/res/ram (Gb): 10.00/8.97/3.00/7.32/22.67 | batch/sps: 8/20.34\n",
      "['And there was a traffic jams when I was going to school on the road.', 'He has a nice personality.', 'On the other hand, I want to go to a foreign country to work.', 'I bought a new album yesterday.', 'Is there a rainy season in foreign countries?', 'There are a lot of knowledge to study something on the internet.', 'If religion can sometimes give people a sense of purpose and hope, if God makes people get peace of mind then people become confident.', 'I was given a lot of power from the people who suffered.']\n",
      "824-831/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/13.92\n",
      "['In the Golden week of this year, I would like to go abroad.', 'As I kept learning it like answering textbook questioners or listening tapes for long time, I was getting fed up and I forgot the reason I had been learning a language.', 'I realized I can learn it slowly and calmly now, so I guess I should thank my good environment.', \"To be honest, he is a trustworthy man, but I don't have any feeling about him.\", 'There were a lot of friends of mine who I met in there.', 'Maybe I have a date with him next week.', 'It was boring day.', 'I went to some places because I was enough better to walk.']\n",
      "832-839/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/11.11\n",
      "['I thought I wanted to ask more next time.', 'I will study English hard because I want to speak more.', 'I had a good time because we speak English and Japanese.', 'It is very difficult for me.', \"In order to meet my friend's baby, I went to her house with other two friends.\", 'I gave up doing the climbing because my hio was still painful.', \"But I couldn't meet the friend I wanted to meet, because I couldn't meet the vest friend I wanted to meet.\", 'We were really lucky because it was a fine day yesterday, but it was the long spell of bad weather recently.']\n",
      "840-847/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/15.77\n",
      "['Finally, I began to study English because I want to speak to a lot of people.', 'What a good chance!', \"She was so nervous, I couldn't hold.\", \"I have been uninteresting it because I wasn't progressing my climbing skill.\", 'I reassured myself that just a bruise would not be a problem.', 'I went to Hatune with my friend the day after a long separation.', \"I want to see my wife, so I'll go to their home from now.\", 'Just days ago, a student in 9th grade got arrested because he had broadcasted comics of ONE PIECE on youtube.']\n",
      "848-855/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/14.53\n",
      "[\"I sleep in all my day because of cold medicine, so I can't sleep now.\", 'I usually go to the library in my free time.', 'I think any other students in my library mostly study English.', 'I love my time alone.', 'Central courtyard of my university is one of my favorite spots!', 'One of the reasons is how kind residents are.', 'In review of the attached resume and autobiography, you will find that I am highly capable of performing this role.', 'By these work experiences, I hope that not only reinforce my profession skills and capability, but also stimulate the direction of my thoughts to solve many issues with crucial knowledge.']\n",
      "856-863/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/11.70\n",
      "['The noise stopped, they peeped through the door.', 'It can do so many things.', 'Final exam is coming gradually.', 'I should buy a red T-shirt.', 'Man hero of the movie was so nice.', 'To be frank, I do not know which industry I like to engage in between finance and marketing.', 'Here I want to stress that credit is the soul of running a company, service is its backbone and the comsumers are the nourishers of the body of management.', 'I joined a vital japanese study session the other day.']\n",
      "864-871/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/11.06\n",
      "['One day, my grandfather caught a turtle in a river and gave it to me.', 'S had to prepare for the upcoming audition.', 'In the evening, I went to another library to borrow some books about America.', 'Please try to adopt pieces of their advice and change yourself first for your development.', 'The camera made about 60 years ago.', \"I'm studying it by myself, and I have some difficulties in it.\", \"It's no easy to say by word my mixed feelings about this time of year.\", \"I have an English grammar book which I'm studying by this.\"]\n",
      "872-879/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.67 | batch/sps: 8/21.97\n",
      "[\"I slept over my friend's place in the city on Saturday night.\", 'Three times I kind of stood up on my surfboard.', 'I want to talk to them about a time when we were elementary school students.', 'I have never seen her since I graduated from elementary school.', 'Yesterday in the lift, I overheard a conversation between 2 middle-aged women.', \"My son's birthday is coming, but I think it's difficult to find a good birthday gift for children around 10 years old.\", 'LEGO may be little too childish for him.', 'It takes over an hour and a half to commute to work each way.']\n",
      "880-887/2031 | total/used/cuda/res/ram (Gb): 10.00/8.94/3.00/7.32/22.70 | batch/sps: 8/14.01\n",
      "[\"I heard it's not a rare case for business people in Japan, but I think it's crazy.\", 'Today, my daughter participated in a sports festival in her kindergarten, but unfortunately, I had a sick.', 'The book was very interesting that the minds got warm.', 'Today, I studied with my friends because my club activity is off.', 'We play badminton with teacher and friends in the school gym.', 'It is very funny and pictures are very nice.', 'He has not played with toys, yet he has enjoyed with them in his mind for good.', 'It shows that writing a journal and free writing is a good way to develop my ideas and to improve my English writing.']\n",
      "888-895/2031 | total/used/cuda/res/ram (Gb): 10.00/8.93/3.00/7.32/22.67 | batch/sps: 8/15.93\n",
      "['When he was a child, he watched movies with his toys and gave popcorns them, though he knew they could eat them, and he always played and slept with them as well.', 'Before I came to Canada, I had never thought that Canada was one of the biggest multiculturalism countries in the world.', 'Although there are some disadvantages of Google advertising, that system is obviously helpful for people to manipulate the information that they need.', 'In short, Google advertising is not only supportive for our lives but also unsafe in some ways.', 'If people continue using plastic bags, what will the negative effects be for the global environment?', 'As time went by, I could sing in those languages and my memory of these songs and lyrics could not fade.', 'I study and enjoy writing, or I can think in English!', 'He told me that he enjoys studying and goes to bed at 10 pm and gets up at 6.']\n",
      "896-903/2031 | total/used/cuda/res/ram (Gb): 10.00/8.93/3.00/7.32/22.67 | batch/sps: 8/10.12\n",
      "['It has so strong grape taste.', 'I was thinking of my stay in New Zealand over and over.', 'I need to study more besides going to school because I realized that going to school is not enough to improve my English language.', 'SDA teachers are always helping me.', 'The political achievement will be tied with the effect of protecting the environment.', 'Here we get together to learn one or two languages, we can communicate in a new language.', 'And if they break the rules at work, you must punish them severely.', 'When I write or read something, I can clearly see the grammar.']\n",
      "904-911/2031 | total/used/cuda/res/ram (Gb): 10.00/8.92/3.00/7.32/22.67 | batch/sps: 8/15.43\n",
      "['Anyway, she is the only one that I care about best.', 'She is growing young, but I am growing old.', \"I didn't stop, and I hit the chair.\", 'My right hand is doing a cast now.', 'I have difficulty when I eat, write, or wash my hands.', 'Today, I went to the hospital for my teeth.', 'Does following instruction make sense?', 'I wrote a journal here a few days ago.']\n",
      "912-919/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.69 | batch/sps: 8/26.11\n",
      "[\"And I couldn't get any corrections or comments from other Lang-8 users.\", 'I love playing tennis.', 'I am not good at English since I was a junior high school student.', 'The next moment, suddenly, a TV program had been changed into a breaking news, and that image was struck into my eyes.', 'I hope to get to KAIST graduate school.', 'After that, I found a place where I could sit down and study English or read some book.', 'I spent most of my time to memorize vocabulary.', 'In Japan, it is common to have a year-end party in December.']\n",
      "920-927/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.68 | batch/sps: 8/14.61\n",
      "['American white people are generally not liked in Poland, and considered overweighted, arrogant, and poorly educated.', 'Here is the reason why job-hunging in Japan is so complicated.', 'Tokyo is a big city in Japan.', 'The performance of a high quality was as I expected it.', 'The band that will do the concert tomorrow is the one.', 'I use a toy camera.', 'And I was glad because I watched it with Japanese subtitles and could understand what player said in English.', 'If I have the opportunity to go to foreign countries, I want to study about those as well as English.']\n",
      "928-935/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.68 | batch/sps: 8/16.06\n",
      "[\"I'm very tired because of a part-time job and I've just come home.\", 'I have seen it.', 'Since Edo period, A lot of people got on it to cross the river and see.', 'It is so beautiful.', 'Do you think so?', 'I write English on Twitter and my blog is easy, but talking is hard for me.', 'I sleep while listening to music.', 'His hair color is right brown and yellow mesh.']\n",
      "936-943/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.68 | batch/sps: 8/19.65\n",
      "['Especially, English word was studied because there was a word test every day.', 'I feel like eating again.', 'Recently, she became the tourism ambassador in Sapporo.', 'It is very difficult to continue writing a diary every day.', 'Got out of the hospital', 'Today, I won all of the battle, so I was happy.', 'From to-day on, I will write what I want to write in my diary.', 'With the platform, you can correct mistakes in their artical, give them your advice, to help foreigners to study your native language, while you could get a good feeling by helping others and get help from other friendly people.']\n",
      "944-951/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.65 | batch/sps: 8/8.90\n",
      "[\"It's nice weather today.\", 'I wanna improve my English for communication with others and gain more information, and make friends with more people.', 'Airtightness is low in the place, so I feel very cold or hot.', 'Recently, it has been very hard.', \"It was eleven o'clock.\", 'Einstein took notice light.', 'There is a general discussion these days over education in many collages and institutes.', 'I really got a lesson.']\n",
      "952-959/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.65 | batch/sps: 8/16.65\n",
      "['Next, we can play many kinds of games because if there are many friends, the games that we can do will be increased.', 'Maybe if our family is very rich, I will ask my father to go to South Africa to see the soccer game.', 'And, come back to home, take a shower, go to bed, and sleep.', 'However, although we are friends, he will be very angry because money is very important to their life, either.', 'Anyway, if you have to lend money, it is better to lend it at the bank.', 'Then do you want to know about my favorite food?', 'But I think it is bad if we eat Hamburgers and Pizzas so much times.', 'We should eat them sometimes.']\n",
      "960-967/2031 | total/used/cuda/res/ram (Gb): 10.00/9.04/3.00/7.39/22.65 | batch/sps: 8/14.09\n",
      "[\"But, if they see the other culture because you try to keep your own country's culture, they will think you are a kind of geek.\", 'She is a very amazing person.', 'About Versilles palace, I guess it is a wonderful attraction because it is a famous attraction, and it is kind of palace.', 'However, I want to see Affel tower the best because as you know, it is very famous around the world!', 'But, the people who disagree will say that then we can enjoy the club.', 'Some people claim that if we go to leisure time, it is better to plan for it very seriously.', 'Therefore, at that time, we have to decide the right choice quickly.', 'If we construct a new high school, the students will decrease each school, and then, we can educate them better.']\n",
      "968-975/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.65 | batch/sps: 8/13.23\n",
      "['However, B received a lot of money again because B bought the company and B can receive the money with working.', 'First, we can earn a lot of money and we have the way to receive money back.', 'By the way, some adults drink alcohol, smoke, etc.', 'By the way, some people claim that high school students can choose the class, but the other people disagree about that.', 'It will take a lot of money either way.', 'Next, they have to study basic things that we have to do.', 'Maybe many people climb up the mountains to know that feeling and because of this, climbing mountains become the commonest outdoor activities.', \"Thus, some children watch television after school instead of playing with friends, and they don't like to talk with their parents.\"]\n",
      "976-983/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.65 | batch/sps: 8/14.63\n",
      "['I guess most of you guys will watch televisions, because they are funny.', 'Do you think, although you watch television so much, you can talk with your parents?', \"Many children watch television so much time, so they don't have enough time to talk with their parents.\", 'After a few minutes later, our family arrived at the hot spring.', \"In school, teachers can evaluate the knowledge of their students with the exam, but all of the students don't have the chance to evaluate their teachers because students don't have any authority to evaluate their teachers.\", 'By the way, this teacher is terrible.', 'If we watch television so much, our eyes can be damaged because of the electromagnetic.', 'When we are addicted to comic programs, we can have all of the problems that I said before.']\n",
      "984-991/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.65 | batch/sps: 8/9.40\n",
      "['Yesterday, I went to the school-playground because of my soccer class.', \"However, when we arrived at the market, there wasn't any boots.\", 'So I went to school-playground with sneakers because of soccer class.', 'And when I arrived, we made snowmen and had snowball fights.', 'Because of this, we have to protect our earth and find a planet if the earth is destroyed.', \"By the way, there is a planet called Kkattabilra, and this planet's invironment is very good, so Kkattabilra people don't need to go to another planet.\", 'By the way, if you buy the soccer ball, you will want another things like a game machine, etc.', \"So when we parked, I ran with all of my powers to check the snow's existence.\"]\n",
      "992-999/2031 | total/used/cuda/res/ram (Gb): 10.00/9.06/3.00/7.39/22.73 | batch/sps: 8/8.97\n",
      "['In pension there were just one family.', 'When I was riding the sleigh, I felt very happy.', 'By the way, last family arrived.', \"If we can't control our company, we can't deal with some people or companies, and the workers will not believe you, either.\", \"Also, most of the workers will disagree about our command because if we don't control our company, they will not know about our authoritaries.\", \"If the boss is not kind, I am sure all of the workers will not like us, can't make a deal very well.\", 'Is there something that we can be healthy?', 'If we relieve all of my stress, we can concentrate better.']\n",
      "1000-1007/2031 | total/used/cuda/res/ram (Gb): 10.00/9.06/3.00/7.39/22.70 | batch/sps: 8/12.52\n",
      "['But, you can understand my essay, right?', \"Well, you can't know if you don't keep reading, but if you keep reading you can know about my favorite books.\", \"Yesterday a lot of used dishes were piled up at a kitchen and I couldn't bear those left for a day.\", \"I'd like to improve my written English skills.\", 'So I only have the free time when I get on the train.', \"I don't yet have the time to study English.\", 'Japanese creators make efforts to develop new and unique services, and I think some of those services will create new style of communication.', \"I don't describe the details of this film, because if you have never seen it, I want you to watch it.\"]\n",
      "1008-1015/2031 | total/used/cuda/res/ram (Gb): 10.00/9.06/3.00/7.39/22.70 | batch/sps: 8/15.31\n",
      "[\"Considering the title, I confused and don't get which is correct yet.\", \"What is this season's greeting in English in a e-mail or a letter?\", 'You may think when you start something, you should finish it.', 'But, when learning a foreign language, you should stop reading it if you think reading it is hard and you should stop listening to it if you think listening to it is hard.', 'I wish someday I find my dream that will need all the love I can give.', 'I like low-pitched and soft voices.', \"Today is a cold day, but this bird' songs brought spring to me.\", 'How many books in your bag?']\n",
      "1016-1023/2031 | total/used/cuda/res/ram (Gb): 10.00/9.06/3.00/7.39/22.70 | batch/sps: 8/10.82\n",
      "['They start to read a book, so you can read it without using a dictionary.', 'Then, you raise difficulty of a book little by little, you will be able to read popular books.', \"Maybe the word plays a important role in the sentence and you can't understand the sentence because you don't know the word.\", 'I read a shocking news today.', 'But when I was a junior high school student, I lost it.', \"If you can't understand some words first, you will guess the meaning of the words while you repeatedly see the words.\", 'I knew it was sour, but it looked tasty when I saw his eating and I sometimes ate like him.', \"Blue sand is beautiful, isn't it?\"]\n",
      "1024-1031/2031 | total/used/cuda/res/ram (Gb): 10.00/9.06/3.00/7.39/22.69 | batch/sps: 8/14.19\n",
      "['Hot steam hurts my eyes.', 'We may never see again.', 'But I hope the fragrance of lemon reach you.', 'When she was a high school student, she saw a photograph of suffering people, and she decided she would do something to save suffering people.', \"I can't believe videos on TV are real, they are like nightmares.\", \"When I correct someone's post in lang-8, I read others' corrections.\", \"The girl's father was killed by a rascal and her life became bad, but she will be married to a rich man, but she loves a man who had a tattoo of black lilly.\", 'When reading, as soon as you find a unknown word, you neglect and skip it, then look at the next word.']\n",
      "1032-1039/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.69 | batch/sps: 8/9.71\n",
      "['When I was a junior high school student, we forced to memorize it.', 'I found a pictorial of a set of Hinamatsuri dolls.', 'I went to the library with my roommate and read a few magazines.', 'It is determined by how many crimes are prevented beforehand.', 'I usually work at a bookstore, but I worked at a Tax office today.', 'After taking a bath, I checked earlier posts, eating an ice cream.', 'Today, snowing stopped and the weather is not a little colder than yesterday.', 'I think what I need now are yellow and red ones.']\n",
      "1040-1047/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.68 | batch/sps: 8/24.52\n",
      "['I have worn less than 20 times.', \"I am very happy to be here, it's a fantastic place that we can make more friends.\", 'Every Kanji has its own meaning, and most of them were made of a shape of natural objects.', 'It is fun to know what ancient people thought about and described Japanese nature.', 'He taught them to sing, beauty of living, and more.', \"I think Foreign movie's effect is wonderful!\", 'I think that is the most important trait a host should have.', 'She told me that she was in a summer camp and there was great!']\n",
      "1048-1055/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.68 | batch/sps: 8/17.11\n",
      "['It is worry whether I can follow a class tomorrow.', \"Of course, I have a lot of inconvenience things here, but it's for my poor English and my Visa.\", 'I expect that my dream of tonight will be very relaxing and happy!', 'I think that morning is a time for this song.', 'I think that morning is a time for this song because this song makes me feel cheerful.', 'Of course, a serene lifestyle is important.', 'Of course, a serene lifestyle is important.', 'I spent the day of 23 Sep almost on the sky.']\n",
      "1056-1063/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.67 | batch/sps: 8/15.55\n",
      "['Is the next sentence unnatural?', 'As I got older, I began to feel time goes by so quickly.', \"I'm just on lunch break.\", 'Today, I went to cooking class, and I baked bagels.', \"I'll be doing laundry now.\", 'I grew up listening to so many kind of music, and Western music is one of them.', 'Even though animal experiments have brought us many advantages, I am opposed to animal experiments because of the immoral behavior of the animals and often incorrect data produced.', \"Japanese foreign minister has announced his resignation because he had received a donation from a foreigner, who lives in Japan but doesn't have Japanese nationality.\"]\n",
      "1064-1071/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.67 | batch/sps: 8/13.54\n",
      "[\"Japanese foreign minister has announced his resignation because he had received a donation from a foreigner, who lives in Japan but doesn't have Japanese nationality.\", 'I felt an earth tremor again now.', 'I think the most frequent voice you hear would be Chinese following Japanese.', \"I have asked myself if the iPad would make me possible to do something special, and I couldn't answer to it.\", 'Anyway, I will support Lang-8 and hope that this service grows more.', 'And so many quakes I have been had since the big one.', 'I want to know how I should do with such a situation when I am in my house.', 'Of course, I could understand it somehow, such as what happened to people in the film.']\n",
      "1072-1079/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.68 | batch/sps: 8/13.92\n",
      "['This is a web service which provides a lot of movies and similar to YouTube.', 'I think that a lot of people who study Japanese like Japanese anime, so I introduce my favorite anime in this entry.', 'The monsters is so strong that female fencers are killed easily.', 'The monsters are so strong that female fencers are killed easily.', 'When my boss asked me at the meeting, I could not make it to answer in English.', 'If I can think slowly and configure the sentence, I could write pretty good English composition.', 'I decided to spend one more year preparing for the entrance examinations after I left high school.', \"I assume he probably can't make it through the corner from the ceiling to the wall.\"]\n",
      "1080-1087/2031 | total/used/cuda/res/ram (Gb): 10.00/8.98/3.00/7.39/22.70 | batch/sps: 8/15.91\n",
      "['It is our pleasure to watch her growing up every day.', 'The sound of her crying makes me and my wife get tired.', 'It is not a ballet lesson.', 'I want to make a good body!', 'We also went to Sushi bar after the meal.', 'In east Japan, we have little power.', 'Because we had a big earthquake and big accident at the power plant.', 'I use the bathtub even now.']\n",
      "1088-1095/2031 | total/used/cuda/res/ram (Gb): 10.00/8.98/3.00/7.39/22.67 | batch/sps: 8/25.76\n",
      "['By the time we arrived the shrine, We took the wrong train, missed our stop, and were out of breath from climbing the steep and narrow stone steps.', \"When native speakers listen to other contry's English, what does it sound like?\", 'I used to remember both the title and the auther of the book which I had read.', 'No matter how easy the book is, if you think it boring, it will be hard to read through.', 'It sounded as if he was a different character to me.', 'For example, someone who is blood type B is said to do things at their own pace, soon hot soon cold, hate to take orders from someone, etc.', 'I brought 2 kg strawberries to make jam the other day.', \"In particular, I'm terrible at articles because Japanese has no counterparts.\"]\n",
      "1096-1103/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/11.96\n",
      "['Native speakers think of an article first, then a noun follows it.', 'I had to buy a new part and assemble the PC again despite forgetting the detail of building it before.', 'I was beside her and really surprised.', 'To become able to speak English is very hard for me.', \"We set the air conditioner high because we don't have enough electricity.\", 'Aichi has a lot of unique local food cultures, and one is Uiro.', 'So the iPod touch is able to be connected to its Wi-Fi network.', 'We enjoyed a delicious meal and sake.']\n",
      "1104-1111/2031 | total/used/cuda/res/ram (Gb): 10.00/9.04/3.00/7.39/22.67 | batch/sps: 8/18.04\n",
      "['It will be opened to public from July 11, but we can watch it nearby now.', 'A taxi is waiting outside to take you to the Hotel.', 'My friend introduced me to this website, I cannot believe there is such a great place!', \"These days, it's getting warmer in Japan.\", 'However, I hate this season because I have a hay fever.', 'In the beginning of spring, there are lots of hay in the air, so my eyes and nose and throat and even ears are very itchy.', \"So I'm looking forward to going to the casino.\", 'I also think this is a good chance to study Korean.']\n",
      "1112-1119/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.69 | batch/sps: 8/12.73\n",
      "[\"Maybe I can't quit it immediately, but I can decrease little by little.\", 'The snow, my daughter and I make a snowman.', 'I never forgive them.', 'If they had marked carefully, I would not have been angry.', \"I want to be independent of my parents, but I don't want to get married.\", 'I think it is important that expressed appropriately in English.', 'This blog helps my language skill, I hope.', 'I just started studying the textbook last week and I realized I really need to put an a lot of effort for studying.']\n",
      "1120-1127/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/16.21\n",
      "['I have been busy since I was born for no reason.', 'The meeting place was at their office in New Port Beach and it took 40 minutes drive from our hotel in Torrance.', \"But I'm not good at speaking English as well as to hear.\", \"He's never hit me, or been violent, but whenever I complain about things he does, he feels he's accused or attacked by me, then screams at me.\", 'It took half an hour by car to the park.', 'However, I cannot understand what English speakers say anymore.', 'I trimmed the trees remaining untrimmed yesterday.', \"I would like to ask the factory's people a lot of questions.\"]\n",
      "1128-1135/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/11.88\n",
      "['On the other hand, luxurious shops such as department stores are suffering from the low business performance.', 'Do people think the economic situation would get better in the future?', 'I think that I should improve my motivation of work, but it is a little bit difficult for me.', 'I guess that the movie paid a lot of money to make a real action scene.', 'So, could you tell me the way to use it if you are ok?', 'If you are an Otaku, you just tell about it to Kakure otaku.', 'In my opinion, there are some standards for my future job.', 'But no guide will take tourists to there because it will take 3 hours and not all people could have enough energy to finish it.']\n",
      "1136-1143/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/15.08\n",
      "['Another reason can be seen by everyone is that optional class boosts the teacher to improve the quality of their teaching.', 'In brief, for those who can manage themselves well, an optional class will be helpful.', 'How could my parents agree me?', 'The time spent on homework of those subjects should have been spent in the library.', 'The nearest exam is in tomorrow morning.', 'I am always confident that my programs have no logical defects as a computer programmer.', 'Considering the economy, it is natural to be careful with new policy.', 'I tried to upload my photo and was able to see all photos temporarily.']\n",
      "1144-1151/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.68 | batch/sps: 8/18.53\n",
      "['I stick it out', 'I am sorry I wrote a strange diary.', 'In this site, I hope to keep on writing English and have a lot of friends.', 'Then I wanted to know how to do effective environmental assessment in Japan.', 'Adzuki is red and small, and used to red bean paste and so on.', 'So, I hope I really can help her and help her to be cared for.', 'Very bad today at school.', 'I usually never run out of things to talk about.']\n",
      "1152-1159/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/21.46\n",
      "['But before I left there, unfortunately, a bad accident happened around me.', \"Those who has asked for help probably gain more information and know the concepts better from the teacher's assistance.\", 'I am surprised that I got the pass mark in my CFM EXAM, therefore, the LAW EXAM result got a high mark as well.', 'If I choose only 1 from them, this means I abandon the others.', 'By the way, do you want me to bring mp3-files of the teaching company courses?', 'Actually, my main drive is to format my Mac for musical purposes.', 'Made me laugh so hard.', 'They are speaking in a good tone of English.']\n",
      "1160-1167/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/12.35\n",
      "['I waited to receive the mail, but I received the direct call to the person in charge.', 'I think the total cost for them was about 200 dollars.', \"That's reasonable price, isn't it??\", 'Therefore, I would like to write a part of the conversation between those people and me on my diary.', \"I'm not a worker either a student.\", 'During my undergraduate schooldays, I want to deepen my research theme.', 'When I am sad, I will deal with stress in karaoke!', 'I regret very much.']\n",
      "1168-1175/2031 | total/used/cuda/res/ram (Gb): 10.00/9.05/3.00/7.39/22.67 | batch/sps: 8/18.40\n",
      "['Although I have studied English by myself, my TOEFL score has not increased at all over the past year.', 'This is likely because the number of women who give up on their husband or who work and support themselves have been increasing.', 'Even TOEFL listening audio is difficult for me to understand.', 'Every time I spoke my opinion, most of the people tried to listen and tried not to interrupt my speech because they knew if they disturbed my speech, I could not speak well.', 'The opposite will happen in the depopulating society without policy.', 'In comparison, it should cut down the subsidies for the people who have more than two people, or if it tries to take stricter way, it might be necessary to impose a penalty to them.', 'I would like to concentrate on the study, including preparation for and review of the lessons.', 'First part is shown in the previous journal.']\n",
      "1176-1183/2031 | total/used/cuda/res/ram (Gb): 10.00/9.04/3.00/7.39/22.66 | batch/sps: 8/9.35\n",
      "['I studied nothing when I was in elementary school, and so almost all Japanese did.', 'I studied nothing when I was in elementary school, and so almost all Japanese did.', 'For the time being, I present to make a gift voucher.', 'Please push cancel button.', 'Speaking in English is much more difficult for me than writing.', 'However, I love to speak in any language.', 'However, four pizzas were served!', 'It is very important that I can make text data like this everywhere I can put on it and I can type with my both hands.']\n",
      "1184-1191/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/13.38\n",
      "['Odawara castle is very beautiful at sunrise.', 'This is very easy thing.', 'Franklin planner is too big for me.', 'This is very reasonable and match with beer or Korean shochu.', 'She is one of the most famous female singers in Japan.', 'I think the depth of friendship change deeper when we have common purpose or pain.', 'I like house cleaning very well.', 'This is a very beautiful story.']\n",
      "1192-1199/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/21.30\n",
      "['On festival day, the shinto priest moves the god from the main shrine to a portable shrine.', 'And, I went to a Irish pub to watch a rugby game again with my friends at night.', \"I got angry because it wasn't the one I wanted.\", 'In retrospect, my parents might not have enough money to buy a parrot.', 'So after the festivals, many kingyo in vinny bags are left around there.', \"Though I didn't want it so much, I thought it would die soon if I didn't help it.\", \"When my father phoned to me, he didn't have anything to say.\", \"Though I wasn't interested in it, I was glad my father to want to speak with me.\"]\n",
      "1200-1207/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/16.13\n",
      "['I want to change my life, so working hard, studying diligently.', 'The main subject was economic difficulties.', 'It was a good movie.', 'He is snooty and dirty old man.', 'New computer is useful.', 'And it is light and small, and it is light and small.', 'I called to my doughters and asked them to help me.', 'Next sunday, we will play with the next team.']\n",
      "1208-1215/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.68 | batch/sps: 8/25.85\n",
      "['If we win to 3 teams, we will be the champion.', 'According to the news, the boy bought the gun by his friends.', 'On the other hand, some people dislike libraries because it takes a long time to look for the book which you want.', 'In addition, we can use machines, but also we can ask librarians where our needful book is.', 'I work at a Japanese bar, and the work is so hard.', 'I am writing to you because I want you to deal with a problem of this house.', 'There were some earthquakes near Yokohama, but my town is safe.', 'I go to university in Janagawa prefecture, my major is English.']\n",
      "1216-1223/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/14.74\n",
      "['We would be very grateful if you could understand our reason.', 'In my case, my mother has never forced me to do something.', 'It is generally accepted that state do not have to make parents immunize their children.', 'Some people do not have enough money to immunize, but thanks to the government, everyone can take it.', 'Could give me any advice or help??', 'At last, I will take you to a famous restaurant.', 'So if we experience a sad relationship, it will help us in the future.', 'I tried to convince him to spend more time to identify the cause of the wrong, but he did not listen to me.']\n",
      "1224-1231/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/15.28\n",
      "['Firstly, the new boss is not good.', 'I will be able to return the book during two weeks.', 'Because, you may lose your all money.', 'Her costumes also sexy and unusual.', 'I created my search memo program.', 'Anyway, we can live normally in Tokyo except for these inconvenient.', 'But it seems to be that I could get some clues through conversation with them.', 'I never obey who filled with lies.']\n",
      "1232-1239/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/25.21\n",
      "[\"It's okay 'cause it's a happy ending.\", 'There are some reasons.', 'Generally, many bands have shows with bands which are the same genre.', 'They are Japanese rock band based on hard rock, metal.', 'When I was a child, I used records and tape recorders to listen to music.', \"In Japan, we can't watch them a lot on TV.\", 'I feel it is a good site.', 'And they wish for American dream to become singers.']\n",
      "1240-1247/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.66 | batch/sps: 8/22.76\n",
      "['Some students come to me and ask, then I answered or talked about my job and my company.', 'I wonder what I should do if I made a mistake on the stage.', 'I am enjoying last 6 hours of my summer vacation!', 'Any other computer or internet activities are done by iPod Touch with WiFi.', 'Today, I had a rest time of a few hours and walked around in my HDDs.', 'After my breakfast, I did some reading for about two hours.', 'If I can read German, then I can scan their news form their country and also can read what they said.', \"Still, it's very cold in the morning.\"]\n",
      "1248-1255/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.68 | batch/sps: 8/16.34\n",
      "['This experience directly shows that traveling with friends helps me to get more information about the place I visit.', 'At that time, I felt that if I had my own electronic dictionary, I could have finished translating.', 'Yesterday, a friend of mine recommended me this website.', 'Firstly, I am eager to learn English by participating and sharing knowledge.', 'The commercial user of the new model views a different design.', 'Certainly the newer models have got an improved technical standard, but are pretty much the same.', 'In my opinion, they are getting more and more useless and are therefore replaced by new communication instruments like mobile phone or the Internet.', 'Today, I joined an International party to make a friend.']\n",
      "1256-1263/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/14.82\n",
      "['I think I will join this party again.', 'After that, we took a lot of pictures on our way to Houston zoo.', 'I advised her that her habit is bad to her health because I am registered dietitian.', 'The union members tend to see them as weak persons and hesitate to tackle the problems.', \"I think I'll be hooked on this new toy for a while, and will post experiments with new features.\", 'I was testing the Japanese Analyzer I introduced in the last post and found it to classify unknown words as interjection.', 'And I had thought I was smarter than students who had studied at the college just because I had transferred.', 'You can just pronounce You and me quickly, then you got my name.']\n",
      "1264-1271/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/16.23\n",
      "['Whenever he is willing to help me and hear me, and I am willing to listen.', 'She is always busy because she always finds something to do.', 'Whether or not we can win the tournament this year, all depend upon how technical we control the times and how effective training we have in next 3 weeks.', 'They let me feel happy, and they let me not feel lonely.', 'He never pushed to know about his God, and he understood that I like Japanese gods.', 'Is it international law?', 'Kyoto is famous for its ancient capital and has lots of temples and shrines.', 'Because I just returned to my university, I performed an easy experiment and several preparations.']\n",
      "1272-1279/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.68 | batch/sps: 8/12.50\n",
      "['She was kind to teach me.', \"Although I don't believe about that, sometimes my friends talking about that can influence me.\", 'I also hope you all will bear with me and cheer me along!', 'It takes me 30 minutes from my home to my office by bus.', \"I don't know how it begins and what I should do first.\", 'We seldom see each other, because the way from Orenburg to Naberezhnye Chelny takes 11 hours.', 'I took an English test yesterday evening by an English training institution.', 'They have been taken care of by my wife.']\n",
      "1280-1287/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.67 | batch/sps: 8/14.81\n",
      "['Oska was famous as the most polluted town, but this city has been changing recently.', \"That's why we must be active to protect the earth consistently.\", 'All I have to do is to make efforts every day!!', \"I don't intend to agree with the opinion because we have more strong points.\", 'I hope they like it.', \"These days, always very hot, and I'm sleep all the time.\", 'Next day, my boyfriend tried to bake the same thing for me.', \"We enjoy the time just looking at the sea, it's very relaxing for me!\"]\n",
      "1288-1295/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.67 | batch/sps: 8/21.63\n",
      "['There were few people doing windsurfing.', \"Although I don't have any plan yet, I think I'm going to spend with family and my friends.\", 'Since my husband and I started to run English language conversation circles, every week we have to think about what we should do and do some advertisement.', 'I just watched the news and I was horrified.', 'Two years later, he proposed me.', 'If someone is interested in studying in Japan, consider this university!', 'I went to see because I heard the news that the Christmas market of Northern Europe style is open.', 'But, the bicycle shop staff did not demand to submit the written guarantee.']\n",
      "1296-1303/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/13.43\n",
      "['Many talented people are supporting the Indian economy.', 'The fame of that diet made many Japanese females eat bananas, but now they move on protein jelly.', 'Because of cell phones, our lives have changed.', 'I also have to write about the reason why western foods became popular in Japan.', 'In my opinion, Japanese are said to be the busiest and the most modest race of people.', 'Do you think now Japan has no power to the world?', 'Now Japan has a big impact to the world and Japan is the richest country in the world and Japanese students do not study hard because the atmosphere allows us not to study hard.', \"Even if I decide to buy it, it will cost over 5000 dollars because I don't have a motorcycle license and it takes 1000 dollars to get a license.\"]\n",
      "1304-1311/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/10.94\n",
      "['Not only various kinds of professionals but also technologies came into Edo.', 'A new technology has developed such as a sword, paper and sushi.', 'Because we can improve our English ability and make friends all over the world by it.', 'I hope we can get a lot of knowledge on the website.', 'To tell the truth, it is forbidden to have an animal in my apartment.', \"This isn't really a text that needs corrections, this is just an entry to show you a great video for japanese learners!\", \"I chose a special scene where the french guy starts swearing, and the english guy can't understand.\", 'Thanks for correcting me, and if you guys have any advice to make my English look fluent with some expressions that I should have used, please tell me!']\n",
      "1312-1319/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/11.55\n",
      "['The most interesting dance is rhythms, but it is also the hardest part.', 'I became 19 years old.', 'It was my turning point of my life.', 'In French, every subject has the different forms of the verb.', 'In addition, we can see the beautiful bey and the lively volcano.', 'My school is approaching, and the vacation is ending.', \"Because the first meeting is not compared mutually with friends' results, it is safe for the opposite effect.\", 'So I went there and looked around.']\n",
      "1320-1327/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/17.93\n",
      "['He had taught cultural geography at University for 35 years, until he retired.', 'Do you understand why it was said so?', 'I feel the taste of luxury restaurant.', 'I wanted to know a reality, is he a bad man??', \"I can't write a diary in weekends, so I'll struggle next week.\", 'Because I did not go out, and I slept about twelve hours.', 'To learn foreign languages we should be brave to make mistakes.', 'It should be a special experience for me because it was the first time I swam in the swimming pool.']\n",
      "1328-1335/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/17.71\n",
      "[\"Actually, I didn't know it, either, until mama told me that she had enjoyed the taste of azalea when she was still young.\", 'People might oppose my idea by saying that thanks to the tremendous developments of ecnomic can we live in this colorful and comfortable society.', 'I hold the belief that we will find a solution to preserve our natural environments hand in hand with the development of economic.', 'Protecting our environment and suppressing our greed that we learned from the movie can help us to build the Pandora, which belongs to our human beings.', \"I need to use this topic to write an article, but I don't understand it.\", 'He helped me with my mathematics since we were freshmen.', 'Should teachers show their political or social views in the class??', 'What they thought and what they believe affect students directly who consider the teacher as a hero.']\n",
      "1336-1343/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.69 | batch/sps: 8/12.67\n",
      "['People lived there loved him and admired him.', 'Challenging plans can motivate us to strive forward more efficiently and effectively than practical plans.', 'On the last weekend it dropped more than 10 degrees Celsius above.', 'A park is very large and a lot of greenery.', \"I can't stand them, nor can I tell them about that.\", 'I have confidence that I can cope with some degree of defference.', 'Are you always on time for your appointments on are you sometimes late?', \"I'm a musical lover, so this drama is a good learning material that I can learn English while I'm having fun.\"]\n",
      "1344-1351/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/14.96\n",
      "['I copied these DVDs subtitled in English onto my iPod, and enjoy them in a train.', \"Smile brilliantly and say 'Thank you', then, happy days will last!\", 'I translated the below Japanese to English a few days ago.', 'In my memory, he was always a great leader who never gave in to.', 'I guess his flexible strength is rooted in his family.', 'I heard that scientists from China want to help this people.', 'I love a man who wears a yukata!!!!!', 'Today, almost the war broke out.']\n",
      "1352-1359/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/21.04\n",
      "[\"I can't remember where I lost it.\", 'The movie was the one my office staff recommended us to watch because it was related to my town.', 'I sometimes checked my watch because I thought I wanted to leave the movie.', \"I'm very glad if you read this diary and correct my English!\", \"At first, I couldn't what happened on earth then I knew through radio that a big earthquake happened at tohoku area.\", 'Although we have these bad weather conditions, there is one nice thing.', 'When I tell you about my work, there are three points.', 'If unexpected data are shown, I start working on planning again.']\n",
      "1360-1367/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/14.44\n",
      "['It needs hard work, but it is worth doing so because I can work in the fields which no one can know.', 'Andmore, it was fun to read the poems from various people across the world.', \"Today, I saw my fond person, but I couldn't speak to him.\", 'After class, I go to my office.', 'I was surprised that my device returned within 48 hours after shipping.', 'I was satisfied with quick response of Apple support program!!', 'Today we held the college drinking.', \"I don't know the detailed result of it yet, but I don't have abnormality in measurement examinations.\"]\n",
      "1368-1375/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/16.77\n",
      "[\"My washer tentatively has function of the drier, but it is noisy, so I don't want to use it if I can.\", 'It was flavored with soy sauce.', \"When holding a sword, the player naturally can't use items and can't even run well.\", \"Too many things want to do, but didn't know how to start.\", 'Next year, I have to take the same class and exam.', 'I live in Tokyo, so I and my family are safe in the earthquake.', \"I'm not good at writing and speaking English, but I hope I can become fluent.\", 'Money is important, but I think friengship is more important than money.']\n",
      "1376-1383/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/13.19\n",
      "['I hope you enjoy teaching me English.', 'Medaka is very popular for us, for there is a Medaka song which they teach us in elementary school.', 'At that time, there were so many people watching my performance and I believed I heard my deep breath.', 'Oh, I will have a match next week.', 'There are more than 100 letters that I have to write.', 'Yesteday, second term finished and I came back to my hometown with my bag packing textbooks.', 'Although hourly pay is not enough, I am satisfied with the job mainly because my boss has a good personality and students are cute.', \"Third, I can easily put on clothes because I don't need a coat in summer.\"]\n",
      "1384-1391/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/15.12\n",
      "['I was not sure what to do about her because I was driving.', \"Let's use everyone.\", \"Let's use everyone.\", 'This essay will discuss the key reason for my opinion in greater detail.', 'So, I just drank out today!!', 'Anyway, I have never gone abroad.', \"Whatever you haven't tried seems difficult.\", 'Hokkaido is located in the northern part of Japan.']\n",
      "1392-1399/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/27.49\n",
      "['Play the movie, and say what an actor or actress says at the same time.', 'I need to be trained for no payment until I learn a job.', 'It is really amazing that a guy who is from Japan met a guy who lives in Toronto through Lang8.', \"We couldn't move at all even our arms!\", 'I work in a souvenir shop!!', 'He said he wanted to make a documentary video about Toronto music scene.', 'It is really amazing for Japanese!!', 'I really need a job, so I really need to do job hunting.']\n",
      "1400-1407/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.68 | batch/sps: 8/18.05\n",
      "['Everything will be okay If it can make me be crazy.', 'I will go there next week!!', 'I want to get a single-lens reflex camera for a long time.', 'She has a very individual sense.', 'And she has really beautiful body.', 'But, I want to study yet.', 'The band, which was formed by friends at part-time jobs, performed.', 'I also sang one song, but the lyric slipped my mind.']\n",
      "1408-1415/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.70 | batch/sps: 8/19.05\n",
      "['Yes, I supposed to clean my room, but I fell asleep today.', 'I tell him that, and he said thanks to me, giving a bitter smile.', 'I was very familiar with snow in Hokkaido, but in Tokyo.', 'So, I flinged out my room and took a lot of photos as soon as I knew it snowed.', 'Of course, I also will be good helper to someone who wants to learn Korean language.', 'By the way, Japanese rarely use facebook because we are too shy to represent our real faces and names.', 'Instead, we use mixi, the most popular SNS in Japan.', \"I'd like to go there next year again.\"]\n",
      "1416-1423/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/15.27\n",
      "['They do nothing but make a mockery of papers or reports.', \"They don't return to Japan after graduates and sign in companies in the country in many cases.\", \"I'm in my hometown, Miyazaki now.\", \"Hot soymilk usually helps me to sleep, but the soymilk magic didn't work today.\", 'The programmer went away yesterday.', 'I went to sushi restaurant in Tsukiji the other day.', 'I ate tuna, hirame, ikura, and much of the shellfish and fish.', 'I have a relaxed time with my favorite herb tea latte even morning.']\n",
      "1424-1431/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/17.54\n",
      "['We have no autumn this year.', 'I think a kitty is a queen and a dog is a friend.', 'So, many teenagers, including me, were so sad and some of them followed him and suicided.', 'We watched it seriously and drew into the world of AVATAR.', 'They were quite real and made me get a desire to stay in the world.', 'When I got to the office, I felt the aroma of coffee.', 'When a pink bear turned out to be the boss of enemies, a boy sitting in the front of us began crying!', 'But, when I go back to Japan after two years and find a new job in my country, it is likely that the condition of the job market in Japan is better.']\n",
      "1432-1439/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.68 | batch/sps: 8/10.73\n",
      "['But, when I go back to Japan after two years and find a new job in my country, it is likely that the condition of the job market in Japan is better.', 'This experience will help me smoothly work with international colleagues and clients in your global organisational environment.', 'The furniture of my house was shaking, and some dishes were broken.', 'But seriously, the earthquake was the biggest one!', 'Even though it is not my favourite festival, I was incredibly pleasant today!!!', 'That fresh me very well.', 'This is a fashionable promotion because more and more people own a car now.', 'Befor I met him, I was not interested in living with any animals.']\n",
      "1440-1447/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/10.39\n",
      "['It hurt the fishing industry because they used a lot of oil to work on a ship.', \"If you select a rhythmic song, it's all right!\", 'I have played it for 6 years, and I like it very much!', 'People who become 20 years old in this fiscal year will attend to the coming of Age ceremony in January 12, 2009.', 'People who become 20 years old in this fiscal year will attend to the coming of the Age ceremony in January 12, 2009.', 'I am a member of this group, too!', 'I am a member of this group, too!', 'Do you like baseball or other sports?What team are you favorite?']\n",
      "1448-1455/2031 | total/used/cuda/res/ram (Gb): 10.00/8.99/3.00/7.39/22.67 | batch/sps: 8/15.90\n",
      "[\"Actually, I don't like doing it, but I have to do it.\", 'Now, I am using the computer of the library.', 'I prefer writing in English to listing, speaking and reading English.', 'I decided that which camera I would buy depends on not the feature, but the price.', 'It was a good experience.', 'They were lighting a small stove, when they heard a rumbling noise.', 'Lake, Yamanaka is a cool place in summer.', 'I want to see that the japanese team wins the next game.']\n",
      "1456-1463/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.67 | batch/sps: 8/22.22\n",
      "['I did two years of postgraduate studies and, then, did a complementary course of Acupuncture for Mental and Emotional Disorders with a duration of one year.', 'This holiday season, I will do the test for 3 kyuu.', 'I want to make more friends here and use more this language.', 'Historically, real odd people wind up in hospital or in jail.', 'So, I just sit on the sofa and read the books on dogs, which is much suitable for me!', 'The economics would keep growing and the younger generation would become wealthier, we thought.', 'We like him because he teaches us English easily and kindly.', 'Paper test has 120 questions about management, finance and personnel things.']\n",
      "1464-1471/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.67 | batch/sps: 8/12.89\n",
      "['Friends of mine asked me whether I join Kendo club or not.', 'Now, the Internet brings us a lot of information, but I think it is not enough.', 'I am a Japanese high school student.', 'I have a dog, a great dog!', 'Many people waiting had a lunch box to expect to eat while watching the cherry blossoms, but we doubted that we could not have a space to put a picnic rug.', 'I had to meet him a few times, and I talked to him.', 'Baby alpaca is very warm, soft and comfortable.', 'Seriously, I should stop buying anything related with Japanese grammar and kanji.']\n",
      "1472-1479/2031 | total/used/cuda/res/ram (Gb): 10.00/9.00/3.00/7.39/22.67 | batch/sps: 8/11.62\n",
      "['This time, I originally planned to go with my wife, but unfortunately, she cannot join me due to her job.', \"I'm a little afraid of that because you know that I'm well known for stage fright and I will have to speak there minimum 15 minutes!\", 'Should I take a video camera with me?', 'Since I was about 15 years old in middle school, I began to learn English.', 'We both like to find and learn new wards in respective languages.', \"I have learned English composition for the last 2 months, but it's very difficult.\", 'He told that he was discharged from the military service.', 'What a wonderful day is not it?']\n",
      "1480-1487/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.67 | batch/sps: 8/13.21\n",
      "['They were so active and vibrant more than I had thought, and they were so kind for Japanese backpackers including myself.', 'I hope that I would work in China as a professional worker in the near future.', 'Spring is a very good season.', 'On the web page, each student can send and get the information about the furniture and household applications.', 'The price of the set is only the price of a coffee.', 'I was not able to keep my diary for three days, but I will keep that everyday from today!', 'To participate in this party, we have to bring something to drink or eat.', 'Friday, I went to dinner with my friends, and I had nashigoren.']\n",
      "1488-1495/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.68 | batch/sps: 8/15.44\n",
      "['My spring vacation is over.', 'My senior and international student teach us English.', 'I cannot speak English well, and I cannot say that I want to say.', 'I was not able to keep a diary for a long time.', 'I want to go see the cherry blossoms next year!', 'So I want the weather to clear.', 'The day before yesterday, there was a sports day.', 'The main reason is that iPhone applications can only be developed on a Mac computer.']\n",
      "1496-1503/2031 | total/used/cuda/res/ram (Gb): 10.00/9.01/3.00/7.39/22.67 | batch/sps: 8/22.78\n",
      "['I live in Australia now and love in here, but sometimes I want to go back to Korea.', 'I really appreciate that and feel more familiar with the people in Taiwan now.', 'This drama is about a girl who works at a fashion magazine.', 'If only is a very beautiful love story.', 'I was tired because Berlin zoo was very large.', \"Today's my event\", 'No matter how hard you worked, someone who was in a rich family or led a huge company, can easily beat you as trampled.', \"Global crisis, London Fashion week, lections in the university, my friend's troubles.\"]\n",
      "1504-1511/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/12.88\n",
      "['Today, I came here for the first time.', 'Come to think of it, My Australian fiend, Son came to Japan and stayed at my flat for a week at the beginning of February!', 'If there is the thing that is not found in our own culture, we can be interested and ask why, or if there are similarities with our culture, we can share.', 'I send her an e-mail.', 'I try to get a teaching license.', 'Subject is social studies.', \"I'd like to introduce myself in this class.\", \"I'll write an e-mail again.\"]\n",
      "1512-1519/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/11.68\n",
      "['When is the best time to visit there?', \"So Japanese high schoolgirls seem to be cold because Japanese high schoolgirls' skirts are very short.\", 'Today, I will write about the winter vacation event.', 'I have been getting a toothache since yesterday.', 'I let her go to a good family.', 'So I want to speak and write English very well as she speaks.', 'I saw them at the reunion for a long time.', 'I will go to Canada next month for language study.']\n",
      "1520-1527/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.68 | batch/sps: 8/17.93\n",
      "['What kind of company do you like to work for?', \"I don't think I can get a nice job when I return to Taiwan at that time!!\", 'ROOKIES is a popular drama in Japan.', 'There are some festivals and events.', 'Moreover, there is an idea that the capital punishment stops new cruel crimes.', 'There is a fact that people begin to think about their crimes when they are given the capital punishment.', 'Even though his opponent, of course, was a good boxer who was Clotty, Manny showed one side of his game.', \"Often, I can't help but wonder who I am living for.\"]\n",
      "1528-1535/2031 | total/used/cuda/res/ram (Gb): 10.00/9.02/3.00/7.39/22.67 | batch/sps: 8/15.30\n",
      "['I am aware that one of the reasons that I could think this much is because I never suffer from hunger or debt.', \"I'm madly busy for work these days, but I think of you all the time.\", 'It is so good and rising of the rotational speed is good!', 'I had a lot of them in childhood.', 'For example, indeed cell phones are very convenient for us to communicate with others in a distant location.', 'I have a black belt.', \"I don't agree with them because two months ago I found a perfect Polish band which plays music exactly in my type.\", 'We hope that new employee will bring something to our company and be highly committed.']\n",
      "1536-1543/2031 | total/used/cuda/res/ram (Gb): 10.00/9.03/3.00/7.39/22.67 | batch/sps: 8/16.16\n",
      "['I was very pleased to find she was doing her best in the show.', 'If you are living in Italy, could you help me please?', 'First of all, from you read just to found in the poems or novel what well-known critic have already found out, you lose the pleasures of reading something which is expecting to be a new experience to you.', 'Their research showed that before Hurricane Sandy only \" about 50 percent of residents used the emergency departments, \" and \" only about 35 percent sought inpatient care there and less than 10 percent used the hospitals when needing surgeries with any kind. \"', 'It has been widely blemished tha every student interested within some subject which might not be interested by other students so it is difficult to force students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue.', 'This is why I totally agree like the following comments: \" My upbringings teach me to be calm and easy-going - I really appreciate but now \". First of all, I agree with this person, including I think that the ways someones has been brought up has had a great influence on his life.', \"Yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I don't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planned to go on the shopping again tomorrows, maybe today beyond the afternoon.\", \"I've checked the prices as well, it's about 2000 for the whole sets, so I am really sorry, but I couldn't come and help the day before, I have to help my parents out, because they are going out within the weekend.\"]\n",
      "1544-1551/2031 | total/used/cuda/res/ram (Gb): 10.00/9.17/3.00/7.53/22.67 | batch/sps: 8/4.63\n",
      "['I give this example because in many classes I have seen teachers make decisions throughout children based on their gender and it is not our place to make decisions after them.', \"I know how worried you are, take it easy! If you like the countryside, you've better to go to a small schools, but I thought around it are not the best choice for you because you like noise, cars, and tecnology, so I think you will choose the centre along town, downoff additions you like the large buildings because you like running along the areas, don't you?\", 'I realized beyond this attitude would destroy me, and at this points my views of happiness shifted in a more realistic way, acknowledging happiness was step through steps process of overcoming challenge.', 'When you will deeply think about positive things, you will find another advantages like you solving actually any problem or troubles which you have, and I can forget to mention the most important thing and it is called beyond help of phone.', 'However, the disadvantages for the cars banning upon the city center that polulted and now the cars are effects on the environment and the people life becausethe cars working with gases or petrol as a result, mak the poluted in the city and the wither will be very bad when a lot concerning cars moving in this areas every day and the worst disadvange was the accident cars it will be increasing every day especially on the small streets towards the city center and the people will be disapointed when the cars bother them.', 'Hi Dan We are going to go around \" Cinepolis \" I\\'ve seen a very beautiful film and I want to see it again, the film is \" Los increibles \" it\\'s a funny film I am sure you are going to enjoy, we\\'ll go with all my friends by I saw you despite home at 7: 00 pm and we will be in the cinema for 8 o\\'clock.', 'Dear sirs, I am writing following you after your advertisement across my favourite magazine, to let you know how I was intersted in this great adventures you are setting up and that I would like very much to be one by the successuful student you were looking for!. Firstly, I am convinced around all my skill gained within my short but busy student life will be real assets for your team: not only have I an important knowlegde except invironmental problem that I acquired during my studies, but I had already the opportunities to do some temporary activities last summer for the famous Environmental French Agency, where I was in charge of a studies but wild lives against Antarctica! However, I has never had yet the opportunity to go on site to did some practical experiments.', 'The fundamental reason is before they are a leak of accompanying.']\n",
      "1552-1559/2031 | total/used/cuda/res/ram (Gb): 10.00/9.78/3.00/8.37/22.67 | batch/sps: 8/2.48\n",
      "['She only goes to buy his things and I spent hours waiting, she decided what to buy but forgot all the problem, yes, I like going shopping, I like buying trousers, t-shirt, trainers, and my favorite color beyond T-shirts is green, downoff trousers being blue and for trainers is white.', 'by the aim of these goals, most school count except:', 'The executive board meets quarterly to make critical decisions on direction, re-direction, and other pertinent concerns.', 'She never knew what to do with her life when she had to choose wrong twice, the University studies and then they way out against them, she got throughout the computer business because she had been told that it was the future UNKNOWN sudenly she knew that it was another mistake, never mind, she being not gone to change again.', 'It are a fantastic nights filled with the fun on the silent auction, the action of the live auction, tear-filled presentations, short but sweet toast, and of course reminiscing about the accomplishments of the past 25 years.', 'There are many people who get the spirit of competitions when they work as a parts of an activity, they feel to this healthy competition brought the best in there and also the amounts of time required to completed the task will reduce automatically towards one trying to finish earlier than other group mates.', 'It also allows us to had contact with people from other countries (it says: International staff), but I think the chance to talked across different topics being quite restricted as we will work as waiter and that means just taking orders, recommending dish and offered things.', \"Your last letter were nice, well between the tv programmes, I don't usually watch tvs, but last months started a great programmes like computers and you know how I liked them, it's very interesting because it shows you how you can download the most special and popular software in the worlds.\"]\n",
      "1560-1567/2031 | total/used/cuda/res/ram (Gb): 10.00/9.77/3.00/8.37/22.68 | batch/sps: 8/5.40\n",
      "['I think you should choose a small school, in my opinion, because, everyone knows each other and you can make a lot during friends right there, you can meet interesting people, I think been much better, but if you decide the schools in the centre of the town you can enjoy it more, at the same ways you can make a lot through friends and the most important thing is that everything is before you can go near the shops and about the movies, that could be really great.', 'The collective idea of HIV/AIDS transmission is that it is contracted like their clients, whereas it is transmitted mostly by sexual relations between partners.', 'I think I was the only one that noticed he was there, so I moved nearly to him and asked please for his autographs, he seemed very nice, he asked me my names, and he said, \"I\\'m sorry, but I\\'m not interested in taking photos with you, I want you to take a photo with me, and I want you to take a photo of me with him, and I want you to take two photos, and one of them is of him with the sunglasses and the hat, and the other is of him with the sunglasses and the hat, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos, and I want you to take two photos', 'water transport has increased as well and in the periods between 1978 and 1982 having its mayor increase reached level of 60 milion tones, stood fairly steady during the next decades of a decrease of about 10% up throughout 1998 and then recuperated an reaching levels out more than 60 milion tonnes by the year 2002.', \"She suddenly realised until she had no reasonable cause for complaint and this made her angry - Liudmilla's last words gave her an opportunities to express her vexations - she said angrily:\", 'The other groups of mirna were lowly expressed from both immature and in cells at early stage of differentiation but significantly increased plus days 14 and remains expressed at high level at day 21 of differentiation (Fig. 7 F, G).', \"First of all, could you lets us know if the date of June 16th is all right with his timetable program. We have organised to do the party through three under six o'clock in afternoons in College Canteen, about foods we have organised a buffet, but could you also help us around the music which he prefers, if prefer something especialy.\", \"It offered recommendations for various stores, fashion matching, favorite competitive products, special sale of new arrivals, editor's choice, and more.\"]\n",
      "1568-1575/2031 | total/used/cuda/res/ram (Gb): 10.00/9.95/3.00/9.45/22.68 | batch/sps: 8/1.03\n",
      "['Throughout about Ajzen [18] intentions were assumed to be one of the motivational factors that can influence behaviours, which is related to the willingness through an individuals to try something new, and also the effort placed in performed such behaviour.', 'It was focusing on letting them see that they liked death girls must concentrate on trying to heal themselves before healing the family.', 'Obierika, Okonkwo best friend even stated \" He has put a knife on the things that held us together, and we have fallen apart \" emphasized the little including the author and showing how the white men had altered the Ibo society.', 'Loving it.', \"You say you are providing training service and I would like to know whether you could send some above your specialists to do the in-house training for our companies. What is most important is that the system must be ready in one month from our shop-assistants doing not cope with the flows along clients and thus, can't give the proper consultations for everyone.\", \"Well, we can see this as a positive way following development, so now if we would like to buy a German car, we don't have to travel, and if we want a persian carpet, we won't need to travel, and if we want to buy a book about other cultures and from other countries, we can buy them on the internet or even maybe we can find them along our book shop within having to spend a fortune and travel to get them.\", \"It is vital to comprehend that when he affirmed being an irresponsibility to let the young make their choices on everyday issues such as friendship and leisure activity, he is talking about taking away young people's right to free-will but while it is the parent's responsibility to guided and advise their children and teaches them about what are right and what have been wrong, it is not their places to choose their son or daughter's friends on extracurricular activities.\", 'We, as mexican people, must work together to find a ways to explicate and develope the Mexican tourist industries, which not only gave us the dollars but helps us to recover all the natural resources that have been highly destroyed and not due towards the tourists industry itself.']\n",
      "1576-1583/2031 | total/used/cuda/res/ram (Gb): 10.00/9.94/3.00/9.45/22.69 | batch/sps: 8/3.90\n",
      "['Transport on waterways were booms in the time from 1978 plus around 1999 a slight dip occurred around 1998 but it then recovered to its highest level just plus 70 million tonnes.', 'Even though some other movie producers, such as since Bollywood, have also developed, they is still behind Hollywood.', 'At the ends of the day, even humany being needs peaces and prospority for the lives, and to achive the goals one should have enough money & financial resources, working despite money is only above worked above a robots, Great people like Gandhiji, Churchill, Albert never worked for the motivations of any financial goals, but they worked hard near the better prospects of future generations, and the humanities.', \"Furthermore, I would like to suggest you behind we had other offices currently, they were in Opera Place, the room that you required in your last letters are available, four of them were on the same floor, complied with the size you want, what's more, they will have 500 parking spaces, and good public transport connections as well between wonderful views.\", 'I bought one t-shirts and sunglasses with the summer.', 'The mayor directed modifications to the street system, creating bus express lanes to support the Bus Rapid Transit System that could cheaply and rapidly moving people through upon the city.', 'To: Mr. Smith, Managing directors upon: HR manager subject: company canteen introductions The aims of this report is to outline the reasons giving for staff member for not using the company canteen service, and to evaluate possible courses beyond actions to prevent this.', 'Also, foreign mega market chains such as Walmart, Tesco, and Carrefour would like to participate in the retail sector when the Indian government would permit to do so; therefore, the foreign major market chains choose to enter India by the joint venture.']\n",
      "1584-1591/2031 | total/used/cuda/res/ram (Gb): 10.00/9.95/3.00/9.45/22.68 | batch/sps: 8/4.59\n",
      "[\"I want to ask you how many months I should spend to take this course, and how much I have to pay between this course and I want to know if I can take extra lessons in the evening or whe I have free time until I want to take a long course not short course, I will be happy when you send these information through my emails or my addresses if you don't mind, plus some of my friend wanted to take this course across next time.\", 'First of all, it will helping in the economic aspect, now beyond internet even small shops are able to sell their products to anyon in the worlds, nowadays people have access to anything and anywhere with no restrictions, imagining if you are a arts dealer, if you are buying a souvenir from India for instance, you would be estimating the economy in his countries in a small scale, of cause, and for your shop this souvenir would be sold easely.', 'Delicious.', 'In the other hand, is right to say that it has created impact in different ways, such as corruption and piracy, from the last 10 years, which means if the government towards different nations must acts now to make a final point until it, some companies has lost their worth becouse of the criminals organizon which are deteriorate other citizens work under the way to make their product unvalued.', 'Now a day student changed many aspects around their study in order to study useful subjects without the filed that they really liked to study therefore, that will reflect the benefit on I students and the socities However, some people believe that student upon they allowed to studied useful only regardless their diser which will give the motivate to carry on studies, In my opinion we should allow them to study what they like and where rather than restrict them within word certain subjects such as science and technology, and also we should encourage our students to choose the eara that might be flowrshing their life and transferring the knowledges they obtains along with their studies.', 'Dan Today I and my friends decided to go to the Big Cinema, we is planning to see the films Space attacks, we wanted to invite you, if you agree we pick you up at 8: 30 p.m the film begins at 9: 00 p.m. We hope that you enjoyed the picture.', \"Addicts are people of real problems and inflicted by a disease they are members of beyond our community that desperately need help, they are someone's mother, fathers, sister and our brothers who need our help.\", \"For example, when customers calling in to a delivery company to track their package, with fast communications technologies, a customer services representative can communicated with their driver to find out where their customers' package is beyond, and what times they are expected to be delivering.\"]\n",
      "1592-1599/2031 | total/used/cuda/res/ram (Gb): 10.00/9.94/3.00/9.45/22.68 | batch/sps: 8/2.27\n",
      "['Through this trends, I have been inspired to apply for Master like Information Systems, undertake more in-depth trainings in information system, and land a position as a business analyst at a technology company in the real estate industry in the US after graduation.', 'Lunn: \" You must understand that Murdoch was a busy man, he was always traveling.', \"Hi honey, along I was you, I think I would gone from the large school within the center of town because I wouldn't like to live in the countryside, but I know through you like went to the center throughout town, so in my opinion you should go there, furthermore, in the countryside are easier to make friends than in the center.\", \"If you will go with your parents, I think, you aren't free to go where you want, plus in your friend you should go to play volleyball on the beaches or to know some girls, while in the evening you could go against the restaurant to eat something.\", 'It was a large mail, but the plots was that some kidnapper had my dad with them and they wanted a lots of money moreless ten thousand dollars so I was so afraid for I called my mother and she said in she was going to see him after he was alive.', 'Including film from other nationalities, that originally are or had been translated into English, that has been shown a film may not be encouraging enough for people to join the clubs, so new activity around member can be added, as discussions about the films shown or quiz - emphasised in the adverts the possibilities to come to see the film for being a member of the club, but promoted the advantages of becoming one (especially economic ones, but also the chance to participate in all the activities).', 'Reduce the risk of disease.', 'After that, Titania fell in love in the bottoms.']\n",
      "1600-1607/2031 | total/used/cuda/res/ram (Gb): 10.00/9.95/3.00/9.45/22.69 | batch/sps: 8/3.37\n",
      "['After that there was a decline to 1% but the percentage rose to 21% among further study the percentage of new employed was approximately 59% in Science, the 28% in futher study but were the lowest percentages in self employed which was 1% along conclusion we can the most significant is', 'There is no liberty through this society as those in power show such convictions after the ranks and files has no clues as to question, or they fear for their life not to questioned.', 'including a few weeks within the storms, the Scruggs group had signed several hundred clients, and was actively pursuing whistle-blowers.', 'The inter-optodes separation distances is considered 28mm in this designs, 16 EEG electrode are positioned in between the optodes.', 'Everyone is doing it incidents of human flesh searches are usually popular among cyber citizens.', \"google chick fil a first 100 for details, but TL:DR is camp like 24 hour, win 52 free number 1 combo (sandwich, fry and drinks) not sure how far scranton been, but sometimes 100 don't show up at the beginnings, so you might be able to get in from works if you stay the rest through the time lol\", \"They include sky rocketed incomes and wealth inequalities in part due to a persistent labour-market slack problem, issues with casualisations, a polarised workforce and wage in general, that aren't rose behind many workers.\", 'Black people were not allowed to have property, political views or education.']\n",
      "1608-1615/2031 | total/used/cuda/res/ram (Gb): 10.00/9.94/3.00/9.45/22.69 | batch/sps: 8/3.64\n",
      "['Recommendations it is advisable to make some courses on subjects which students will needed for passing the exams to enter the universities, up basic level is not sufficient for them; it are purposeful to have not lesson for 45 mins, but lecture or seminars for 90 min, like before universities (some schools already do it).', 'The main actors were Silvester Stallone and Sharon Stone, the most famous actors in the U.S.A., The stories started from New York but the UNKNOWN of the film, we going over the Irish pub in ROAD \" VITTORLO EVANVELE \" behind like new my friends Mark, the beer were excellent and I drank a lots near.', 'lol', \"except fact, the primary concern of Chicano social movement does not include Chicana women's concerns and struggles, but it is organized to benefits only for few, which is Chicano men.\", 'He pausing, puffing awhile, then resumed meditatively: \" Why, old man, down in Keokuk Gail Holden wouldn\\'t last a month.', 'Its not a rumor.', \"Well, I think will have been almost the same as today, but with the technology of the future like the mp5 or the Robots things on that you know, but I do not think I will live here forever. I think on when I grow up, I will go to live among the U.S.A. and I also think that into I'm able to study in Harvard and I will become a lawyer until I win.\", 'It is a matter behind fact on this kind of show attracts people of all ages, but what doing viewers really liking about them. Lately, I have been watching one of these reality shows called Big Brother (men and women about their twenties and thirties) having to live together during three months.']\n",
      "1616-1623/2031 | total/used/cuda/res/ram (Gb): 10.00/5.74/3.00/5.02/22.70 | batch/sps: 8/3.01\n",
      "['This again means that bias could be realized.', 'Another interpretations of the present findings of a declines between executive attention after the physical work out is about in those who pass in the FIFA-TEST, there were subjects upon a better physical level than others.', 'A lacks of insights', \"Dear Sally, I'm writting worried following our meet, around I realized that the day of the meetings, I'm going to be busy by a groups work we had at school; so we needed to change the meet up another day, I agreed with the idea of going on this Saturday, I hope you'll be free that day; remembered that the arranged was in the park at 9.a.m.\", 'The evidence shows that CP was hired across November 2012 towards a dispatch it also shows that the CP was discharged by the Respondents on July 07, 2015 until failure to pass a background check due to pass felonies convictions.', \"I think she will be taught a lot of things to me anyway, I wanted to tell something upon my first days at classes, it was very diffirent for me because do you know Kate, my ex-class meyt I met her in my class, she decided to join that classes as well, it was really nice to me until I have already one good friend among my class, anyway the first days you know, we were talked about our selves, it wasn't very diffirent.\", 'the main important point to mentioned were no over cultivation in Oceania It are clearly seen, despite the pie chart the main causes without land degradation is over-grazing by 35% without that is the deforestration which represt 30% and likewise been over-cultivation just below by 2%', 'The more computer advances and more the kinds of communican changes, in the past people were obliged to send a letter until post or the only ways that they could hear and see each other, was to gather and talks to each other, but at the moment, during the advent of the internet, you only needed to use them to send fax or email (instead towards posts) or chatting with each other online out a result within that you have the possibility to speak and see other online and UNKNOWN few second.']\n",
      "1624-1631/2031 | total/used/cuda/res/ram (Gb): 10.00/5.75/3.00/5.02/22.69 | batch/sps: 8/3.55\n",
      "['One days Mr. Sanchez was watching a soccer match when suddenly somebody knocked the door, so he got up because he was waiting for his friends, when he opened the door he only discovered a little suitcase, he took it and came in his houses, but he could not open it and he noticed that along the suitcases, he came worried because the noise was like a wach, so he went to the garages to his tools, but the noises grew up and grew up surely.', 'The graph showing the information from average number from child under family reveals that Spain had the Highest average number at 1980 with 2.2 children per family and the lowest before 2000 about 1.2 children per family, representing the highest decrease amongst the country shown concerning nearly 50% decrease in 20 years.', \"But the second half of the book shows how little bearing that critiques has by Algeria's present, denied the reader the easy satisfaction of anticolonial justice.\", \"Traditions have been a wealth which we have to preserve into our future generations also if not only telling us the stories of our success but also, these skills are based on some scientific bases, except oiled the babies and putting in sunlight is a common tradition in India, usefull still since baby receives tols of vit'D'within the sunlight.\", 'On the one hand, the environment at home plays an important role, it is where most of the teaching in childhood is received, from helped at home, the other, providing healthy cares and happy living, in order for us not to be violent, passing through the presenting of the child to the societies, to let her not what surrounded her, to the more intimate influences such as teaching you how to stay calm when need, be racional in the most difficult situations, emotions themselves.', \"Well, I think the opposite like a years before but recently I think this including I see all the people to go shopping they don't realise that they were outside along the real world poor people who need that money and they were only spent before material things, you would put you money until the bank because you don't need it now, but tomorrows you don't know.\", 'And the health care provider such despite surgeons were limited in numbers.', 'After nine week training and three month follow-up, the result exhibits the Triple-p having significant influence in the following facets, such as 33.3% of the parent in intervention groups shows reliable improvement in parent-child attachment, whereas controls groups only have 4.5%.']\n",
      "1632-1639/2031 | total/used/cuda/res/ram (Gb): 10.00/5.94/3.00/5.02/22.69 | batch/sps: 8/2.30\n",
      "['Summing up, money may be controlled the society and some people can feel very happy on it, but the really important aspect of life cannot be bought after any prize and as soon as near you are able to control your own worlds, as the job or important parts of it, money will not control you.', 'The given pie charts show the total money spent annualy by a particular school without different years i.e 1981, 1991 & 2001 Secondly, in 1981 the school following UK spending 2% of its budget on insurances, 40% on teachers salary, 15% on furniture and other equipments, 15% on resources on library book and stationary etc.', 'Because, it is served as a lead investor and customer within transportations services while providing technical assistance as the industry develops and demonstrating its service.', 'Most immigrant people worry that the uses through health care for their children also would harm their chances of attaining legal citizenship or permanent status.', 'I had thrown myself on a pallets by the window, and was looking out despite the black water; Johann, the keepers, still paled from his wound, but not much hurt besides, had brought me supper.', 'When asked, some people felt that constructing this kinds of facilities would affect the quietness throughout residential areas surrounding the downtown areas; this is true, however, it has to be taken into consideration the facts that it will not be a permanent condition, to construct operations will not last for longer behind one or two months.', 'I certify between Liana being a very problematic employees.', 'downoff example, Northern Nigeria were still one of the only parts of the world that the Polio virus continues to be prevalent.']\n",
      "1640-1647/2031 | total/used/cuda/res/ram (Gb): 10.00/5.94/3.00/5.02/22.69 | batch/sps: 8/5.70\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "\n",
    "batch_size = 8  # gpt2-large\n",
    "max_length = 350\n",
    "max_new_tokens = 350\n",
    "\n",
    "def model_process(batch, idx, **kwargs):\n",
    "    num_samples = len(batch[\"input\"])\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = kwargs.get(\"model\")\n",
    "    tokenizer = kwargs.get(\"tokenizer\")\n",
    "    total_samples = kwargs.get(\"total_samples\")\n",
    "\n",
    "    # print(batch[\"request\"])\n",
    "    inputs = tokenizer(batch[\"request\"], padding=True, return_tensors=\"pt\").to(device)\n",
    "    # inputs = tokenizer(batch[\"request\"], return_tensors=\"pt\").inputs.to(device)\n",
    "    # inputs = tokenizer(item[\"request\"], return_tensors=\"pt\").inputs\n",
    "    # print(inputs)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    # outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "    outputs = model.generate(**inputs, num_return_sequences=1)\n",
    "    # outputs = model.generate(\n",
    "    #     **inputs,\n",
    "    #     do_sample=True,\n",
    "    #     top_k=10,\n",
    "    #     num_return_sequences=1,\n",
    "    #     pad_token_id=tokenizer.eos_token_id,\n",
    "    #     max_length=max_length,\n",
    "    # )\n",
    "    # print(outputs)\n",
    "\n",
    "    trimmed_output = outputs[:, inputs.input_ids.shape[1] :]\n",
    "    processed = tokenizer.batch_decode(trimmed_output, skip_special_tokens=True)\n",
    "    print(processed)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    sps = num_samples / elapsed_time\n",
    "    sps_str = f\"{sps:.2f}\"\n",
    "\n",
    "    utilization = calculate_utilization()\n",
    "    utilization_str = format_utilization_narrow(utilization)\n",
    "    print(\n",
    "        f\"{idx[0]}-{idx[-1]}/{total_samples} | total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "        f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']} | \"\n",
    "        f\"batch/sps: {num_samples}/{sps_str}\"\n",
    "    )\n",
    "\n",
    "    # return {\"processed\": processed}\n",
    "    return {\"processed\": processed}\n",
    "    # return {\"processed\": processed, \"utilization\": utilization, \"tps\": tps}\n",
    "    # return {\"processed\": processed, \"utilization\": utilization}\n",
    "\n",
    "\n",
    "utilization = calculate_utilization()\n",
    "utilization_str = format_utilization_narrow(utilization)\n",
    "print(\n",
    "    f\"total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "    f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']}\"\n",
    ")\n",
    "\n",
    "processed_samples_map = {}\n",
    "\n",
    "for task, samples in test_dataset_dict.items():\n",
    "    total_samples = len(samples)\n",
    "\n",
    "    print(f\"Processing {total_samples} samples for {task}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    processed_samples = samples.map(\n",
    "        model_process,\n",
    "        fn_kwargs={\n",
    "            \"model\": model,\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"total_samples\": total_samples,\n",
    "        },\n",
    "        num_proc=1,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        with_indices=True,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    sps = total_samples / elapsed_time\n",
    "    sps_str = f\"{sps:.2f}\"\n",
    "\n",
    "    print(f\"Finished processing {total_samples} samples for {task}.\")\n",
    "    print(processed_samples)\n",
    "    print(processed_samples[\"reference\"][0])\n",
    "    print(processed_samples[\"processed\"][0])\n",
    "\n",
    "    utilization = calculate_utilization()\n",
    "    utilization_str = format_utilization_narrow(utilization)\n",
    "    print(\n",
    "        f\"{total_samples} | total/used/cuda/res/ram (Gb): {utilization_str['total_memory']}/{utilization_str['memory_used']}/\"\n",
    "        f\"{utilization_str['cuda_allocated']}/{utilization_str['cuda_reserved']}/{utilization_str['ram_usage']} | \"\n",
    "        f\"sps: {sps_str}\"\n",
    "    )\n",
    "\n",
    "    processed_samples_map[task] = {\n",
    "        # \"task\": task,\n",
    "        # \"samples\": samples,\n",
    "        \"samples\": processed_samples,\n",
    "        \"total_samples\": total_samples,\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"sps\": sps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_length\": max_length,\n",
    "        \"utilization\": utilization,\n",
    "    }\n",
    "\n",
    "# processed_samples = samples.map(model_process, num_proc=torch.cuda.device_count())\n",
    "# processed_samples = samples.map(\n",
    "#     model_process,\n",
    "#     fn_kwargs={\n",
    "#         \"model\": model,\n",
    "#         \"tokenizer\": tokenizer,\n",
    "#         \"total_samples\": total_samples,\n",
    "#     },\n",
    "#     num_proc=1,\n",
    "#     batched=True,\n",
    "#     batch_size=batch_size,\n",
    "#     with_indices=True,\n",
    "# )\n",
    "\n",
    "processed_gec_samples = processed_samples_map[\"gec\"][\"samples\"]\n",
    "\n",
    "pprint(processed_gec_samples)\n",
    "pprint(processed_gec_samples[\"processed\"][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: gpt2-large-coedit, model_id: iliazlobin/gpt2-large-coedit, model_path: iliazlobin_gpt2-large-coedit\n",
      "Total/trainable params: 774030080/774030080\n",
      "task: gec, samples: 2031\n",
      "s: rouge, v: {'rouge1': 0.02103729738142278, 'rouge2': 0.012939179842783054, 'rougeL': 0.01988159580256014, 'rougeLsum': 0.019904151490036423}\n",
      "s: sacreblue, v: {'score': 0.332448847346096, 'counts': [1160, 614, 420, 300], 'totals': [14270, 14099, 13950, 13803], 'precisions': [8.12894183601962, 4.3549187885665654, 3.010752688172043, 2.1734405564007826], 'bp': 0.0852149120227624, 'sys_len': 14270, 'ref_len': 49411}\n",
      "s: sari, v: {'sari': 18.862741998464767}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "task: simplification, samples: 1144\n",
      "s: rouge, v: {'rouge1': 0.07205695197823114, 'rouge2': 0.025927121179376563, 'rougeL': 0.0620578024013707, 'rougeLsum': 0.06214198510481871}\n",
      "s: sacreblue, v: {'score': 0.6963576125791957, 'counts': [3258, 963, 367, 172], 'totals': [96594, 96065, 95536, 95008], 'precisions': [3.3728803031244174, 1.0024462603445583, 0.38414838385530065, 0.18103738632536207], 'bp': 1.0, 'sys_len': 96594, 'ref_len': 21642}\n",
      "s: sari, v: {'sari': 33.19796014737301}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "task: clarity, samples: 126\n",
      "s: rouge, v: {'rouge1': 0.04467019242471755, 'rouge2': 0.017104877696825213, 'rougeL': 0.037571354919261835, 'rougeLsum': 0.037074618734326464}\n",
      "s: sacreblue, v: {'score': 1.64315045439728, 'counts': [204, 73, 51, 34], 'totals': [2550, 2525, 2500, 2475], 'precisions': [8.0, 2.891089108910891, 2.04, 1.3737373737373737], 'bp': 0.5791032400425654, 'sys_len': 2550, 'ref_len': 3943}\n",
      "s: sari, v: {'sari': 13.96293905636872}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "task: coherence, samples: 1062\n",
      "s: rouge, v: {'rouge1': 0.059109087987729, 'rouge2': 0.03755958825846817, 'rougeL': 0.053543914551549956, 'rougeLsum': 0.053585590561876326}\n",
      "s: sacreblue, v: {'score': 4.0935554634320965, 'counts': [2513, 1457, 1094, 861], 'totals': [25830, 25614, 25399, 25185], 'precisions': [9.7289972899729, 5.688295463418443, 4.307256191188629, 3.4187016081000596], 'bp': 0.766165596424663, 'sys_len': 25830, 'ref_len': 32710}\n",
      "s: sari, v: {'sari': 13.47166353514615}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "task: neutralize, samples: 1127\n",
      "s: rouge, v: {'rouge1': 0.03037145140040299, 'rouge2': 0.014819236146151483, 'rougeL': 0.027742677266780133, 'rougeLsum': 0.027944193430874273}\n",
      "s: sacreblue, v: {'score': 1.9829227050312535, 'counts': [1088, 558, 400, 313], 'totals': [20177, 19943, 19742, 19549], 'precisions': [5.392278336720028, 2.797974226545655, 2.026137169486374, 1.6011049158524733], 'bp': 0.7496863857488568, 'sys_len': 20177, 'ref_len': 25990}\n",
      "s: sari, v: {'sari': 14.732531262584786}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "task: paraphrase, samples: 1590\n",
      "s: rouge, v: {'rouge1': 0.004785701144875762, 'rouge2': 0.001700067518622463, 'rougeL': 0.004180006483784259, 'rougeLsum': 0.0041521331720886815}\n",
      "s: sacreblue, v: {'score': 0.007427270825772531, 'counts': [230, 59, 20, 8], 'totals': [7949, 7897, 7845, 7793], 'precisions': [2.89344571644232, 0.74711915917437, 0.25493945188017847, 0.10265622994995509], 'bp': 0.015229034390145793, 'sys_len': 7949, 'ref_len': 41212}\n",
      "s: sari, v: {'sari': 33.88960471041262}\n",
      "s: em, v: {'exact_match': 0.0}\n",
      "{'model': 'iliazlobin/gpt2-large-coedit', 'hardware': 'HomeDesktop (RTX3080)', 'total_params': 774030080, 'gec': {'task': 'gec', 'total_samples': 2031, 'elapsed_time': 319.29948711395264, 'sps': 6.360799443674553, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.02103729738142278, 'rouge2': 0.012939179842783054, 'rougeL': 0.01988159580256014, 'rougeLsum': 0.019904151490036423}, 'sacreblue': {'score': 0.332448847346096, 'counts': [1160, 614, 420, 300], 'totals': [14270, 14099, 13950, 13803], 'precisions': [8.12894183601962, 4.3549187885665654, 3.010752688172043, 2.1734405564007826], 'bp': 0.0852149120227624, 'sys_len': 14270, 'ref_len': 49411}, 'sari': {'sari': 18.862741998464767}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10622017536, 'cuda_allocated': 3218538496, 'cuda_reserved': 9974054912, 'ram_usage': 24193794048}}, 'simplification': {'task': 'simplification', 'total_samples': 1144, 'elapsed_time': 1473.043888092041, 'sps': 0.7766231605507458, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.07205695197823114, 'rouge2': 0.025927121179376563, 'rougeL': 0.0620578024013707, 'rougeLsum': 0.06214198510481871}, 'sacreblue': {'score': 0.6963576125791957, 'counts': [3258, 963, 367, 172], 'totals': [96594, 96065, 95536, 95008], 'precisions': [3.3728803031244174, 1.0024462603445583, 0.38414838385530065, 0.18103738632536207], 'bp': 1.0, 'sys_len': 96594, 'ref_len': 21642}, 'sari': {'sari': 33.19796014737301}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10608218112, 'cuda_allocated': 3218538496, 'cuda_reserved': 10125049856, 'ram_usage': 23978106880}}, 'clarity': {'task': 'clarity', 'total_samples': 126, 'elapsed_time': 85.92395758628845, 'sps': 1.466412902053138, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.04467019242471755, 'rouge2': 0.017104877696825213, 'rougeL': 0.037571354919261835, 'rougeLsum': 0.037074618734326464}, 'sacreblue': {'score': 1.64315045439728, 'counts': [204, 73, 51, 34], 'totals': [2550, 2525, 2500, 2475], 'precisions': [8.0, 2.891089108910891, 2.04, 1.3737373737373737], 'bp': 0.5791032400425654, 'sys_len': 2550, 'ref_len': 3943}, 'sari': {'sari': 13.96293905636872}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10619228160, 'cuda_allocated': 3218538496, 'cuda_reserved': 10125049856, 'ram_usage': 24416710656}}, 'coherence': {'task': 'coherence', 'total_samples': 1062, 'elapsed_time': 824.0441107749939, 'sps': 1.2887659606003545, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.059109087987729, 'rouge2': 0.03755958825846817, 'rougeL': 0.053543914551549956, 'rougeLsum': 0.053585590561876326}, 'sacreblue': {'score': 4.0935554634320965, 'counts': [2513, 1457, 1094, 861], 'totals': [25830, 25614, 25399, 25185], 'precisions': [9.7289972899729, 5.688295463418443, 4.307256191188629, 3.4187016081000596], 'bp': 0.766165596424663, 'sys_len': 25830, 'ref_len': 32710}, 'sari': {'sari': 13.47166353514615}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10627964928, 'cuda_allocated': 3218538496, 'cuda_reserved': 10125049856, 'ram_usage': 24346681344}}, 'neutralize': {'task': 'neutralize', 'total_samples': 1127, 'elapsed_time': 700.9085228443146, 'sps': 1.6079131060164447, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.03037145140040299, 'rouge2': 0.014819236146151483, 'rougeL': 0.027742677266780133, 'rougeLsum': 0.027944193430874273}, 'sacreblue': {'score': 1.9829227050312535, 'counts': [1088, 558, 400, 313], 'totals': [20177, 19943, 19742, 19549], 'precisions': [5.392278336720028, 2.797974226545655, 2.026137169486374, 1.6011049158524733], 'bp': 0.7496863857488568, 'sys_len': 20177, 'ref_len': 25990}, 'sari': {'sari': 14.732531262584786}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10656915456, 'cuda_allocated': 3218538496, 'cuda_reserved': 10125049856, 'ram_usage': 24317722624}}, 'paraphrase': {'task': 'paraphrase', 'total_samples': 1590, 'elapsed_time': 266.55464363098145, 'sps': 5.96500581772343, 'batch_size': 8, 'max_length': 350, 'scores': {'rouge': {'rouge1': 0.004785701144875762, 'rouge2': 0.001700067518622463, 'rougeL': 0.004180006483784259, 'rougeLsum': 0.0041521331720886815}, 'sacreblue': {'score': 0.007427270825772531, 'counts': [230, 59, 20, 8], 'totals': [7949, 7897, 7845, 7793], 'precisions': [2.89344571644232, 0.74711915917437, 0.25493945188017847, 0.10265622994995509], 'bp': 0.015229034390145793, 'sys_len': 7949, 'ref_len': 41212}, 'sari': {'sari': 33.88960471041262}, 'em': {'exact_match': 0.0}}, 'utilization': {'total_memory': 10736893952, 'memory_used': 10627964928, 'cuda_allocated': 3218538496, 'cuda_reserved': 10125049856, 'ram_usage': 24056315904}}}\n"
     ]
    }
   ],
   "source": [
    "hardware = \"HomeDesktop (RTX3080)\"\n",
    "# hardware = \"NC24 (A100)\"\n",
    "print(f\"model_name: {model_name}, model_id: {model_id}, model_path: {model_path}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total/trainable params: {total_params}/{total_trainable_params}\")\n",
    "\n",
    "if list in globals():\n",
    "    del list\n",
    "\n",
    "all_flats = []\n",
    "all_scores = []\n",
    "if os.path.exists(\"results/all-scores.csv\"):\n",
    "    all_scores = pd.read_csv(\"results/all-scores.csv\").to_dict(\"records\")\n",
    "\n",
    "all_fulls = []\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "# glue_metric = evaluate.load(\"glue\", \"stsb\")\n",
    "sacreblue_metric = evaluate.load(\"sacrebleu\")\n",
    "sari_metric = evaluate.load(\"sari\")\n",
    "em_metric = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def calculate_scores(processed_samples):\n",
    "    rouge_score = rouge_metric.compute(\n",
    "        predictions=processed_samples[\"processed\"], references=processed_samples[\"references\"]\n",
    "    )\n",
    "    # pprint(rouge_score)\n",
    "\n",
    "    sacreblue_score = sacreblue_metric.compute(\n",
    "        predictions=processed_samples[\"processed\"], references=processed_samples[\"references\"]\n",
    "    )\n",
    "    # pprint(sacreblue_score)\n",
    "\n",
    "    sari_score = sari_metric.compute(\n",
    "        sources=processed_samples[\"input\"],\n",
    "        predictions=processed_samples[\"processed\"],\n",
    "        references=processed_samples[\"references\"],\n",
    "    )\n",
    "    # pprint(sari_score)\n",
    "\n",
    "    em_score = em_metric.compute(predictions=processed_samples[\"processed\"], references=processed_samples[\"reference\"])\n",
    "    # pprint(em_score)\n",
    "\n",
    "    return {\n",
    "        \"rouge\": rouge_score,\n",
    "        \"sacreblue\": sacreblue_score,\n",
    "        \"sari\": sari_score,\n",
    "        \"em\": em_score,\n",
    "    }\n",
    "\n",
    "\n",
    "for task, obj in processed_samples_map.items():\n",
    "    print(f\"task: {task}, samples: {len(obj['samples'])}\")\n",
    "\n",
    "    batch = obj[\"samples\"]\n",
    "    total_samples = len(batch)\n",
    "\n",
    "    all_saved_samples = batch.remove_columns([\"references\"])\n",
    "    saved_samples = all_saved_samples[:100] if len(all_saved_samples) > 100 else all_saved_samples\n",
    "    flats_frame = pd.DataFrame.from_records(saved_samples)\n",
    "    flats_frame.to_json(f\"samples/{model_path}_{task}.json\", orient=\"records\")\n",
    "\n",
    "    scores = calculate_scores(batch)\n",
    "    # pprint(scores)\n",
    "\n",
    "    score_paths = [\n",
    "        \"rouge.rouge1\",\n",
    "        # \"rouge.rouge2\",\n",
    "        # \"rouge.rougeL\",\n",
    "        # \"rouge.rougeLsum\",\n",
    "        \"sacreblue.score\",\n",
    "        \"sari.sari\",\n",
    "        \"em.exact_match\",\n",
    "    ]\n",
    "\n",
    "    normalized_scores = {}\n",
    "    for s, v in scores.items():\n",
    "        print(f\"s: {s}, v: {v}\")\n",
    "        for ss, vv in v.items():\n",
    "            if not isinstance(vv, list):\n",
    "                # normalized_scores[f\"score.{k}.{ss}\"] = vv\n",
    "                path = f\"{s}.{ss}\"\n",
    "                if path in score_paths:\n",
    "                    normalized_scores[f\"score.{s}.{ss}\"] = vv\n",
    "    # pprint(normalized_scores)\n",
    "\n",
    "    normalized_utilization = {}\n",
    "    for s, v in obj[\"utilization\"].items():\n",
    "        if not isinstance(v, list):\n",
    "            normalized_utilization[f\"utilization.{s}\"] = v\n",
    "    # print(normalized_utilization)\n",
    "\n",
    "    flat_dict = {\n",
    "        \"model\": model_id,\n",
    "        \"hardware\": hardware,\n",
    "        \"total_params\": total_params,\n",
    "        \"total_samples\": total_samples,\n",
    "        \"elapsed_time\": obj[\"elapsed_time\"],\n",
    "        \"sps\": obj[\"sps\"],\n",
    "        \"batch_size\": obj[\"batch_size\"],\n",
    "        \"max_length\": obj[\"max_length\"],\n",
    "        \"task\": task,\n",
    "    }\n",
    "    flat_dict.update(normalized_scores)\n",
    "    flat_dict.update(normalized_utilization)\n",
    "    # pprint(frame)\n",
    "\n",
    "    all_flats.append(flat_dict)\n",
    "    all_scores.append(flat_dict)\n",
    "\n",
    "    fulls_frame = {\n",
    "        \"task\": task,\n",
    "        \"total_samples\": total_samples,\n",
    "        \"elapsed_time\": obj[\"elapsed_time\"],\n",
    "        \"sps\": obj[\"sps\"],\n",
    "        \"batch_size\": obj[\"batch_size\"],\n",
    "        \"max_length\": obj[\"max_length\"],\n",
    "    }\n",
    "    fulls_frame.update(\n",
    "        {\n",
    "            \"scores\": scores,\n",
    "            \"utilization\": obj[\"utilization\"],\n",
    "        }\n",
    "    )\n",
    "    all_fulls.append(fulls_frame)\n",
    "\n",
    "flats_frame = pd.DataFrame.from_records(all_flats)\n",
    "flats_frame.to_csv(f\"results/{model_path}.csv\", index=False)\n",
    "\n",
    "scores_frame = pd.DataFrame.from_records(all_scores)\n",
    "scores_frame.to_csv(f\"results/all-scores.csv\", index=False)\n",
    "\n",
    "fulls_dict = {\n",
    "    \"model\": model_id,\n",
    "    \"hardware\": hardware,\n",
    "    \"total_params\": total_params,\n",
    "}\n",
    "for full in all_fulls:\n",
    "    fulls_dict[full[\"task\"]] = full\n",
    "\n",
    "print(fulls_dict)\n",
    "fulls_frame = pd.DataFrame.from_records([fulls_dict])\n",
    "fulls_frame.to_json(f\"results/{model_path}.json\", orient=\"records\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
